{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 더미 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import tensorflow as tf\n",
    "print(tf.__version__) # .__version__ 속성으로 버전을 확인함\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 간단한 딥러닝 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용할 입력 데이터를 준비함.\n",
    "# # y=x+1 관계를 갖는 숫자를 x,y 변수에 각각 10개씩 입력함.\n",
    "# # 이 때, x변수의 숫자 배열을 (10행 1열) 형태의 2차원 배열로 변환함.\n",
    "# x=[-3,31,-11,4,0,22,-2,-5,-25,-14]\n",
    "# y=[-2,32,-10,5,1,23,-1,-4,-24,-13]\n",
    "\n",
    "# X_train=np.array(x).reshape(-1,1)\n",
    "# y_train=np.array(y)\n",
    "\n",
    "# print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "케라스 Sequential API는 레이어 여러 개를 연결하여 신경망 모델을 구성하는 도구이다.  \n",
    "  \n",
    "간단한 아키텍처를 가지면서도 대부분의 딥러닝 모델을 만들 수 있다는 장점이 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential() # Sequential 모델 인스턴스를 생성함\n",
    "\n",
    "\n",
    "# # add 메소드를 사용하여 완전 연결 레이어(Dense)를 모델에 추가함.\n",
    "\n",
    "# # 입력 데이터의 차원(input_dim)은 모델 학습에 사용하는 설명 변수(피처)의 개수를 지정하는데,\n",
    "# # 여기서는 1개의 피처를 사용하므로 1로 설정함.\n",
    "\n",
    "# # 완전 연결 레이어의 출력값은 목표 레이블(Y)을 예측함\n",
    "# # 한 개의 연속성 수치(ex.주택 가격)를 예측하는 회귀 문제이므로 유닛(unit) 개수는 1임\n",
    "# # 활성화(activation) 함수로 'linear' 옵션을 지정하여 선형 함수의 출력을 그대로 사용함.\n",
    "# model.add(Dense(units=1,activation='linear',input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summary 메소드를 이용하여 모델 아키텍처(구조)를 확인함\n",
    "# # 딥러닝 모델이 학습할 모수(파라미터:Param #)는 2개인데,\n",
    "# # 일차함수의 기울기(회귀계수)와 절편(상수항)임.\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델이 훈련하는데 필요한 기본 설정을 compile 함수에 지정하는데,\n",
    "# # 옵티마이저(optimizer)와 손실 함수(loss)를 설정함.\n",
    "\n",
    "# # adam 옵티마이저를 선택하고 회귀 분석의 손실 함수인 평균제곱오차(mse)를 지정함.\n",
    "\n",
    "# # metrics 옵션에 보조 평가 지표를 추가할 수 있는데,\n",
    "# # 여기서는 평균절대오차(mae)를 추가하여 손실 함수를 모니터링할 때 함께 추적하기로 함.\n",
    "# model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit 메소드에 훈련 데이터를 입력하여 모델을 학습시키는데,\n",
    "# # 컴파일 단계에서 설정한 adam 옵티마이저와 mse 손실 함수를 가지고 최적의 가중치와 편향을 찾음.\n",
    "\n",
    "# # 에포크(epoch)는 전체 입력 데이터를 모두 몇 번 학습할 것인지 반복 횟수를 정함.\n",
    "\n",
    "# # verbose 옵션을 False(0)로 지정하면 훈련 과정을 화면에 보여주지 않는데,\n",
    "# # 훈련 과정을 표시하려면 1 또는 2를 입력함.\n",
    "# model.fit(X_train,y_train,epochs=3000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습을 마친 딥러닝 모델의 가중치를 확인하려면 weights 속성을 보면 됨\n",
    "# # 기울기에 해당하는 가중치(kernel:0)와 절편에 해당하는 편향(bias:0) 모두 1에 가까운 값을 가지는데,\n",
    "# # 이는 모델 학습을 통해 일차함수 관계식을 매우 근사하게 찾아낸 것으로 볼 수 있다.\n",
    "# model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트 데이터(X)를 predict 메소드에 입력하면 목표 레이블(Y)에 대한 예측값을 얻을 수 있음.\n",
    "# model.predict([[11],[12],[13]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 딥러닝을 활용한 회귀 분석 : 보스턴 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print('시드 고정:',SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sklearn 데이터셋에서 보스턴 주택 데이터셋 로딩\n",
    "# from sklearn import datasets\n",
    "# housing=datasets.load_boston()\n",
    "# X_data=housing.data\n",
    "# y_data=housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_data.shape,y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "입력 데이터의 서로 다른 피처 값의 범위를 비슷한 크기로 맞춰 주면 딥러닝 모델의 성능을 확보하는데 유리한데,  \n",
    "  \n",
    "이것을 피처 스케일링이라고 부름.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MinMaxScaler를 사용하여 입력 데이터(X_data)의 모든 피처 값을 0~1 범위로 정규화 처리함.\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# X_data_scaled=scaler.fit_transform(X_data)\n",
    "\n",
    "# X_data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용하기 위하여 훈련 데이터(80%)와 검증 데이터(20%)를 분할함.\n",
    "# # 학습 - 테스트 데이터셋 분할\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X_data,y_data,test_size=0.2,shuffle=True,random_state=SEED)\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MLP 모델 아키텍처 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결(Dense) 레이어만 사용하여 5개 레이어를 갖는 다층 신경망(MLP)을 만든다.  \n",
    "  \n",
    "레이어를 추가할 때는 add 함수를 사용한다.  \n",
    "  \n",
    "은닉 레이어 4개는 각각 128개, 64개, 32개, 16개의 유닛을 갖는다.  \n",
    "  \n",
    "입력 데이터의 피처가 13개이므로 첫 번째 Dense 레이어의 input_dim에 13을 지정한다.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망\n",
    "# def build_model(num_input=1):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='relu',input_dim=num_input))\n",
    "#     model.add(Dense(64,activation='relu'))\n",
    "#     model.add(Dense(32,activation='relu'))\n",
    "#     model.add(Dense(16,activation='relu'))\n",
    "#     model.add(Dense(1,activation='relu'))\n",
    "\n",
    "#     model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(num_input=13)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 미니 배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델을 훈련시킬 때 샘플 데이터를 한 개씩 입력해서 가중치를 갱신하려면 학습 시간이 오래 걸리는 문제가 있음.  \n",
    "  \n",
    "***미니 배치 학습***은 전체 데이터를 여러 개의 작은 배치 단위로 나누고 배치에 들어 있는 샘플 데이터를 묶어서 모델에 입력함.  \n",
    "  \n",
    "배치 단위로 경사하강법을 적용하고 손실 함수를 최소화하는 방향으로 가중치를 업데이트함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련\n",
    "# model.fit(X_train,y_train,epochs=100,batch_size=32,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "evaluate 함수에 테스트 데이터를 입력하여 모델의 일반화 성능을 평가함  \n",
    "  \n",
    "loss는 11.93이고 mae는 2.57임  \n",
    "  \n",
    "검증 손실이 훈련 손실보다 크기 때문에 과대적합으로 판단됨  \n",
    "  \n",
    "배치 크기에 따라 모델 성능이 달라질 수 있기 때문에 모델을 설계할 때 중요하게 고려해야 함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "학습 데이터 일부(여기서는 25%)를 검증 데이터를 사용하여 교차 검증을 해봄  \n",
    "  \n",
    "fit 메소드의 validation_split 옵션에 테스트 데이터셋 비율을 입력하면 됨  \n",
    "  \n",
    "마지막 200번째 에포크 학습이 끝났을 때 훈련 손실이 검증 손실보다 작은 값이므로 과대적합 상태로 판단됨.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=build_model(num_input=13)\n",
    "# history=model.fit(X_train,y_train,batch_size=32,epochs=200,validation_split=0.25,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "훈련 손실(loss)과 검증 손실(val_loss)을 그래프로 나타냄  \n",
    "  \n",
    "가로축에는 에포크(epoch)를 놓고 세로축에 손실 함수 값을 표시함  \n",
    "  \n",
    "모델 10에포크까지 매우 빠른 속도로 학습이 되고, 이후 점차 완만하게 학습 속도가 낮아지며  \n",
    "그래프가 평평해지는 추이를 보임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_loss_curve(total_epoch=10,start=1):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['loss'][start-1:total_epoch],\n",
    "#             label='Train')\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['val_loss'][start-1:total_epoch],\n",
    "#             label='Validation')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('mse')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_loss_curve(total_epoch=200,start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "20에포크 이후의 손실 함수를 그림  \n",
    "  \n",
    "앞의 그래프에서는 훈련 손실과 검증 손실 간에 차이가 드러나지 않았지만,\n",
    "다음의 그래프를 보면 40에포크 이후 과대적합이 커지는 것을 볼 수 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_curve(total_epoch=200,start=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 딥러닝을 활용한 분류 예측 : 와인 품질 등급 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print(\"시드 고정:\",SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=pd.read_csv('./output/data/wine/train.csv')\n",
    "# test=pd.read_csv('./output/data/wine/test.csv')\n",
    "# submission=pd.read_csv('./output/data/wine/sample_submission.csv')\n",
    "\n",
    "# print(train.shape,test.shape,submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train 데이터의 내용을 살펴봄, 목표 변수는 와인 품질을 나타내는 quality 열임.\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일의 양식을 보면 와인 품질을 나타내는 quality 열에 예측값을 입력해야 함.\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type 열의 데이터를 살펴봄, 화이트 와인(white)이 4159개, 레드와인(red)이 1338개\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "type 열의 범주형 데이터는 문자열 값을 가짐  \n",
    "  \n",
    "모델 학습에 입력하려면 숫자형 데이터로 변환해야 함  \n",
    "  \n",
    "화이트 와인을 나타내는 'white' 문자열을 숫자 1로 바꾸고,  \n",
    "레드 와인을 나타내는 'red' 문자열을 숫자 0으로 변환함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['type']=np.where(train['type']=='white',1,0).astype(int)\n",
    "# test['type']=np.where(test['type']=='white',1,0).astype(int)\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이번에는 목표 변수인 quality 열의 데이터 개수를 확인함, 6등급 와인의 개수가 가장 많음.\n",
    "\n",
    "# train['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "목표 변수는 연속형 숫자 데이터가 아니라, 와인 등급을 나타내는 범주형 데이터임  \n",
    "  \n",
    "케라스 to_categorical 함수를 이용하여 목표 변수를 원핫 인코딩 변환함.  \n",
    "  \n",
    "원핫 인코딩을 하기 전에 숫자 3을 차감하여 와인 등급을 0~6 범위로 바꿈  \n",
    "  \n",
    "와인 등급은 3~9까지 모두 7개 클래스로 구분되는데, 3~9 범위 값으로 원핫 인코딩을 하면  \n",
    "숫자 0부터 최대값인 9까지 10개 클래스로 인식하기 때문임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_train=to_categorical(train.loc[:,'quality']-3)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델 학습에 사용할 피처를 선택하고, MinMax 스케일링으로 모든 피처 변수의 데이터를 0~1 범위로  \n",
    "정규화 변환함.  \n",
    "  \n",
    "이때 훈련 데이터(X_train)로 정규화 학습을 하고, 같은 조건을 검증 데이터(X_test)에 적용하여 변환하는 점에 유의함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 피처 선택\n",
    "# X_train=train.loc[:,'fixed acidity':]\n",
    "# X_test=test.loc[:,'fixed acidity':]\n",
    "\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaler.fit(X_train)\n",
    "# X_train_scaled=scaler.fit_transform(X_train)\n",
    "# X_test_scaled=scaler.fit_transform(X_test)\n",
    "\n",
    "# print(X_train_scaled.shape,y_train.shape)\n",
    "# print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 설계 : 드랍아웃 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결 레이어(Dense) 4개 층으로 구성되는 신경망 모델을 구성함  \n",
    "  \n",
    "모델의 과대적합을 방지하기 위하여 드랍아웃(Dropout) 레이어를 추가함  \n",
    "  \n",
    "드랍아웃은 입력 레이어왕 은닉 레이어 간의 연결 중 일부를 랜덤으로 제거한 상태에서 학습하는 기법임  \n",
    "  \n",
    "결과적으로 유닛 사이에 연결된 가중치 수를 줄이는 효과를 얻기 때문에 과대적합을 방지 가능.  \n",
    "  \n",
    "  \n",
    "미니 배치 단위로 학습할 때마다 연결 네트워크에서 제거되는 가중치가 달라짐,  \n",
    "때문에 매번 다른 네트워크 구조를 갖는 모델을 얻게 됨  \n",
    "  \n",
    "즉, 앙상블 효과가 있어 모델 성능이 개선됨  \n",
    "  \n",
    "  \n",
    "Dense 레이어 뒤에 Dropout 레이어를 추가하고, dropout rate를 설정함  \n",
    "  \n",
    "0.2로 설정하면 20% 확률로 랜덤하게 연결을 제거하게 됨  \n",
    "  \n",
    "은닉 레이어의 활성화 함수로 tanh를 사용해 봄  \n",
    "  \n",
    "다중 분류 모델이므로 마지막 출력 레이어의 활성화 함수는 softmax를 적용함  \n",
    "  \n",
    "옵티마이저는 RMSProp, 손실 함수는 categorical_crossentropy를 지정함  \n",
    "  \n",
    "metrics 옵션에 여러 개의 보조 평가 지표를 입력할 수 있음  \n",
    "  \n",
    "여기서는 acc(정확도)와 mae(평균절대값오차)를 지정함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망 모델\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "# def build_model(train_data,train_target):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='tanh',input_dim=train_data.shape[1]))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(64,activation='tanh'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(32,activation='tanh'))\n",
    "#     model.add(Dense(train_target.shape[1],activation='softmax'))\n",
    "\n",
    "#     model.compile(optimizer='RMSProp',loss='categorical_crossentropy',metrics=['acc','mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(X_train_scaled,y_train)\n",
    "# model.summary()\n",
    "\n",
    "# # tanh 함수는 -1~+1 사이의 출력 범위를 가짐\n",
    "# # 입력값이 0 근처일 때는 학습율이 좋지만,\n",
    "# # 입력값이 커지거나 작아지는 경우 기울기(가중치)가 0에 가까워지므로\n",
    "# # 학습이 이루어지지 않는 문제가 생김.\n",
    "\n",
    "# # 따라서 ReLU 함수에 비해 사용빈도가 낮음 편임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 콜백 함수 : Early Stopping 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "콜백(callback) 함수를 사용하면 모델 학습 과정을 세밀하게 컨트롤할 수 있음.  \n",
    "  \n",
    "가장 많이 사용되는 방법 중에 Early Stopping이 있음.  \n",
    "  \n",
    "딥러닝 모델 학습에서 에포크 수를 늘려 학습을 계속 반복하면 훈련 데이터에 대한 오차(손실 함수)  \n",
    "를 계속 낮출 수 있음.  \n",
    "  \n",
    "하지만 과대적합을 일으켜 테스트 데이터를 포함한 새로운 데이터에 대한 예측력이 나빠지는 문제가 발생함.  \n",
    "  \n",
    "이때 Early Stopping을 사용하면 과대적합이 발생하기 직전에 학습을 멈출 수 있음.  \n",
    "  \n",
    "홀드아웃으로 검증 데이터를 분할하고, 검증 데이터에 대한 모델 성능이 일정 에포크 동안 좋아지지 않으면  \n",
    "모델 학습을 중단함.  \n",
    "  \n",
    "이때 허용되는 에포크 수를 patience 옵션에 설정함.  \n",
    "  \n",
    "다음의 예제는 200에포크로 설정되어 있지만, 학습 중 10에포크 동안 연속하여  \n",
    "검증 데이터에 대한 손실 함수(val_loss)가 줄어들지 않으면 학습을 멈춤.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early Stopping 기법\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# X_tr,X_val,y_tr,y_val=train_test_split(X_train_scaled,y_train,test_size=0.15,shuffle=True,random_state=SEED)\n",
    "\n",
    "# early_stopping=EarlyStopping(monitor='val_loss',patience=10)\n",
    "# history=model.fit(X_tr,y_tr,batch_size=64,epochs=200,validation_data=(X_val,y_val),callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "Early Stopping으로 학습을 멈추면 모델은 학습이 중지된 상태의 가중치로 고정됨  \n",
    "  \n",
    "검증 데이터에 대한 모델 성능을 evaluate 함수로 평가하면 앞의 실행 결과에서 54에포크가 종료된 상태에서의  \n",
    "  \n",
    "평가 지표 값(val_loss,val_acc,val_mae)과 동일하다는 것을 알 수 있음  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 예측값 정리 및 파일 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "테스트 데이터를 predict 함수에 입력하면 목표 변수의 각 클래스에 대한 확률값을 반환함  \n",
    "  \n",
    "다중 분류 문제로 마지막 레이어의 활성화 함수를 softmax로 사용했기 때문.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test 데이터에 대한 예측값 정리\n",
    "# y_pred_proba=model.predict(X_test)\n",
    "# y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "앞에서 출력한 첫 번째 원소를 보면 7개 클래스에 대한 예측 확률값이 순서대로 표시되어 있음  \n",
    "  \n",
    "4번째 원소(클래스 3)의 확률값이 가장 높으며,  \n",
    "넘파이 argmax 함수를 사용하면 가장 값이 큰 원소의 인덱스 값을 얻을 수 있음.  \n",
    "  \n",
    "따라서 7개 확률값 중에서 가장 큰 원소가 있는 인덱스 3을 출력함.  \n",
    "  \n",
    "  \n",
    "하지만 모델이 예측한 값을 그대로 제출하면 안 됨  \n",
    "  \n",
    "데이터 전처리를 할 때 목표 변수의 값에서 3을 차감했기 때문  \n",
    "  \n",
    "모델 예측값에 3을 더하면 목표 레이블 값을 복원할 수 있음  \n",
    "  \n",
    "따라서 첫 번째 테스트 샘플에 대한 예측값은 6이 됨.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_label=np.argmax(y_pred_proba,axis=-1)+3\n",
    "# y_pred_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 양식에 맞게 정리\n",
    "# submission['quality']=y_pred_label.astype(int)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일 저장\n",
    "# submission.to_csv('output/data/wine/wine_dnn_002.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# print('Number of rows and columns:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['lightning','condition','datetime','HI','DI'], axis=1, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['test']=str(df['year'])+'-'+str(df['month'])+'-'+str(df['day'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['year','month','day'],axis=1,inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Onehot Encoding\n",
    "# df['hour']=df['hour'].astype('category')\n",
    "# df=pd.get_dummies(df,columns=['hour'],prefix='H',drop_first=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_27=df[df['region']==27]\n",
    "# df_27=df_27.reset_index(drop=True)\n",
    "# df_27.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10=df[df['region']==10]\n",
    "# df_10=df_10.reset_index(drop=True)\n",
    "# df_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_01=df_10[pd.DatetimeIndex(df_10['date']).year<=2019]\n",
    "# df_10_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "# X_train_scaled=X_train.loc[:,'temp':]\n",
    "# X_test_scaled=X_test.loc[:,'temp':]\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train_scaled.values)\n",
    "# X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "# X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in test_data.take(1):\n",
    "#     inputs,targets=batch\n",
    "\n",
    "# print(\"Input:\",inputs.numpy().shape)\n",
    "# print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8m=df[(df['month']==8)]\n",
    "# df_8m_10r=df_8m[df_8m['region']==10]\n",
    "\n",
    "# df_7m=df[(df['month']==7)]\n",
    "# df_7m_10r=df_7m[df_7m['region']==10]\n",
    "\n",
    "# df_6m=df[(df['month']==6)]\n",
    "# df_6m_10r=df_6m[df_6m['region']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_8m=df_8m_10r['datetime'].to_list() \n",
    "# xs_7m=df_7m_10r['datetime'].to_list()\n",
    "# xs_6m=df_6m_10r['datetime'].to_list()\n",
    "\n",
    "# ys_8m=df_8m_10r['temp'].to_list()\n",
    "# ys_7m=df_7m_10r['temp'].to_list()\n",
    "# ys_6m=df_6m_10r['temp'].to_list()\n",
    "\n",
    "# plt.figure(figsize=(100, 8))\n",
    "\n",
    "# plt.plot(xs_8m, ys_8m, 'o-', ms=3, lw=1, label='8th month')\n",
    "# plt.plot(xs_7m, ys_7m, 'o-', ms=3, lw=1, label='7th month')\n",
    "# plt.plot(xs_6m, ys_6m, 'o-', ms=3, lw=1, label='6th month')\n",
    "# plt.ylim(0,40)\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Temp')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 라이브러리 및 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "# from keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf=pd.read_csv('output/DL_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 전처리\n",
    "#### by KMJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (14831616, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>...</th>\n",
       "      <th>가로등</th>\n",
       "      <th>교육용</th>\n",
       "      <th>농사용</th>\n",
       "      <th>산업용</th>\n",
       "      <th>심야</th>\n",
       "      <th>일반용</th>\n",
       "      <th>임시전력</th>\n",
       "      <th>주택용</th>\n",
       "      <th>prev_winter</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-06-01 00:00:00</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-01 01:00:00</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-06-01 02:00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour             datetime  temp  rainfall  humidity  \\\n",
       "0  2010      6    1     0  2010-06-01 00:00:00  16.5       0.0      53.0   \n",
       "1  2010      6    1     1  2010-06-01 01:00:00  18.1       0.0      49.0   \n",
       "2  2010      6    1     2  2010-06-01 02:00:00  19.7       0.0      46.0   \n",
       "\n",
       "   wind_speed  wind_direction  ...  가로등  교육용  농사용  산업용  심야  일반용  임시전력  주택용  \\\n",
       "0         NaN             NaN  ...  NaN  NaN  NaN  NaN NaN  NaN   NaN  NaN   \n",
       "1         NaN             NaN  ...  NaN  NaN  NaN  NaN NaN  NaN   NaN  NaN   \n",
       "2         NaN             NaN  ...  NaN  NaN  NaN  NaN NaN  NaN   NaN  NaN   \n",
       "\n",
       "   prev_winter       date  \n",
       "0          NaN 2010-06-01  \n",
       "1          NaN 2010-06-01  \n",
       "2          NaN 2010-06-01  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=rdf[:]\n",
    "print('Number of rows and columns:', df.shape)\n",
    "\n",
    "fact = pd.factorize(df['region'])\n",
    "df['region'] = fact[0]\n",
    "\n",
    "df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "      <th>HI</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104445</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>10.141667</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104446</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>11.498889</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104447</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>12.824444</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "104445 2022-04-30  11.5       0.0      55.0         1.0           313.0   \n",
       "104446 2022-04-30  12.9       0.0      48.0         1.0           311.0   \n",
       "104447 2022-04-30  14.2       0.0      44.0         1.2           157.0   \n",
       "\n",
       "        region  hour         HI  height  \n",
       "104445       0    21  10.141667   42.48  \n",
       "104446       0    22  11.498889   42.48  \n",
       "104447       0    23  12.824444   42.48  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 컬럼과 특정 동네 데이터만 가져옴\n",
    "dataset = df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour','HI','height']]\n",
    "dataset = dataset[dataset['region']==0]\n",
    "dataset.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 0\n",
       "temp                 0\n",
       "rainfall             0\n",
       "humidity             0\n",
       "wind_speed        4519\n",
       "wind_direction    4519\n",
       "region               0\n",
       "hour                 0\n",
       "HI                   0\n",
       "height               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리를 진행하기 위하여 복사본으로 작업\n",
    "predata = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              datetime64[ns]\n",
       "temp                     float64\n",
       "rainfall                 float64\n",
       "humidity                 float64\n",
       "wind_speed               float64\n",
       "wind_direction           float64\n",
       "region                     int64\n",
       "hour                       int64\n",
       "HI                       float64\n",
       "height                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풍향이 360도이면 0도로 수정\n",
    "for i in range(len(predata)) :\n",
    "    if predata.loc[i,'wind_direction'] == -1:\n",
    "        predata.loc[i,'wind_direction'] = np.nan\n",
    "    elif predata.loc[i,'wind_direction'] == 360:\n",
    "        predata.loc[i,'wind_direction'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "temp              0\n",
       "rainfall          0\n",
       "humidity          0\n",
       "wind_speed        0\n",
       "wind_direction    0\n",
       "region            0\n",
       "hour              0\n",
       "HI                0\n",
       "height            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepoll = predata.copy()\n",
    "prepoll.dropna(inplace=True)\n",
    "prepoll.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "      <th>HI</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.651111</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.629444</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.880556</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temp  rainfall  humidity  wind_speed  wind_direction  region  \\\n",
       "0 2010-12-06  11.6       0.0      32.0         4.1           304.0       0   \n",
       "1 2010-12-06  10.6       0.0      35.0         3.6           300.0       0   \n",
       "2 2010-12-06   9.2       0.0      27.0         3.8           295.0       0   \n",
       "\n",
       "   hour        HI  height  \n",
       "0     7  9.651111   42.48  \n",
       "1     8  8.629444   42.48  \n",
       "2     9  6.880556   42.48  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepoll = prepoll.reset_index(drop=True)\n",
    "prepoll.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99604"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepoll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝\n",
    "### 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56999, 9) (56999, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setting\n",
    "train_split_idx=60000                 # 시작 행 인덱스의 번호\n",
    "window_size=3000                       # 과거 3000시간 동안 시계열 데이터를 학습 데이터로 사용 / 하이퍼파라미터\n",
    "future=1                              # 1시간 이후의 타깃 예측\n",
    "\n",
    "# Features\n",
    "X_train=prepoll.iloc[:train_split_idx-window_size-future,0:]\n",
    "X_train.drop('temp', axis=1, inplace=True) # 'temp' 열을 제외한 나머지 컬럼이 feature\n",
    "\n",
    "# Targets\n",
    "y_train=prepoll.iloc[window_size+future:train_split_idx,[1]]  # 'temp' 열\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "      <th>HI</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>2017-10-22</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.816667</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60000</th>\n",
       "      <td>2017-10-22</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.786111</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60001</th>\n",
       "      <td>2017-10-22</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.242778</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "59999 2017-10-22  19.6       0.0      46.0         4.0            41.0   \n",
       "60000 2017-10-22  20.6       0.0      41.0         5.5            55.0   \n",
       "60001 2017-10-22  21.3       0.0      29.0         6.9            59.0   \n",
       "\n",
       "       region  hour         HI  height  \n",
       "59999       0     0  18.816667   42.48  \n",
       "60000       0     1  19.786111   42.48  \n",
       "60001       0     2  20.242778   42.48  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepoll.iloc[[train_split_idx-1,train_split_idx,train_split_idx+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39604, 9) (39604, 1)\n"
     ]
    }
   ],
   "source": [
    "# X_test\n",
    "test_start=train_split_idx-window_size-future   # 테스트 데이터 시작 행\n",
    "test_end=prepoll.shape[0]-window_size-future\n",
    "X_test=prepoll.iloc[test_start:test_end,0:]\n",
    "X_test.drop('temp', axis=1, inplace=True)\n",
    "\n",
    "# y_test\n",
    "# label_start= +future        # 테스트 데이터의 첫 번째 타깃 데이터 위치\n",
    "y_test=prepoll.iloc[train_split_idx:,[1]]    # 'temp' 열 선택\n",
    "\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력 데이터 0~1로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "X_train_scaled=X_train.loc[:,'rainfall':]\n",
    "X_test_scaled=X_test.loc[:,'rainfall':]\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train_scaled.values)\n",
    "X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled =tf.convert_to_tensor(X_train_scaled, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_test_scaled = tf.convert_to_tensor(X_test_scaled, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 사이즈 조정 - 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch 크기로 시계열 변환\n",
    "train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=8)\n",
    "test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=8)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (배치사이즈, 타임스텝, 컬럼수-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (8, 3000, 8)\n",
      "Target: (8, 1)\n"
     ]
    }
   ],
   "source": [
    "for batch in test_data.take(1):\n",
    "    inputs,targets=batch\n",
    "\n",
    "print(\"Input:\",inputs.numpy().shape)\n",
    "print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3000, 8), dtype=float32, numpy=\n",
       "array([[0.        , 0.3877551 , 0.11666667, ..., 0.        , 0.75008065,\n",
       "        0.        ],\n",
       "       [0.        , 0.3265306 , 0.14166667, ..., 0.04347826, 0.776659  ,\n",
       "        0.        ],\n",
       "       [0.        , 0.19387755, 0.16666667, ..., 0.08695652, 0.7733417 ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.8061224 , 0.05833333, ..., 0.9130435 , 0.4436712 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.7244898 , 0.09166667, ..., 0.95652175, 0.49605158,\n",
       "        0.        ],\n",
       "       [0.        , 0.53061223, 0.225     , ..., 1.        , 0.5337213 ,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([20.6], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3층 레이어 / 하이퍼파라미터, unit-하이퍼파라미터\n",
    "#### mae 값 0.5 이하일 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 32)                5248      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,793\n",
      "Trainable params: 5,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[3000,8])) # 행열 사이즈\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 9.7599 - mse: 127.9443\n",
      "Epoch 1: val_loss improved from inf to 8.62236, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 844s 998ms/step - loss: 9.7599 - mse: 127.9443 - val_loss: 8.6224 - val_mse: 102.9531\n",
      "Epoch 2/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 9.0834 - mse: 111.1919\n",
      "Epoch 2: val_loss improved from 8.62236 to 8.52403, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 1047s 1s/step - loss: 9.0834 - mse: 111.1919 - val_loss: 8.5240 - val_mse: 100.2025\n",
      "Epoch 3/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 9.0122 - mse: 109.7418\n",
      "Epoch 3: val_loss improved from 8.52403 to 8.38819, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 1024s 1s/step - loss: 9.0122 - mse: 109.7418 - val_loss: 8.3882 - val_mse: 96.9484\n",
      "Epoch 4/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 8.7995 - mse: 104.6376\n",
      "Epoch 4: val_loss improved from 8.38819 to 8.11339, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 1005s 1s/step - loss: 8.7995 - mse: 104.6376 - val_loss: 8.1134 - val_mse: 90.8316\n",
      "Epoch 5/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 8.3327 - mse: 93.6132\n",
      "Epoch 5: val_loss improved from 8.11339 to 7.64497, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 937s 1s/step - loss: 8.3327 - mse: 93.6132 - val_loss: 7.6450 - val_mse: 80.9482\n",
      "Epoch 6/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 7.5993 - mse: 77.7793\n",
      "Epoch 6: val_loss improved from 7.64497 to 7.17664, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 1013s 1s/step - loss: 7.5993 - mse: 77.7793 - val_loss: 7.1766 - val_mse: 71.3931\n",
      "Epoch 7/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 6.8562 - mse: 63.8298\n",
      "Epoch 7: val_loss improved from 7.17664 to 6.43769, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 962s 1s/step - loss: 6.8562 - mse: 63.8298 - val_loss: 6.4377 - val_mse: 57.4245\n",
      "Epoch 8/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 5.6154 - mse: 43.7913\n",
      "Epoch 8: val_loss improved from 6.43769 to 5.41003, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 966s 1s/step - loss: 5.6154 - mse: 43.7913 - val_loss: 5.4100 - val_mse: 41.5004\n",
      "Epoch 9/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 4.2426 - mse: 26.2056\n",
      "Epoch 9: val_loss improved from 5.41003 to 4.74002, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 913s 1s/step - loss: 4.2426 - mse: 26.2056 - val_loss: 4.7400 - val_mse: 32.6061\n",
      "Epoch 10/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 3.5617 - mse: 19.0200\n",
      "Epoch 10: val_loss improved from 4.74002 to 4.42284, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 933s 1s/step - loss: 3.5617 - mse: 19.0200 - val_loss: 4.4228 - val_mse: 28.2310\n",
      "Epoch 11/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 3.1777 - mse: 15.3012\n",
      "Epoch 11: val_loss improved from 4.42284 to 4.20384, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 928s 1s/step - loss: 3.1777 - mse: 15.3012 - val_loss: 4.2038 - val_mse: 25.1522\n",
      "Epoch 12/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 2.8503 - mse: 12.3983\n",
      "Epoch 12: val_loss improved from 4.20384 to 4.04642, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 926s 1s/step - loss: 2.8503 - mse: 12.3983 - val_loss: 4.0464 - val_mse: 22.8920\n",
      "Epoch 13/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 2.5885 - mse: 10.2847\n",
      "Epoch 13: val_loss improved from 4.04642 to 3.83406, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 948s 1s/step - loss: 2.5885 - mse: 10.2847 - val_loss: 3.8341 - val_mse: 20.3447\n",
      "Epoch 14/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 2.3553 - mse: 8.5883\n",
      "Epoch 14: val_loss improved from 3.83406 to 3.69490, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 977s 1s/step - loss: 2.3553 - mse: 8.5883 - val_loss: 3.6949 - val_mse: 18.7502\n",
      "Epoch 15/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 2.1635 - mse: 7.3224\n",
      "Epoch 15: val_loss improved from 3.69490 to 3.57266, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 934s 1s/step - loss: 2.1635 - mse: 7.3224 - val_loss: 3.5727 - val_mse: 17.4621\n",
      "Epoch 16/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.9651 - mse: 6.1301\n",
      "Epoch 16: val_loss improved from 3.57266 to 3.46244, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 931s 1s/step - loss: 1.9651 - mse: 6.1301 - val_loss: 3.4624 - val_mse: 16.5396\n",
      "Epoch 17/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.7961 - mse: 5.1906\n",
      "Epoch 17: val_loss improved from 3.46244 to 3.35964, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 882s 1s/step - loss: 1.7961 - mse: 5.1906 - val_loss: 3.3596 - val_mse: 15.8301\n",
      "Epoch 18/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.6376 - mse: 4.3698\n",
      "Epoch 18: val_loss improved from 3.35964 to 3.23787, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 872s 1s/step - loss: 1.6376 - mse: 4.3698 - val_loss: 3.2379 - val_mse: 14.6659\n",
      "Epoch 19/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.5766 - mse: 4.0642\n",
      "Epoch 19: val_loss improved from 3.23787 to 3.16982, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 872s 1s/step - loss: 1.5766 - mse: 4.0642 - val_loss: 3.1698 - val_mse: 14.0085\n",
      "Epoch 20/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.5187 - mse: 3.7881\n",
      "Epoch 20: val_loss improved from 3.16982 to 3.04403, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 877s 1s/step - loss: 1.5187 - mse: 3.7881 - val_loss: 3.0440 - val_mse: 12.8642\n",
      "Epoch 21/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.4390 - mse: 3.4215\n",
      "Epoch 21: val_loss improved from 3.04403 to 2.94656, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 874s 1s/step - loss: 1.4390 - mse: 3.4215 - val_loss: 2.9466 - val_mse: 12.0358\n",
      "Epoch 22/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.3800 - mse: 3.1608\n",
      "Epoch 22: val_loss improved from 2.94656 to 2.87590, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 875s 1s/step - loss: 1.3800 - mse: 3.1608 - val_loss: 2.8759 - val_mse: 11.4892\n",
      "Epoch 23/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.3286 - mse: 2.9466\n",
      "Epoch 23: val_loss improved from 2.87590 to 2.81484, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 827s 980ms/step - loss: 1.3286 - mse: 2.9466 - val_loss: 2.8148 - val_mse: 10.9863\n",
      "Epoch 24/40\n",
      "844/844 [==============================] - ETA: 0s - loss: 1.2937 - mse: 2.7998\n",
      "Epoch 24: val_loss improved from 2.81484 to 2.75933, saving model to ./output/model\\origbest.h5\n",
      "844/844 [==============================] - 897s 1s/step - loss: 1.2937 - mse: 2.7998 - val_loss: 2.7593 - val_mse: 10.5566\n",
      "Epoch 25/40\n",
      " 36/844 [>.............................] - ETA: 11:42 - loss: 2.0231 - mse: 5.6636"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\github\\Team_Project\\prototype_KMJ.ipynb Cell 121'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/Team_Project/prototype_KMJ.ipynb#ch0000120?line=0'>1</a>\u001b[0m \u001b[39m# 모델 훈련\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/github/Team_Project/prototype_KMJ.ipynb#ch0000120?line=1'>2</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(train_data,epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49mtest_data,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(filepath\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./output/model/origbest.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/Team_Project/prototype_KMJ.ipynb#ch0000120?line=2'>3</a>\u001b[0m \u001b[39m# 최종 모델 저장\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/github/Team_Project/prototype_KMJ.ipynb#ch0000120?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m./output/model/origmodel.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1401'>1402</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1402'>1403</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1403'>1404</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1404'>1405</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1405'>1406</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1406'>1407</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1407'>1408</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1408'>1409</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1409'>1410</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1410'>1411</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2449'>2450</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2450'>2451</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2451'>2452</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2452'>2453</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2453'>2454</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1859'>1860</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1860'>1861</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1861'>1862</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1862'>1863</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1863'>1864</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1864'>1865</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1865'>1866</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=494'>495</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=495'>496</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=508'>509</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=509'>510</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "# callback : 가장 성능이 좋은 모델만 저장\n",
    "history=model.fit(train_data,epochs=40,validation_data=test_data,verbose=1,callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath='./output/model/origbest.h5', save_best_only=True, verbose=1)])\n",
    "# epoch 전체 실행 후 최종 모델 저장\n",
    "model.save('./output/model/origmodel.h5')\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=50,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 재훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 286s 67ms/step - loss: 1.3174 - mse: 2.9375\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 32)                5248      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,793\n",
      "Trainable params: 5,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 초기에 저장한 최종 모델 복원, 요약\n",
    "loaded_model = tf.keras.models.load_model('./output/model/trained.h5')\n",
    "loaded_model.evaluate(train_data)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 3.3066 - mse: 18.1604\n",
      "Epoch 1: val_loss improved from inf to 7.60117, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1119s 263ms/step - loss: 3.3066 - mse: 18.1604 - val_loss: 7.6012 - val_mse: 77.7889\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 2.3890 - mse: 9.7686\n",
      "Epoch 2: val_loss improved from 7.60117 to 6.11611, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1144s 269ms/step - loss: 2.3890 - mse: 9.7686 - val_loss: 6.1161 - val_mse: 51.2813\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 1.6546 - mse: 4.5272\n",
      "Epoch 3: val_loss improved from 6.11611 to 3.19971, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1052s 247ms/step - loss: 1.6546 - mse: 4.5272 - val_loss: 3.1997 - val_mse: 14.4847\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 1.1382 - mse: 2.1844\n",
      "Epoch 4: val_loss improved from 3.19971 to 1.85366, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1056s 248ms/step - loss: 1.1382 - mse: 2.1844 - val_loss: 1.8537 - val_mse: 5.2788\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.9266 - mse: 1.4970\n",
      "Epoch 5: val_loss improved from 1.85366 to 1.41763, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1188s 280ms/step - loss: 0.9266 - mse: 1.4970 - val_loss: 1.4176 - val_mse: 3.2054\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.8573 - mse: 1.3052\n",
      "Epoch 6: val_loss improved from 1.41763 to 1.26560, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1071s 252ms/step - loss: 0.8573 - mse: 1.3052 - val_loss: 1.2656 - val_mse: 2.6478\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.8221 - mse: 1.2201\n",
      "Epoch 7: val_loss improved from 1.26560 to 1.23089, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1101s 259ms/step - loss: 0.8221 - mse: 1.2201 - val_loss: 1.2309 - val_mse: 2.5302\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.7975 - mse: 1.1600\n",
      "Epoch 8: val_loss improved from 1.23089 to 1.19634, saving model to ./output/model\\trained.h5\n",
      "4250/4250 [==============================] - 1278s 301ms/step - loss: 0.7975 - mse: 1.1600 - val_loss: 1.1963 - val_mse: 2.4176\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.7809 - mse: 1.1204\n",
      "Epoch 9: val_loss did not improve from 1.19634\n",
      "4250/4250 [==============================] - 1175s 276ms/step - loss: 0.7809 - mse: 1.1204 - val_loss: 1.2270 - val_mse: 2.5329\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.7691 - mse: 1.0919\n",
      "Epoch 10: val_loss did not improve from 1.19634\n",
      "4250/4250 [==============================] - 1169s 275ms/step - loss: 0.7691 - mse: 1.0919 - val_loss: 1.2281 - val_mse: 2.5334\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 재훈련\n",
    "history=loaded_model.fit(train_data,epochs=10,validation_data=test_data,verbose=1,callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath='./output/model/trained.h5', save_best_only=True, verbose=1)])\n",
    "\n",
    "# 최종 모델 저장\n",
    "loaded_model.save('./output/model/backup.h5')\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=50,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 데이터로 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('./output/model/trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 316832 values, but the requested shape has 24000 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\github\\Team_Project\\prototype_KMJ.ipynb Cell 132'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/github/Team_Project/prototype_KMJ.ipynb#ch0000139?line=0'>1</a>\u001b[0m tf\u001b[39m.\u001b[39;49mreshape(X_test_scaled, [\u001b[39m3000\u001b[39;49m, \u001b[39m8\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\github\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/github/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 316832 values, but the requested shape has 24000 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "tf.reshape(X_test_scaled, [3000, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238/1238 [==============================] - 1s 840us/step - loss: 14.2854 - mse: 288.9476\n",
      "오차:  288.94757080078125\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = loaded_model.evaluate(X_test_scaled, y_test)\n",
    "print('오차: ', test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a361ab2d5bcaf6ce52bdf68136849a2f83cd149430793ce39e0b5f62eae2684c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
