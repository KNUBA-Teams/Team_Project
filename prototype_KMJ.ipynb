{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 더미 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import tensorflow as tf\n",
    "print(tf.__version__) # .__version__ 속성으로 버전을 확인함\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 간단한 딥러닝 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용할 입력 데이터를 준비함.\n",
    "# # y=x+1 관계를 갖는 숫자를 x,y 변수에 각각 10개씩 입력함.\n",
    "# # 이 때, x변수의 숫자 배열을 (10행 1열) 형태의 2차원 배열로 변환함.\n",
    "# x=[-3,31,-11,4,0,22,-2,-5,-25,-14]\n",
    "# y=[-2,32,-10,5,1,23,-1,-4,-24,-13]\n",
    "\n",
    "# X_train=np.array(x).reshape(-1,1)\n",
    "# y_train=np.array(y)\n",
    "\n",
    "# print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "케라스 Sequential API는 레이어 여러 개를 연결하여 신경망 모델을 구성하는 도구이다.  \n",
    "  \n",
    "간단한 아키텍처를 가지면서도 대부분의 딥러닝 모델을 만들 수 있다는 장점이 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential() # Sequential 모델 인스턴스를 생성함\n",
    "\n",
    "\n",
    "# # add 메소드를 사용하여 완전 연결 레이어(Dense)를 모델에 추가함.\n",
    "\n",
    "# # 입력 데이터의 차원(input_dim)은 모델 학습에 사용하는 설명 변수(피처)의 개수를 지정하는데,\n",
    "# # 여기서는 1개의 피처를 사용하므로 1로 설정함.\n",
    "\n",
    "# # 완전 연결 레이어의 출력값은 목표 레이블(Y)을 예측함\n",
    "# # 한 개의 연속성 수치(ex.주택 가격)를 예측하는 회귀 문제이므로 유닛(unit) 개수는 1임\n",
    "# # 활성화(activation) 함수로 'linear' 옵션을 지정하여 선형 함수의 출력을 그대로 사용함.\n",
    "# model.add(Dense(units=1,activation='linear',input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summary 메소드를 이용하여 모델 아키텍처(구조)를 확인함\n",
    "# # 딥러닝 모델이 학습할 모수(파라미터:Param #)는 2개인데,\n",
    "# # 일차함수의 기울기(회귀계수)와 절편(상수항)임.\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델이 훈련하는데 필요한 기본 설정을 compile 함수에 지정하는데,\n",
    "# # 옵티마이저(optimizer)와 손실 함수(loss)를 설정함.\n",
    "\n",
    "# # adam 옵티마이저를 선택하고 회귀 분석의 손실 함수인 평균제곱오차(mse)를 지정함.\n",
    "\n",
    "# # metrics 옵션에 보조 평가 지표를 추가할 수 있는데,\n",
    "# # 여기서는 평균절대오차(mae)를 추가하여 손실 함수를 모니터링할 때 함께 추적하기로 함.\n",
    "# model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit 메소드에 훈련 데이터를 입력하여 모델을 학습시키는데,\n",
    "# # 컴파일 단계에서 설정한 adam 옵티마이저와 mse 손실 함수를 가지고 최적의 가중치와 편향을 찾음.\n",
    "\n",
    "# # 에포크(epoch)는 전체 입력 데이터를 모두 몇 번 학습할 것인지 반복 횟수를 정함.\n",
    "\n",
    "# # verbose 옵션을 False(0)로 지정하면 훈련 과정을 화면에 보여주지 않는데,\n",
    "# # 훈련 과정을 표시하려면 1 또는 2를 입력함.\n",
    "# model.fit(X_train,y_train,epochs=3000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습을 마친 딥러닝 모델의 가중치를 확인하려면 weights 속성을 보면 됨\n",
    "# # 기울기에 해당하는 가중치(kernel:0)와 절편에 해당하는 편향(bias:0) 모두 1에 가까운 값을 가지는데,\n",
    "# # 이는 모델 학습을 통해 일차함수 관계식을 매우 근사하게 찾아낸 것으로 볼 수 있다.\n",
    "# model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트 데이터(X)를 predict 메소드에 입력하면 목표 레이블(Y)에 대한 예측값을 얻을 수 있음.\n",
    "# model.predict([[11],[12],[13]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 딥러닝을 활용한 회귀 분석 : 보스턴 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print('시드 고정:',SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sklearn 데이터셋에서 보스턴 주택 데이터셋 로딩\n",
    "# from sklearn import datasets\n",
    "# housing=datasets.load_boston()\n",
    "# X_data=housing.data\n",
    "# y_data=housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_data.shape,y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "입력 데이터의 서로 다른 피처 값의 범위를 비슷한 크기로 맞춰 주면 딥러닝 모델의 성능을 확보하는데 유리한데,  \n",
    "  \n",
    "이것을 피처 스케일링이라고 부름.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MinMaxScaler를 사용하여 입력 데이터(X_data)의 모든 피처 값을 0~1 범위로 정규화 처리함.\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# X_data_scaled=scaler.fit_transform(X_data)\n",
    "\n",
    "# X_data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용하기 위하여 훈련 데이터(80%)와 검증 데이터(20%)를 분할함.\n",
    "# # 학습 - 테스트 데이터셋 분할\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X_data,y_data,test_size=0.2,shuffle=True,random_state=SEED)\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MLP 모델 아키텍처 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결(Dense) 레이어만 사용하여 5개 레이어를 갖는 다층 신경망(MLP)을 만든다.  \n",
    "  \n",
    "레이어를 추가할 때는 add 함수를 사용한다.  \n",
    "  \n",
    "은닉 레이어 4개는 각각 128개, 64개, 32개, 16개의 유닛을 갖는다.  \n",
    "  \n",
    "입력 데이터의 피처가 13개이므로 첫 번째 Dense 레이어의 input_dim에 13을 지정한다.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망\n",
    "# def build_model(num_input=1):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='relu',input_dim=num_input))\n",
    "#     model.add(Dense(64,activation='relu'))\n",
    "#     model.add(Dense(32,activation='relu'))\n",
    "#     model.add(Dense(16,activation='relu'))\n",
    "#     model.add(Dense(1,activation='relu'))\n",
    "\n",
    "#     model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(num_input=13)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 미니 배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델을 훈련시킬 때 샘플 데이터를 한 개씩 입력해서 가중치를 갱신하려면 학습 시간이 오래 걸리는 문제가 있음.  \n",
    "  \n",
    "***미니 배치 학습***은 전체 데이터를 여러 개의 작은 배치 단위로 나누고 배치에 들어 있는 샘플 데이터를 묶어서 모델에 입력함.  \n",
    "  \n",
    "배치 단위로 경사하강법을 적용하고 손실 함수를 최소화하는 방향으로 가중치를 업데이트함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련\n",
    "# model.fit(X_train,y_train,epochs=100,batch_size=32,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "evaluate 함수에 테스트 데이터를 입력하여 모델의 일반화 성능을 평가함  \n",
    "  \n",
    "loss는 11.93이고 mae는 2.57임  \n",
    "  \n",
    "검증 손실이 훈련 손실보다 크기 때문에 과대적합으로 판단됨  \n",
    "  \n",
    "배치 크기에 따라 모델 성능이 달라질 수 있기 때문에 모델을 설계할 때 중요하게 고려해야 함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "학습 데이터 일부(여기서는 25%)를 검증 데이터를 사용하여 교차 검증을 해봄  \n",
    "  \n",
    "fit 메소드의 validation_split 옵션에 테스트 데이터셋 비율을 입력하면 됨  \n",
    "  \n",
    "마지막 200번째 에포크 학습이 끝났을 때 훈련 손실이 검증 손실보다 작은 값이므로 과대적합 상태로 판단됨.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=build_model(num_input=13)\n",
    "# history=model.fit(X_train,y_train,batch_size=32,epochs=200,validation_split=0.25,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "훈련 손실(loss)과 검증 손실(val_loss)을 그래프로 나타냄  \n",
    "  \n",
    "가로축에는 에포크(epoch)를 놓고 세로축에 손실 함수 값을 표시함  \n",
    "  \n",
    "모델 10에포크까지 매우 빠른 속도로 학습이 되고, 이후 점차 완만하게 학습 속도가 낮아지며  \n",
    "그래프가 평평해지는 추이를 보임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_loss_curve(total_epoch=10,start=1):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['loss'][start-1:total_epoch],\n",
    "#             label='Train')\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['val_loss'][start-1:total_epoch],\n",
    "#             label='Validation')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('mse')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_loss_curve(total_epoch=200,start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "20에포크 이후의 손실 함수를 그림  \n",
    "  \n",
    "앞의 그래프에서는 훈련 손실과 검증 손실 간에 차이가 드러나지 않았지만,\n",
    "다음의 그래프를 보면 40에포크 이후 과대적합이 커지는 것을 볼 수 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_curve(total_epoch=200,start=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 딥러닝을 활용한 분류 예측 : 와인 품질 등급 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print(\"시드 고정:\",SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=pd.read_csv('./output/data/wine/train.csv')\n",
    "# test=pd.read_csv('./output/data/wine/test.csv')\n",
    "# submission=pd.read_csv('./output/data/wine/sample_submission.csv')\n",
    "\n",
    "# print(train.shape,test.shape,submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train 데이터의 내용을 살펴봄, 목표 변수는 와인 품질을 나타내는 quality 열임.\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일의 양식을 보면 와인 품질을 나타내는 quality 열에 예측값을 입력해야 함.\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type 열의 데이터를 살펴봄, 화이트 와인(white)이 4159개, 레드와인(red)이 1338개\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "type 열의 범주형 데이터는 문자열 값을 가짐  \n",
    "  \n",
    "모델 학습에 입력하려면 숫자형 데이터로 변환해야 함  \n",
    "  \n",
    "화이트 와인을 나타내는 'white' 문자열을 숫자 1로 바꾸고,  \n",
    "레드 와인을 나타내는 'red' 문자열을 숫자 0으로 변환함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['type']=np.where(train['type']=='white',1,0).astype(int)\n",
    "# test['type']=np.where(test['type']=='white',1,0).astype(int)\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이번에는 목표 변수인 quality 열의 데이터 개수를 확인함, 6등급 와인의 개수가 가장 많음.\n",
    "\n",
    "# train['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "목표 변수는 연속형 숫자 데이터가 아니라, 와인 등급을 나타내는 범주형 데이터임  \n",
    "  \n",
    "케라스 to_categorical 함수를 이용하여 목표 변수를 원핫 인코딩 변환함.  \n",
    "  \n",
    "원핫 인코딩을 하기 전에 숫자 3을 차감하여 와인 등급을 0~6 범위로 바꿈  \n",
    "  \n",
    "와인 등급은 3~9까지 모두 7개 클래스로 구분되는데, 3~9 범위 값으로 원핫 인코딩을 하면  \n",
    "숫자 0부터 최대값인 9까지 10개 클래스로 인식하기 때문임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_train=to_categorical(train.loc[:,'quality']-3)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델 학습에 사용할 피처를 선택하고, MinMax 스케일링으로 모든 피처 변수의 데이터를 0~1 범위로  \n",
    "정규화 변환함.  \n",
    "  \n",
    "이때 훈련 데이터(X_train)로 정규화 학습을 하고, 같은 조건을 검증 데이터(X_test)에 적용하여 변환하는 점에 유의함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 피처 선택\n",
    "# X_train=train.loc[:,'fixed acidity':]\n",
    "# X_test=test.loc[:,'fixed acidity':]\n",
    "\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaler.fit(X_train)\n",
    "# X_train_scaled=scaler.fit_transform(X_train)\n",
    "# X_test_scaled=scaler.fit_transform(X_test)\n",
    "\n",
    "# print(X_train_scaled.shape,y_train.shape)\n",
    "# print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 설계 : 드랍아웃 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결 레이어(Dense) 4개 층으로 구성되는 신경망 모델을 구성함  \n",
    "  \n",
    "모델의 과대적합을 방지하기 위하여 드랍아웃(Dropout) 레이어를 추가함  \n",
    "  \n",
    "드랍아웃은 입력 레이어왕 은닉 레이어 간의 연결 중 일부를 랜덤으로 제거한 상태에서 학습하는 기법임  \n",
    "  \n",
    "결과적으로 유닛 사이에 연결된 가중치 수를 줄이는 효과를 얻기 때문에 과대적합을 방지 가능.  \n",
    "  \n",
    "  \n",
    "미니 배치 단위로 학습할 때마다 연결 네트워크에서 제거되는 가중치가 달라짐,  \n",
    "때문에 매번 다른 네트워크 구조를 갖는 모델을 얻게 됨  \n",
    "  \n",
    "즉, 앙상블 효과가 있어 모델 성능이 개선됨  \n",
    "  \n",
    "  \n",
    "Dense 레이어 뒤에 Dropout 레이어를 추가하고, dropout rate를 설정함  \n",
    "  \n",
    "0.2로 설정하면 20% 확률로 랜덤하게 연결을 제거하게 됨  \n",
    "  \n",
    "은닉 레이어의 활성화 함수로 tanh를 사용해 봄  \n",
    "  \n",
    "다중 분류 모델이므로 마지막 출력 레이어의 활성화 함수는 softmax를 적용함  \n",
    "  \n",
    "옵티마이저는 RMSProp, 손실 함수는 categorical_crossentropy를 지정함  \n",
    "  \n",
    "metrics 옵션에 여러 개의 보조 평가 지표를 입력할 수 있음  \n",
    "  \n",
    "여기서는 acc(정확도)와 mae(평균절대값오차)를 지정함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망 모델\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "# def build_model(train_data,train_target):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='tanh',input_dim=train_data.shape[1]))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(64,activation='tanh'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(32,activation='tanh'))\n",
    "#     model.add(Dense(train_target.shape[1],activation='softmax'))\n",
    "\n",
    "#     model.compile(optimizer='RMSProp',loss='categorical_crossentropy',metrics=['acc','mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(X_train_scaled,y_train)\n",
    "# model.summary()\n",
    "\n",
    "# # tanh 함수는 -1~+1 사이의 출력 범위를 가짐\n",
    "# # 입력값이 0 근처일 때는 학습율이 좋지만,\n",
    "# # 입력값이 커지거나 작아지는 경우 기울기(가중치)가 0에 가까워지므로\n",
    "# # 학습이 이루어지지 않는 문제가 생김.\n",
    "\n",
    "# # 따라서 ReLU 함수에 비해 사용빈도가 낮음 편임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 콜백 함수 : Early Stopping 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "콜백(callback) 함수를 사용하면 모델 학습 과정을 세밀하게 컨트롤할 수 있음.  \n",
    "  \n",
    "가장 많이 사용되는 방법 중에 Early Stopping이 있음.  \n",
    "  \n",
    "딥러닝 모델 학습에서 에포크 수를 늘려 학습을 계속 반복하면 훈련 데이터에 대한 오차(손실 함수)  \n",
    "를 계속 낮출 수 있음.  \n",
    "  \n",
    "하지만 과대적합을 일으켜 테스트 데이터를 포함한 새로운 데이터에 대한 예측력이 나빠지는 문제가 발생함.  \n",
    "  \n",
    "이때 Early Stopping을 사용하면 과대적합이 발생하기 직전에 학습을 멈출 수 있음.  \n",
    "  \n",
    "홀드아웃으로 검증 데이터를 분할하고, 검증 데이터에 대한 모델 성능이 일정 에포크 동안 좋아지지 않으면  \n",
    "모델 학습을 중단함.  \n",
    "  \n",
    "이때 허용되는 에포크 수를 patience 옵션에 설정함.  \n",
    "  \n",
    "다음의 예제는 200에포크로 설정되어 있지만, 학습 중 10에포크 동안 연속하여  \n",
    "검증 데이터에 대한 손실 함수(val_loss)가 줄어들지 않으면 학습을 멈춤.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early Stopping 기법\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# X_tr,X_val,y_tr,y_val=train_test_split(X_train_scaled,y_train,test_size=0.15,shuffle=True,random_state=SEED)\n",
    "\n",
    "# early_stopping=EarlyStopping(monitor='val_loss',patience=10)\n",
    "# history=model.fit(X_tr,y_tr,batch_size=64,epochs=200,validation_data=(X_val,y_val),callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "Early Stopping으로 학습을 멈추면 모델은 학습이 중지된 상태의 가중치로 고정됨  \n",
    "  \n",
    "검증 데이터에 대한 모델 성능을 evaluate 함수로 평가하면 앞의 실행 결과에서 54에포크가 종료된 상태에서의  \n",
    "  \n",
    "평가 지표 값(val_loss,val_acc,val_mae)과 동일하다는 것을 알 수 있음  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 예측값 정리 및 파일 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "테스트 데이터를 predict 함수에 입력하면 목표 변수의 각 클래스에 대한 확률값을 반환함  \n",
    "  \n",
    "다중 분류 문제로 마지막 레이어의 활성화 함수를 softmax로 사용했기 때문.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test 데이터에 대한 예측값 정리\n",
    "# y_pred_proba=model.predict(X_test)\n",
    "# y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "앞에서 출력한 첫 번째 원소를 보면 7개 클래스에 대한 예측 확률값이 순서대로 표시되어 있음  \n",
    "  \n",
    "4번째 원소(클래스 3)의 확률값이 가장 높으며,  \n",
    "넘파이 argmax 함수를 사용하면 가장 값이 큰 원소의 인덱스 값을 얻을 수 있음.  \n",
    "  \n",
    "따라서 7개 확률값 중에서 가장 큰 원소가 있는 인덱스 3을 출력함.  \n",
    "  \n",
    "  \n",
    "하지만 모델이 예측한 값을 그대로 제출하면 안 됨  \n",
    "  \n",
    "데이터 전처리를 할 때 목표 변수의 값에서 3을 차감했기 때문  \n",
    "  \n",
    "모델 예측값에 3을 더하면 목표 레이블 값을 복원할 수 있음  \n",
    "  \n",
    "따라서 첫 번째 테스트 샘플에 대한 예측값은 6이 됨.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_label=np.argmax(y_pred_proba,axis=-1)+3\n",
    "# y_pred_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 양식에 맞게 정리\n",
    "# submission['quality']=y_pred_label.astype(int)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일 저장\n",
    "# submission.to_csv('output/data/wine/wine_dnn_002.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# print('Number of rows and columns:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['lightning','condition','datetime','HI','DI'], axis=1, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['test']=str(df['year'])+'-'+str(df['month'])+'-'+str(df['day'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['year','month','day'],axis=1,inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Onehot Encoding\n",
    "# df['hour']=df['hour'].astype('category')\n",
    "# df=pd.get_dummies(df,columns=['hour'],prefix='H',drop_first=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_27=df[df['region']==27]\n",
    "# df_27=df_27.reset_index(drop=True)\n",
    "# df_27.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10=df[df['region']==10]\n",
    "# df_10=df_10.reset_index(drop=True)\n",
    "# df_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_01=df_10[pd.DatetimeIndex(df_10['date']).year<=2019]\n",
    "# df_10_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "# X_train_scaled=X_train.loc[:,'temp':]\n",
    "# X_test_scaled=X_test.loc[:,'temp':]\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train_scaled.values)\n",
    "# X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "# X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in test_data.take(1):\n",
    "#     inputs,targets=batch\n",
    "\n",
    "# print(\"Input:\",inputs.numpy().shape)\n",
    "# print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8m=df[(df['month']==8)]\n",
    "# df_8m_10r=df_8m[df_8m['region']==10]\n",
    "\n",
    "# df_7m=df[(df['month']==7)]\n",
    "# df_7m_10r=df_7m[df_7m['region']==10]\n",
    "\n",
    "# df_6m=df[(df['month']==6)]\n",
    "# df_6m_10r=df_6m[df_6m['region']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_8m=df_8m_10r['datetime'].to_list() \n",
    "# xs_7m=df_7m_10r['datetime'].to_list()\n",
    "# xs_6m=df_6m_10r['datetime'].to_list()\n",
    "\n",
    "# ys_8m=df_8m_10r['temp'].to_list()\n",
    "# ys_7m=df_7m_10r['temp'].to_list()\n",
    "# ys_6m=df_6m_10r['temp'].to_list()\n",
    "\n",
    "# plt.figure(figsize=(100, 8))\n",
    "\n",
    "# plt.plot(xs_8m, ys_8m, 'o-', ms=3, lw=1, label='8th month')\n",
    "# plt.plot(xs_7m, ys_7m, 'o-', ms=3, lw=1, label='7th month')\n",
    "# plt.plot(xs_6m, ys_6m, 'o-', ms=3, lw=1, label='6th month')\n",
    "# plt.ylim(0,40)\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Temp')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 라이브러리 및 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "# from keras.preprocessing import timeseries_dataset_from_array\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf=pd.read_csv('dataset/DL_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 전처리\n",
    "#### by KMJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (14831616, 23)\n"
     ]
    }
   ],
   "source": [
    "df=rdf[:]\n",
    "print('Number of rows and columns:', df.shape)\n",
    "\n",
    "fact = pd.factorize(df['region'])\n",
    "df['region'] = fact[0]\n",
    "\n",
    "df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "      <th>HI</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104445</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>10.141667</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104446</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>11.498889</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104447</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>12.824444</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "104445 2022-04-30  11.5       0.0      55.0         1.0           313.0   \n",
       "104446 2022-04-30  12.9       0.0      48.0         1.0           311.0   \n",
       "104447 2022-04-30  14.2       0.0      44.0         1.2           157.0   \n",
       "\n",
       "        region  hour         HI  height  \n",
       "104445       0    21  10.141667   42.48  \n",
       "104446       0    22  11.498889   42.48  \n",
       "104447       0    23  12.824444   42.48  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 컬럼과 특정 동네 데이터만 가져옴\n",
    "dataset = df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour','HI','height']]\n",
    "dataset = dataset[dataset['region']==0]\n",
    "dataset.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 0\n",
       "temp                 0\n",
       "rainfall             0\n",
       "humidity             0\n",
       "wind_speed        4519\n",
       "wind_direction    4519\n",
       "region               0\n",
       "hour                 0\n",
       "HI                   0\n",
       "height               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 보간하는 전처리를 진행하기 위하여 복사본으로 작업\n",
    "predata = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              datetime64[ns]\n",
       "temp                     float64\n",
       "rainfall                 float64\n",
       "humidity                 float64\n",
       "wind_speed               float64\n",
       "wind_direction           float64\n",
       "region                     int64\n",
       "hour                       int64\n",
       "HI                       float64\n",
       "height                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풍향이 360도이면 0도로 수정\n",
    "for i in range(len(predata)) :\n",
    "    if predata.loc[i,'wind_direction'] == -1:\n",
    "        predata.loc[i,'wind_direction'] = np.nan\n",
    "    elif predata.loc[i,'wind_direction'] == 360:\n",
    "        predata.loc[i,'wind_direction'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보간-여기부터 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결측치를 3차다항식으로 보간해줌\n",
    "# prepoll = predata.copy()\n",
    "# prepoll['wind_direction'] = prepoll['wind_direction'].interpolate(method='spline', limit_direction='forward', order=5, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "temp              0\n",
       "rainfall          0\n",
       "humidity          0\n",
       "wind_speed        0\n",
       "wind_direction    0\n",
       "region            0\n",
       "hour              0\n",
       "HI                0\n",
       "height            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepoll = predata.copy()\n",
    "prepoll.dropna(inplace=True)\n",
    "prepoll.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "      <th>HI</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.651111</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.629444</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.880556</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temp  rainfall  humidity  wind_speed  wind_direction  region  \\\n",
       "0 2010-12-06  11.6       0.0      32.0         4.1           304.0       0   \n",
       "1 2010-12-06  10.6       0.0      35.0         3.6           300.0       0   \n",
       "2 2010-12-06   9.2       0.0      27.0         3.8           295.0       0   \n",
       "\n",
       "   hour        HI  height  \n",
       "0     7  9.651111   42.48  \n",
       "1     8  8.629444   42.48  \n",
       "2     9  6.880556   42.48  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepoll = prepoll.reset_index(drop=True)\n",
    "prepoll.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99604"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prepoll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9499, 9) (9499, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setting\n",
    "train_split_idx=10000                 # 시작 행 인덱스의 번호\n",
    "window_size=500                       # 과거 100시간 동안 시계열 데이터를 학습 데이터로 사용 / 하이퍼파라미터\n",
    "future=1                              # 1시간 이후의 타깃 예측\n",
    "\n",
    "# Features\n",
    "X_train=prepoll.iloc[:train_split_idx-window_size-future,0:]\n",
    "X_train.drop('temp', axis=1, inplace=True)\n",
    "\n",
    "# Targets\n",
    "y_train=prepoll.iloc[window_size+future:train_split_idx,[1]]  # 'temp' 열\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "      <th>HI</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.382778</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>2012-01-29</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>301.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.241111</td>\n",
       "      <td>42.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "9999  2012-01-29   4.1       0.0      17.0         2.0           246.0   \n",
       "10000 2012-01-29   6.4       0.0      11.0         3.7           279.0   \n",
       "10001 2012-01-29   6.2       0.0      14.0         4.3           301.0   \n",
       "\n",
       "       region  hour        HI  height  \n",
       "9999        0     3  4.100000   42.48  \n",
       "10000       0     4  3.382778   42.48  \n",
       "10001       0     5  3.241111   42.48  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepoll.iloc[[train_split_idx-1,train_split_idx,train_split_idx+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89604, 9) (89604, 1)\n"
     ]
    }
   ],
   "source": [
    "# X_test\n",
    "test_start=train_split_idx-window_size-future   # 테스트 데이터 시작 행\n",
    "test_end=prepoll.shape[0]-window_size-future\n",
    "X_test=prepoll.iloc[test_start:test_end,0:]\n",
    "X_test.drop('temp', axis=1, inplace=True)\n",
    "\n",
    "# y_test\n",
    "# label_start= +future        # 테스트 데이터의 첫 번째 타깃 데이터 위치\n",
    "y_test=prepoll.iloc[train_split_idx:,[1]]    # 'temp' 열 선택\n",
    "\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력 데이터 0~1로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "X_train_scaled=X_train.loc[:,'rainfall':]\n",
    "X_test_scaled=X_test.loc[:,'rainfall':]\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train_scaled.values)\n",
    "X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled =tf.convert_to_tensor(X_train_scaled, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_test_scaled = tf.convert_to_tensor(X_test_scaled, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 사이즈 조정 - 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch 크기로 시계열 변환\n",
    "train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=16)\n",
    "test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=16)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (배치사이즈, 타임스텝, 컬럼수-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (16, 500, 8)\n",
      "Target: (16, 1)\n"
     ]
    }
   ],
   "source": [
    "for batch in test_data.take(1):\n",
    "    inputs,targets=batch\n",
    "\n",
    "print(\"Input:\",inputs.numpy().shape)\n",
    "print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(500, 8), dtype=float32, numpy=\n",
       "array([[0.        , 0.06451613, 0.32911393, ..., 0.3043478 , 0.31358695,\n",
       "        0.        ],\n",
       "       [0.        , 0.06451613, 0.2658228 , ..., 0.3478261 , 0.28823107,\n",
       "        0.        ],\n",
       "       [0.        , 0.09677419, 0.18987341, ..., 0.39130434, 0.33423662,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.32258064, 0.06329114, ..., 0.        , 0.26892602,\n",
       "        0.        ],\n",
       "       [0.        , 0.17204301, 0.29113925, ..., 0.04347826, 0.28813502,\n",
       "        0.        ],\n",
       "       [0.        , 0.13978495, 0.35443038, ..., 0.08695652, 0.30734402,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([6.4], dtype=float32)>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3층 레이어 / 하이퍼파라미터, unit-하이퍼파라미터\n",
    "#### mae 값 0.5 이하일 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 32)                5248      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,793\n",
      "Trainable params: 5,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,8])) # 컬럼, 사이즈\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "#history=model.fit(train_data,epochs=40,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=50,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 32)                5120      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,665\n",
      "Trainable params: 5,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_10\" is incompatible with the layer: expected shape=(None, 100, 7), found shape=(None, None, 9)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\prototype_KMJ.ipynb Cell 125'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000131?line=0'>1</a>\u001b[0m \u001b[39m# 모델 훈련\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000131?line=1'>2</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(train_data,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49mtest_data,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000131?line=3'>4</a>\u001b[0m \u001b[39m# 손실 함수 그래프\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000131?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_loss_curve\u001b[39m(history,total_epoch\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\CHAOS_~1\\AppData\\Local\\Temp\\__autograph_generated_filejb2c2hqy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/CHAOS_~1/AppData/Local/Temp/__autograph_generated_filejb2c2hqy.py?line=12'>13</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/CHAOS_~1/AppData/Local/Temp/__autograph_generated_filejb2c2hqy.py?line=13'>14</a>\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/CHAOS_~1/AppData/Local/Temp/__autograph_generated_filejb2c2hqy.py?line=14'>15</a>\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     <a href='file:///c%3A/Users/CHAOS_~1/AppData/Local/Temp/__autograph_generated_filejb2c2hqy.py?line=15'>16</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/CHAOS_~1/AppData/Local/Temp/__autograph_generated_filejb2c2hqy.py?line=16'>17</a>\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_10\" is incompatible with the layer: expected shape=(None, 100, 7), found shape=(None, None, 9)\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=50,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Input(shape=[100,7]))\n",
    "\n",
    "# model.add(LSTM(units=32,return_sequences=False))\n",
    "# model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "# model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련\n",
    "# history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# # 손실 함수 그래프\n",
    "# def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#         history.history['loss'][start-1:total_epoch],\n",
    "#         label='Train')\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#         history.history['val_loss'][start-1:total_epoch],\n",
    "#         label='Validation')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('mae')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 32)                5120      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,793\n",
      "Trainable params: 5,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=8,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 35s 107ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 32s 106ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 33s 107ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 33s 108ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 17/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 18/100\n",
      "307/307 [==============================] - 32s 106ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 19/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 20/100\n",
      "307/307 [==============================] - 32s 105ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 21/100\n",
      "307/307 [==============================] - 32s 106ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 22/100\n",
      "307/307 [==============================] - 32s 106ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 23/100\n",
      "307/307 [==============================] - 33s 107ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 24/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 25/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 26/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 27/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 28/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 29/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 30/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 31/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 32/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 33/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 34/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 35/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 36/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 37/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 38/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 39/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 40/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 41/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 42/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 43/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 44/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 45/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 46/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 47/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 48/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 49/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 50/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 51/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 52/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 53/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 54/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 55/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 56/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 57/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 58/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 59/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 60/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 61/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 62/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 63/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 64/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 65/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 66/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 67/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 68/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 69/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 70/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 71/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 72/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 73/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 74/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 75/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 76/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 77/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 78/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 79/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 80/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 81/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 82/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 83/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 84/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 85/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 86/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 87/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 88/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 89/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 90/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 91/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 92/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 93/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 94/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 95/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 96/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 97/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 98/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 99/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 100/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAFICAYAAADksb1WAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcyklEQVR4nO3dfZSVdd3v8fcnwMFQC5ixiDEH8wE1ZMCN5kMKde4yIwHFB+7uBRMuXdh9tFpHJe0By1wrXa6jN6fUfMBJbw5TYRBqpEkYruVDDjYhIKYm1SgKYggehRj9nj/2BW1xHvYw+8dmZj6vtfZi79/vd137e3GxPvPjt6+5tiICMzMrrQ+UuwAzs57I4WpmloDD1cwsAYermVkCDlczswQcrmZmCfSacJU0R9J6SSuLGHuKpKcktUiavEvfdZJWSXpG0mxJSle1mXVXvSZcgXrgtCLH/g2oA/5vYaOkE4GTgGOATwJjgFNLVqGZ9Ri9JlwjYhnwemGbpE9I+o2k5ZIekTQ8G7s2IlYA7+66G6A/sA9QAfQDXk1fvZl1N70mXNtwK3BxRBwLXArc1N7giHgMWAqsyx4PRMQzyas0s26nb7kLKBdJ+wEnAr8oWDat6GCbQ4Ejgeqs6beSPh0RjyQr1My6pV4bruRn7ZsiorYT20wCHo+INwEkLQZOAByuZvYevXZZICI2Ay9KOhtAeSM72OxvwKmS+krqR/7DLC8LmNn79JpwlTQPeAw4QlKzpPOBLwPnS/oTsAqYkI0dI6kZOBv4iaRV2W7mAy8ATwN/Av4UEffu4UMxs25AvuWgmVnp9ZqZq5nZnuRwNTNLoFdcLVBZWRk1NTXlLsPMepjly5e/FhFVrfX1inCtqamhsbGx3GWYWQ8j6a9t9XlZwMwsAYermVkCDlczswQcrmZmCThczcwScLiamSXgcDUzS8DhamaWgMPVzCyBXvEbWp22+JvwytPlrsLM9qSPjoAv/LBku/PM1cwsAc9cW1PCn15m1jt55mpmloDD1cwsAYermVkCDlczswQcrmZmCThczcwScLiamSXgcDUzS8DhamaWgMPVzCwBh6uZWQIOVzOzBByuZmYJOFzNzBJwuJqZJZAsXCXNkbRe0soOxo2R1CJpcvZ6nKSmgsdWSROzvnpJLxb01aaq38ysK1LeLLse+BFwV1sDJPUBrgUe3NEWEUuB2qx/EPB8YT9wWUTML325Zmalk2zmGhHLgNc7GHYxcA+wvo3+ycDiiHirlLWZmaVWtjVXSUOBScDN7Qw7D5i3S9s1klZIukFSRTv7v1BSo6TGDRs2lKBiM7PilfMDrRuBmRHxbmudkoYAI4AHCpqvAIYDY4BBwMy2dh4Rt0ZELiJyVVVVJSvazKwY5fyCwhzQIAmgEjhdUktELMz6zwEWRMT2HRtExLrs6TZJdwKX7sF6zcyKVrZwjYhhO55LqgfuKwhWgCnkZ6oUjBsSEeuUT+SJQLtXIpiZlUuycJU0DxgLVEpqBmYB/QAi4pYOtq0BDgJ+v0vXXElVgIAmYEZJizYzK5Fk4RoRUzoxtm6X12uBoa2M+0yXCzMz2wP8G1pmZgk4XM3MEnC4mpkl4HA1M0vA4WpmloDD1cwsAYermVkCDlczswQcrmZmCThczcwScLiamSXgcDUzS8DhamaWgMPVzCwBh6uZWQIOVzOzBByuZmYJOFzNzBJwuJqZJeBwNTNLwOFqZpaAw9XMLAGHq5lZAg5XM7MEHK5mZgkkC1dJcyStl7Syg3FjJLVImlzQ9o6kpuyxqKB9mKQnJD0v6WeS9klVv5lZV6ScudYDp7U3QFIf4FrgwV263o6I2uxxRkH7tcANEXEo8A/g/BLWa2ZWMsnCNSKWAa93MOxi4B5gfUf7kyTgM8D8rOmnwMQulGhmlkzZ1lwlDQUmATe30t1fUqOkxyVNzNoGA5sioiV73QwMTV+pmVnn9S3je98IzIyId/OT0vc4OCJeknQI8DtJTwNvdGbnki4ELgT4+Mc/XoJyzcyKV86rBXJAg6S1wGTgph2z1Ih4KfvzL8DDwChgI/BhSTt+IFQDL7W184i4NSJyEZGrqqpKdQxmZq0qW7hGxLCIqImIGvLrqF+NiIWSBkqqAJBUCZwErI6IAJaSD2KAacCvylC6mVmHki0LSJoHjAUqJTUDs4B+ABFxSzubHgn8RNK75MP/hxGxOuubSX62+wPgj8Adico3M+uSZOEaEVM6Mbau4PmjwIg2xv0FOK7LxZmZJebf0DIzS8DhamaWgMPVzCwBh6uZWQIOVzOzBByuZmYJOFzNzBJwuJqZJeBwNTNLwOFqZpaAw9XMLAGHq5lZAg5XM7MEHK5mZgk4XM3MEnC4mpkl4HA1M0vA4WpmloDD1cwsAYermVkCDlczswQcrmZmCThczcwScLiamSXgcDUzSyBZuEqaI2m9pJUdjBsjqUXS5Ox1raTHJK2StELSuQVj6yW9KKkpe9Smqt/MrCtSzlzrgdPaGyCpD3At8GBB81vA1Ig4Otv+RkkfLui/LCJqs0dTSSs2MyuRZOEaEcuA1zsYdjFwD7C+YLs/R8Rz2fOXs76qVHWamaVQtjVXSUOBScDN7Yw5DtgHeKGg+ZpsueAGSRWJyzQz2y3l/EDrRmBmRLzbWqekIcDdwFcKxlwBDAfGAIOAmW3tXNKFkholNW7YsKGkhZuZdaSc4ZoDGiStBSYDN0maCCDpAOB+4FsR8fiODSJiXeRtA+4Ejmtr5xFxa0TkIiJXVeVVBTPbs/qW640jYtiO55LqgfsiYqGkfYAFwF0RMb9wG0lDImKdJAETgXavRDAzK5dk4SppHjAWqJTUDMwC+gFExC3tbHoOcAowWFJd1laXXRkwV1IVIKAJmJGidjOzrlJElLuG5HK5XDQ2Npa7DDPrYSQtj4hca33+DS0zswQcrmZmCThczcwScLiamSXgcDUzS8DhamaWgMPVzCwBh6uZWQIOVzOzBByuZmYJOFzNzBJwuJqZJeBwNTNLoGz3czWzNLZv305zczNbt24tdyk9Rv/+/amurqZfv35Fb+NwNethmpub2X///ampqSF/X3nriohg48aNNDc3M2zYsI43yHhZwKyH2bp1K4MHD3awlogkBg8e3On/CThczXogB2tp7c7fp8PVzCwBh6uZldTGjRupra2ltraWj370owwdOnTn63/+85/tbtvY2Mgll1yyhypNyx9omVlJDR48mKamJgCuuuoq9ttvPy699NKd/S0tLfTt23r05HI5crlWv5Kq2/HM1cySq6urY8aMGRx//PFcfvnl/OEPf+CEE05g1KhRnHjiiTz77LMAPPzww4wfPx7IB/P06dMZO3YshxxyCLNnzy7nIXRa0TNXSQcDh0XEQ5L2BfpGxJZ0pZlZV33v3lWsfnlzSfd51McOYNaXju70ds3NzTz66KP06dOHzZs388gjj9C3b18eeughrrzySu655573bbNmzRqWLl3Kli1bOOKII7jooos6da1pORUVrpIuAC4EBgGfAKqBW4DPpivNzHqSs88+mz59+gDwxhtvMG3aNJ577jkksX379la3+eIXv0hFRQUVFRUceOCBvPrqq1RXV+/JsndbsTPX/wSOA54AiIjnJB2YrCozK4ndmWGmMmDAgJ3Pv/Od7zBu3DgWLFjA2rVrGTt2bKvbVFRU7Hzep08fWlpaUpdZMsWuuW6LiJ0f80nqC0Saksysp3vjjTcYOnQoAPX19eUtJpFiw/X3kq4E9pX0b8AvgHvTlWVmPdnll1/OFVdcwahRo7rVbLQzFNHxBFTSB4Dzgc8BAh4Abo8ONpY0BxgPrI+IT7YzbgzwGHBeRMzP2qYB386G/CAifpq1HwvUA/sCvwa+1lEduVwuGhsbOzpMsx7hmWee4cgjjyx3GT1Oa3+vkpZHRKvXjhU1c42IdyPitog4OyImZ8+LWRaoB05rb4CkPsC1wIMFbYOAWcDx5Nd6Z0kamHXfDFwAHJY92t2/mVk5FBWukg6TNF/Sakl/2fHoaLuIWAa83sGwi4F7gPUFbZ8HfhsRr0fEP4DfAqdJGgIcEBGPZ+F+FzCxmGMwM9uTil1zvZP8jLEFGEc+1P67q28uaSgwKdt3oaHA3wteN2dtQ7Pnu7a3tu8LJTVKatywYUNXSzUz65Riw3XfiFhCfo32rxFxFfDFErz/jcDMiHi3BPt6j4i4NSJyEZGrqqoq9e7NzNpV7HWu27IPtZ6T9D+Bl4D9SvD+OaAhu51XJXC6pJZs/2MLxlUDD2ft1bu0v1SCOszMSqrYmevXgA8ClwDHAv8BTO3qm0fEsIioiYgaYD7w1YhYSP5qhM9JGph9kPU54IGIWAdslvQp5RN5KvCrrtZhZlZqxYZrAHcDi8jPNg8HbutoI0nzyF9idYSkZknnS5ohaUa7bxbxOnA18GT2+H7WBvBV4HbgeeAFYHGRx2Bme8C4ceN44IEH3tN24403ctFFF7U6fuzYsey4VPL0009n06ZN7xtz1VVXcf3117f7vgsXLmT16tU7X3/3u9/loYce6mT1pVPsssBc4DLgaaDo9dGImNKJsXW7vJ4DzGllXCPQ5jWzZlZeU6ZMoaGhgc9//vM72xoaGrjuuus63PbXv/71br/vwoULGT9+PEcddRQA3//+93d7X6VQ7Mx1Q0QsiogXsw+0/hoRf01amZl1S5MnT+b+++/feWPstWvX8vLLLzNv3jxyuRxHH300s2bNanXbmpoaXnvtNQCuueYaDj/8cE4++eSdtyQEuO222xgzZgwjR47krLPO4q233uLRRx9l0aJFXHbZZdTW1vLCCy9QV1fH/PnzAViyZAmjRo1ixIgRTJ8+nW3btu18v1mzZjF69GhGjBjBmjVrSvb3UOzMdZak24ElwLYdjRHxy5JVYmalt/ib8MrTpd3nR0fAF37YZvegQYM47rjjWLx4MRMmTKChoYFzzjmHK6+8kkGDBvHOO+/w2c9+lhUrVnDMMce0uo/ly5fT0NBAU1MTLS0tjB49mmOPPRaAM888kwsuuACAb3/729xxxx1cfPHFnHHGGYwfP57Jkye/Z19bt26lrq6OJUuWcPjhhzN16lRuvvlmvv71rwNQWVnJU089xU033cT111/P7bffXoK/pOJnrl8Basn/NtSXssf4klRgZj3OjqUByC8JTJkyhZ///OeMHj2aUaNGsWrVqvesj+7qkUceYdKkSXzwgx/kgAMO4IwzztjZt3LlSj796U8zYsQI5s6dy6pVq9qt5dlnn2XYsGEcfvjhAEybNo1ly5bt7D/zzDMBOPbYY1m7du3uHvL7FDtzHRMRR5TsXc1sz2hnhpnShAkT+MY3vsFTTz3FW2+9xaBBg7j++ut58sknGThwIHV1dZ3+quod6urqWLhwISNHjqS+vp6HH364S7XuuK1hqW9pWOzM9VFJR5XsXc2sR9tvv/0YN24c06dPZ8qUKWzevJkBAwbwoQ99iFdffZXFi9u/yOeUU05h4cKFvP3222zZsoV77/3XTfi2bNnCkCFD2L59O3Pnzt3Zvv/++7Nly/u/HOWII45g7dq1PP/88wDcfffdnHrqqSU60rYVO3P9FNAk6UXya64CIiJaXzAxs15vypQpTJo0iYaGBoYPH86oUaMYPnw4Bx10ECeddFK7244ePZpzzz2XkSNHcuCBBzJmzJidfVdffTXHH388VVVVHH/88TsD9bzzzuOCCy5g9uzZOz/IAujfvz933nknZ599Ni0tLYwZM4YZM9q9GrQkir3l4MGttXeXKwZ8y0HrTXzLwTQ6e8vBomau3SVEzcz2Fv5qbTOzBByuZj1Qcfeyt2Ltzt+nw9Wsh+nfvz8bN250wJZIRLBx40b69+/fqe2KvVrAzLqJ6upqmpub8U3iS6d///5UV1d3PLCAw9Wsh+nXrx/Dhg0rdxm9npcFzMwScLiamSXgcDUzS8DhamaWgMPVzCwBh6uZWQIOVzOzBByuZmYJOFzNzBJwuJqZJeBwNTNLwOFqZpZAsnCVNEfSekkr2+ifIGmFpCZJjZJOztrHZW07HlslTcz66iW9WNBXm6p+M7OuSHlXrHrgR8BdbfQvARZFREg6Bvg5MDwilgK1AJIGAc8DDxZsd1lEzN91Z2Zme5NkM9eIWAa83k7/m/Gvu/kOAFq7s+9kYHFEvJWgRDOzZMq65ippkqQ1wP3A9FaGnAfM26Xtmmw54QZJFcmLNDPbDWUN14hYEBHDgYnA1YV9koYAI4AHCpqvAIYDY4BBwMy29i3pwmwtt9F3ZDezPW2vuFogW0I4RFJlQfM5wIKI2F4wbl3kbQPuBI5rZ5+3RkQuInJVVVXJajcza03ZwlXSoZKUPR8NVAAbC4ZMYZclgWw2S7bdRKDVKxHMzMot2dUCkuYBY4FKSc3ALKAfQETcApwFTJW0HXgbOHfHB1ySaoCDgN/vstu5kqoAAU3AjFT1m5l1hXrD1+/mcrlobGwsdxlm1sNIWh4Rudb69oo1VzOznsbhamaWgMPVzCwBh6uZWQIOVzOzBByuZmYJOFzNzBJwuJqZJeBwNTNLwOFqZpaAw9XMLAGHq5lZAg5XM7MEHK5mZgk4XM3MEnC4mpkl4HA1M0vA4WpmloDD1cwsAYermVkCDlczswQcrmZmCThczcwScLiamSXgcDUzSyBZuEqaI2m9pJVt9E+QtEJSk6RGSScX9L2TtTdJWlTQPkzSE5Kel/QzSfukqt/MrCtSzlzrgdPa6V8CjIyIWmA6cHtB39sRUZs9zihovxa4ISIOBf4BnF/aks3MSiNZuEbEMuD1dvrfjIjIXg4Aoq2xAJIEfAaYnzX9FJjY9UrNzEqvrGuukiZJWgPcT372ukP/bKngcUkTs7bBwKaIaMleNwND91y1ZmbFK2u4RsSCiBhOfgZ6dUHXwRGRA/4duFHSJzq7b0kXZgHduGHDhtIUbGZWpL3iaoFsCeEQSZXZ65eyP/8CPAyMAjYCH5bUN9usGnipnX3eGhG5iMhVVVWlLN/M7H3KFq6SDs3WUZE0GqgANkoaKKkia68ETgJWZ+uzS4HJ2S6mAb/a85WbmXWsb8dDdo+kecBYoFJSMzAL6AcQEbcAZwFTJW0H3gbOjYiQdCTwE0nvkg//H0bE6my3M4EGST8A/gjckap+M7Ou0L8+sO+5crlcNDY2lrsMM+thJC3PPh96n71izdXMrKdxuJqZJeBwNTNLwOFqZpaAw9XMLAGHq5lZAg5XM7MEHK5mZgk4XM3MEnC4mpkl4HA1M0vA4WpmloDD1cwsAYermVkCDlczswQcrmZmCThczcwScLiamSXgcDUzS8DhamaWgMPVzCwBh6uZWQIOVzOzBByuZmYJOFzNzBJwuJqZJZAsXCXNkbRe0so2+idIWiGpSVKjpJOz9lpJj0lalfWfW7BNvaQXs22aJNWmqt/MrCv6Jtx3PfAj4K42+pcAiyIiJB0D/BwYDrwFTI2I5yR9DFgu6YGI2JRtd1lEzE9Yt5lZlyUL14hYJqmmnf43C14OACJr/3PBmJclrQeqgE1pKjUzK72yrrlKmiRpDXA/ML2V/uOAfYAXCpqvyZYLbpBU0c6+L8yWGxo3bNhQ8trNzNpT1nCNiAURMRyYCFxd2CdpCHA38JWIeDdrvoL80sEYYBAws5193xoRuYjIVVVVpSjfzKxNe8XVAhGxDDhEUiWApAPIz2a/FRGPF4xbF3nbgDuB48pSsJlZB8oWrpIOlaTs+WigAtgoaR9gAXDXrh9cZbNZsu0mAq1eiWBmVm7JPtCSNA8YC1RKagZmAf0AIuIW4CxgqqTtwNvAudmVA+cApwCDJdVlu6uLiCZgrqQqQEATMCNV/WZmXaGIKHcNyeVyuWhsbCx3GWbWw0haHhG51vr2ijVXM7OexuFqZpaAw9XMLAGHq5lZAg5XM7MEHK5mZgk4XM3MEnC4mpkl4HA1M0vA4WpmloDD1cwsAYermVkCDlczswQcrmZmCaT89tdu63v3rmL1y5vLXYaZ7UFHfewAZn3p6JLtzzNXM7MEPHNtRSl/eplZ7+SZq5lZAg5XM7MEHK5mZgk4XM3MEnC4mpkl4HA1M0vA4WpmloDD1cwsAYermVkCDlczswQcrmZmCSgiyl1DcpI2AH8tYmgl8FricvYUH8veqycdT28/loMjoqq1jl4RrsWS1BgRuXLXUQo+lr1XTzoeH0vbvCxgZpaAw9XMLAGH63vdWu4CSsjHsvfqScfjY2mD11zNzBLwzNXMLAGHKyDpNEnPSnpe0jfLXU9nSTpI0lJJqyWtkvS1rH2QpN9Kei77c2C5ay2WpD6S/ijpvuz1MElPZOfoZ5L2KXeNxZD0YUnzJa2R9IykE7rreZH0jezf10pJ8yT1707nRdIcSeslrSxoa/VcKG92dlwrJI3u7Pv1+nCV1Af4MfAF4ChgiqSjyltVp7UA/ysijgI+BfxndgzfBJZExGHAkux1d/E14JmC19cCN0TEocA/gPPLUlXn/Rfwm4gYDowkf0zd7rxIGgpcAuQi4pNAH+A8utd5qQdO26WtrXPxBeCw7HEhcHOn3y0ievUDOAF4oOD1FcAV5a6ri8f0K+DfgGeBIVnbEODZctdWZP3V2T/0zwD3ASJ/cXff1s7Z3voAPgS8SPbZRkF7tzsvwFDg78Ag8l9seh/w+e52XoAaYGVH5wL4CTCltXHFPnr9zJV//aPZoTlr65Yk1QCjgCeAj0TEuqzrFeAj5aqrk24ELgfezV4PBjZFREv2uruco2HABuDObInjdkkD6IbnJSJeAq4H/gasA94AltM9z0uhts5Fl3PB4dqDSNoPuAf4ekRsLuyL/I/fvf7SEEnjgfURsbzctZRAX2A0cHNEjAL+H7ssAXSj8zIQmED+B8bHgAG8/7/Y3Vqpz4XDFV4CDip4XZ21dSuS+pEP1rkR8cus+VVJQ7L+IcD6ctXXCScBZ0haCzSQXxr4L+DDkvpmY7rLOWoGmiPiiez1fPJh2x3Py/8AXoyIDRGxHfgl+XPVHc9LobbORZdzweEKTwKHZZ967kN+kX5RmWvqFEkC7gCeiYj/XdC1CJiWPZ9Gfi12rxYRV0REdUTUkD8Xv4uILwNLgcnZsO5yLK8Af5d0RNb0WWA13fC8kF8O+JSkD2b/3nYcS7c7L7to61wsAqZmVw18CnijYPmgOOVeYN4bHsDpwJ+BF4Bvlbue3aj/ZPL/nVkBNGWP08mvVS4BngMeAgaVu9ZOHtdY4L7s+SHAH4DngV8AFeWur8hjqAUas3OzEBjYXc8L8D1gDbASuBuo6E7nBZhHfr14O/n/VZzf1rkg/yHqj7NMeJr8VRKdej//hpaZWQJeFjAzS8DhamaWgMPVzCwBh6uZWQIOVzOzBByu1qNIekdSU8GjZDdFkVRTeEcls/b07XiIWbfydkTUlrsIM89crVeQtFbSdZKelvQHSYdm7TWSfpfds3OJpI9n7R+RtEDSn7LHidmu+ki6Lbuv6YOS9s3GX5LdT3eFpIYyHabtRRyu1tPsu8uywLkFfW9ExAjgR+TvvAXwf4CfRsQxwFxgdtY+G/h9RIwkfz+AVVn7YcCPI+JoYBNwVtb+TWBUtp8ZaQ7NuhP/hpb1KJLejIj9WmlfC3wmIv6S3eTmlYgYLOk18vfp3J61r4uISkkbgOqI2Fawjxrgt5G/sTKSZgL9IuIHkn4DvEn+V1wXRsSbiQ/V9nKeuVpvEm0874xtBc/f4V+fW3yR/O+ijwaeLLhTlPVSDlfrTc4t+POx7Pmj5O++BfBl4JHs+RLgItj5fV4famunkj4AHBQRS4GZ5L+B4H2zZ+td/NPVepp9JTUVvP5NROy4HGugpBXkZ59TsraLyX9TwGXkvzXgK1n714BbJZ1PfoZ6Efk7KrWmD/DfWQALmB0Rm0p0PNZNec3VeoVszTUXEa+VuxbrHbwsYGaWgGeuZmYJeOZqZpaAw9XMLAGHq5lZAg5XM7MEHK5mZgk4XM3MEvj/cmBHLyk4dOsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=100,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 32)                5120      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,793\n",
      "Trainable params: 5,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=8,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 37s 114ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 17/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 18/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 19/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 20/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 21/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 22/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 23/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 24/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 25/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 26/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 27/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 28/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 29/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 30/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 31/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 32/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 33/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 34/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 35/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 36/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 37/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 38/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 39/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 40/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 41/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 42/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 43/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 44/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 45/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 46/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 47/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 48/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 49/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 50/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 51/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 52/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 53/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 54/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 55/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 56/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 57/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 58/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 59/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 60/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 61/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 62/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 63/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 64/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 65/100\n",
      "307/307 [==============================] - 33s 109ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 66/100\n",
      "307/307 [==============================] - 33s 109ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 67/100\n",
      "307/307 [==============================] - 33s 109ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 68/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 69/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 70/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 71/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 72/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 73/100\n",
      "307/307 [==============================] - 34s 110ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 74/100\n",
      "307/307 [==============================] - 34s 111ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 75/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 76/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 77/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 78/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 79/100\n",
      "307/307 [==============================] - 34s 113ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 80/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 81/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 82/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 83/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 84/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 85/100\n",
      "307/307 [==============================] - 35s 113ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 86/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 87/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 88/100\n",
      "307/307 [==============================] - 34s 112ms/step - loss: 1309699905538752512.0000 - mse: inf - val_loss: 1489641168177201152.0000 - val_mse: inf\n",
      "Epoch 89/100\n",
      "307/307 [==============================] - ETA: 0s - loss: 1309699905538752512.0000 - mse: inf"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\prototype_KMJ.ipynb Cell 134'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000139?line=0'>1</a>\u001b[0m \u001b[39m# 모델 훈련\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000139?line=1'>2</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(train_data,epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49mtest_data,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000139?line=3'>4</a>\u001b[0m \u001b[39m# 손실 함수 그래프\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/KNU_bigdata_project/Team_Project/prototype_KMJ.ipynb#ch0000139?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_loss_curve\u001b[39m(history,total_epoch\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1430'>1431</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1431'>1432</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1432'>1433</a>\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1433'>1434</a>\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1442'>1443</a>\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1443'>1444</a>\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1444'>1445</a>\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1445'>1446</a>\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1446'>1447</a>\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1447'>1448</a>\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1448'>1449</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1449'>1450</a>\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1450'>1451</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1451'>1452</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1452'>1453</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1453'>1454</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1454'>1455</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1455'>1456</a>\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1456'>1457</a>\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1457'>1458</a>\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1753'>1754</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1754'>1755</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1755'>1756</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1756'>1757</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1757'>1758</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=951'>952</a>\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=952'>953</a>\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=953'>954</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=954'>955</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=955'>956</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=956'>957</a>\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2449'>2450</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2450'>2451</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2451'>2452</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2452'>2453</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2453'>2454</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1859'>1860</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1860'>1861</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1861'>1862</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1862'>1863</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1863'>1864</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1864'>1865</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1865'>1866</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=494'>495</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=495'>496</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=508'>509</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=509'>510</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\KNU_bigdata_project\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///d%3A/KNU_bigdata_project/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=100,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Input(shape=[100,7]))\n",
    "\n",
    "# model.add(LSTM(units=64,return_sequences=False))\n",
    "# model.add(Dense(units=32,activation='linear'))\n",
    "# model.add(Dense(units=16,activation='linear'))\n",
    "# model.add(Dense(units=8,activation='linear'))\n",
    "# model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "# model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련\n",
    "# history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# # 손실 함수 그래프\n",
    "# def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#         history.history['loss'][start-1:total_epoch],\n",
    "#         label='Train')\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#         history.history['val_loss'][start-1:total_epoch],\n",
    "#         label='Validation')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('mae')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Input(shape=[100,7]))\n",
    "\n",
    "# model.add(LSTM(units=64,return_sequences=False))\n",
    "# model.add(Dense(units=32,activation='linear'))\n",
    "# model.add(Dense(units=16,activation='linear'))\n",
    "# model.add(Dense(units=8,activation='linear'))\n",
    "# model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "# model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련\n",
    "# history=model.fit(train_data,epochs=50,validation_data=test_data,verbose=1)\n",
    "\n",
    "# # 손실 함수 그래프\n",
    "# def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#         history.history['loss'][start-1:total_epoch],\n",
    "#         label='Train')\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#         history.history['val_loss'][start-1:total_epoch],\n",
    "#         label='Validation')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('mae')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c0ab5b7d89bb0f19665907e9b7c826a43cb7d8ca3372f5212e98c4477c4be25"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
