{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 더미 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.__version__) # .__version__ 속성으로 버전을 확인함\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 간단한 딥러닝 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용할 입력 데이터를 준비함.\n",
    "# # y=x+1 관계를 갖는 숫자를 x,y 변수에 각각 10개씩 입력함.\n",
    "# # 이 때, x변수의 숫자 배열을 (10행 1열) 형태의 2차원 배열로 변환함.\n",
    "# x=[-3,31,-11,4,0,22,-2,-5,-25,-14]\n",
    "# y=[-2,32,-10,5,1,23,-1,-4,-24,-13]\n",
    "\n",
    "# X_train=np.array(x).reshape(-1,1)\n",
    "# y_train=np.array(y)\n",
    "\n",
    "# print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "케라스 Sequential API는 레이어 여러 개를 연결하여 신경망 모델을 구성하는 도구이다.  \n",
    "  \n",
    "간단한 아키텍처를 가지면서도 대부분의 딥러닝 모델을 만들 수 있다는 장점이 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential() # Sequential 모델 인스턴스를 생성함\n",
    "\n",
    "\n",
    "# # add 메소드를 사용하여 완전 연결 레이어(Dense)를 모델에 추가함.\n",
    "\n",
    "# # 입력 데이터의 차원(input_dim)은 모델 학습에 사용하는 설명 변수(피처)의 개수를 지정하는데,\n",
    "# # 여기서는 1개의 피처를 사용하므로 1로 설정함.\n",
    "\n",
    "# # 완전 연결 레이어의 출력값은 목표 레이블(Y)을 예측함\n",
    "# # 한 개의 연속성 수치(ex.주택 가격)를 예측하는 회귀 문제이므로 유닛(unit) 개수는 1임\n",
    "# # 활성화(activation) 함수로 'linear' 옵션을 지정하여 선형 함수의 출력을 그대로 사용함.\n",
    "# model.add(Dense(units=1,activation='linear',input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summary 메소드를 이용하여 모델 아키텍처(구조)를 확인함\n",
    "# # 딥러닝 모델이 학습할 모수(파라미터:Param #)는 2개인데,\n",
    "# # 일차함수의 기울기(회귀계수)와 절편(상수항)임.\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델이 훈련하는데 필요한 기본 설정을 compile 함수에 지정하는데,\n",
    "# # 옵티마이저(optimizer)와 손실 함수(loss)를 설정함.\n",
    "\n",
    "# # adam 옵티마이저를 선택하고 회귀 분석의 손실 함수인 평균제곱오차(mse)를 지정함.\n",
    "\n",
    "# # metrics 옵션에 보조 평가 지표를 추가할 수 있는데,\n",
    "# # 여기서는 평균절대오차(mae)를 추가하여 손실 함수를 모니터링할 때 함께 추적하기로 함.\n",
    "# model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit 메소드에 훈련 데이터를 입력하여 모델을 학습시키는데,\n",
    "# # 컴파일 단계에서 설정한 adam 옵티마이저와 mse 손실 함수를 가지고 최적의 가중치와 편향을 찾음.\n",
    "\n",
    "# # 에포크(epoch)는 전체 입력 데이터를 모두 몇 번 학습할 것인지 반복 횟수를 정함.\n",
    "\n",
    "# # verbose 옵션을 False(0)로 지정하면 훈련 과정을 화면에 보여주지 않는데,\n",
    "# # 훈련 과정을 표시하려면 1 또는 2를 입력함.\n",
    "# model.fit(X_train,y_train,epochs=3000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습을 마친 딥러닝 모델의 가중치를 확인하려면 weights 속성을 보면 됨\n",
    "# # 기울기에 해당하는 가중치(kernel:0)와 절편에 해당하는 편향(bias:0) 모두 1에 가까운 값을 가지는데,\n",
    "# # 이는 모델 학습을 통해 일차함수 관계식을 매우 근사하게 찾아낸 것으로 볼 수 있다.\n",
    "# model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트 데이터(X)를 predict 메소드에 입력하면 목표 레이블(Y)에 대한 예측값을 얻을 수 있음.\n",
    "# model.predict([[11],[12],[13]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 딥러닝을 활용한 회귀 분석 : 보스턴 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print('시드 고정:',SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sklearn 데이터셋에서 보스턴 주택 데이터셋 로딩\n",
    "# from sklearn import datasets\n",
    "# housing=datasets.load_boston()\n",
    "# X_data=housing.data\n",
    "# y_data=housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_data.shape,y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "입력 데이터의 서로 다른 피처 값의 범위를 비슷한 크기로 맞춰 주면 딥러닝 모델의 성능을 확보하는데 유리한데,  \n",
    "  \n",
    "이것을 피처 스케일링이라고 부름.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MinMaxScaler를 사용하여 입력 데이터(X_data)의 모든 피처 값을 0~1 범위로 정규화 처리함.\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# X_data_scaled=scaler.fit_transform(X_data)\n",
    "\n",
    "# X_data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용하기 위하여 훈련 데이터(80%)와 검증 데이터(20%)를 분할함.\n",
    "# # 학습 - 테스트 데이터셋 분할\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X_data,y_data,test_size=0.2,shuffle=True,random_state=SEED)\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MLP 모델 아키텍처 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결(Dense) 레이어만 사용하여 5개 레이어를 갖는 다층 신경망(MLP)을 만든다.  \n",
    "  \n",
    "레이어를 추가할 때는 add 함수를 사용한다.  \n",
    "  \n",
    "은닉 레이어 4개는 각각 128개, 64개, 32개, 16개의 유닛을 갖는다.  \n",
    "  \n",
    "입력 데이터의 피처가 13개이므로 첫 번째 Dense 레이어의 input_dim에 13을 지정한다.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망\n",
    "# def build_model(num_input=1):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='relu',input_dim=num_input))\n",
    "#     model.add(Dense(64,activation='relu'))\n",
    "#     model.add(Dense(32,activation='relu'))\n",
    "#     model.add(Dense(16,activation='relu'))\n",
    "#     model.add(Dense(1,activation='relu'))\n",
    "\n",
    "#     model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(num_input=13)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 미니 배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델을 훈련시킬 때 샘플 데이터를 한 개씩 입력해서 가중치를 갱신하려면 학습 시간이 오래 걸리는 문제가 있음.  \n",
    "  \n",
    "***미니 배치 학습***은 전체 데이터를 여러 개의 작은 배치 단위로 나누고 배치에 들어 있는 샘플 데이터를 묶어서 모델에 입력함.  \n",
    "  \n",
    "배치 단위로 경사하강법을 적용하고 손실 함수를 최소화하는 방향으로 가중치를 업데이트함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련\n",
    "# model.fit(X_train,y_train,epochs=100,batch_size=32,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "evaluate 함수에 테스트 데이터를 입력하여 모델의 일반화 성능을 평가함  \n",
    "  \n",
    "loss는 11.93이고 mae는 2.57임  \n",
    "  \n",
    "검증 손실이 훈련 손실보다 크기 때문에 과대적합으로 판단됨  \n",
    "  \n",
    "배치 크기에 따라 모델 성능이 달라질 수 있기 때문에 모델을 설계할 때 중요하게 고려해야 함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "학습 데이터 일부(여기서는 25%)를 검증 데이터를 사용하여 교차 검증을 해봄  \n",
    "  \n",
    "fit 메소드의 validation_split 옵션에 테스트 데이터셋 비율을 입력하면 됨  \n",
    "  \n",
    "마지막 200번째 에포크 학습이 끝났을 때 훈련 손실이 검증 손실보다 작은 값이므로 과대적합 상태로 판단됨.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=build_model(num_input=13)\n",
    "# history=model.fit(X_train,y_train,batch_size=32,epochs=200,validation_split=0.25,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "훈련 손실(loss)과 검증 손실(val_loss)을 그래프로 나타냄  \n",
    "  \n",
    "가로축에는 에포크(epoch)를 놓고 세로축에 손실 함수 값을 표시함  \n",
    "  \n",
    "모델 10에포크까지 매우 빠른 속도로 학습이 되고, 이후 점차 완만하게 학습 속도가 낮아지며  \n",
    "그래프가 평평해지는 추이를 보임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_loss_curve(total_epoch=10,start=1):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['loss'][start-1:total_epoch],\n",
    "#             label='Train')\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['val_loss'][start-1:total_epoch],\n",
    "#             label='Validation')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('mse')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_loss_curve(total_epoch=200,start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "20에포크 이후의 손실 함수를 그림  \n",
    "  \n",
    "앞의 그래프에서는 훈련 손실과 검증 손실 간에 차이가 드러나지 않았지만,\n",
    "다음의 그래프를 보면 40에포크 이후 과대적합이 커지는 것을 볼 수 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_curve(total_epoch=200,start=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 딥러닝을 활용한 분류 예측 : 와인 품질 등급 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print(\"시드 고정:\",SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=pd.read_csv('./output/data/wine/train.csv')\n",
    "# test=pd.read_csv('./output/data/wine/test.csv')\n",
    "# submission=pd.read_csv('./output/data/wine/sample_submission.csv')\n",
    "\n",
    "# print(train.shape,test.shape,submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train 데이터의 내용을 살펴봄, 목표 변수는 와인 품질을 나타내는 quality 열임.\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일의 양식을 보면 와인 품질을 나타내는 quality 열에 예측값을 입력해야 함.\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type 열의 데이터를 살펴봄, 화이트 와인(white)이 4159개, 레드와인(red)이 1338개\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "type 열의 범주형 데이터는 문자열 값을 가짐  \n",
    "  \n",
    "모델 학습에 입력하려면 숫자형 데이터로 변환해야 함  \n",
    "  \n",
    "화이트 와인을 나타내는 'white' 문자열을 숫자 1로 바꾸고,  \n",
    "레드 와인을 나타내는 'red' 문자열을 숫자 0으로 변환함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['type']=np.where(train['type']=='white',1,0).astype(int)\n",
    "# test['type']=np.where(test['type']=='white',1,0).astype(int)\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이번에는 목표 변수인 quality 열의 데이터 개수를 확인함, 6등급 와인의 개수가 가장 많음.\n",
    "\n",
    "# train['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "목표 변수는 연속형 숫자 데이터가 아니라, 와인 등급을 나타내는 범주형 데이터임  \n",
    "  \n",
    "케라스 to_categorical 함수를 이용하여 목표 변수를 원핫 인코딩 변환함.  \n",
    "  \n",
    "원핫 인코딩을 하기 전에 숫자 3을 차감하여 와인 등급을 0~6 범위로 바꿈  \n",
    "  \n",
    "와인 등급은 3~9까지 모두 7개 클래스로 구분되는데, 3~9 범위 값으로 원핫 인코딩을 하면  \n",
    "숫자 0부터 최대값인 9까지 10개 클래스로 인식하기 때문임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_train=to_categorical(train.loc[:,'quality']-3)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델 학습에 사용할 피처를 선택하고, MinMax 스케일링으로 모든 피처 변수의 데이터를 0~1 범위로  \n",
    "정규화 변환함.  \n",
    "  \n",
    "이때 훈련 데이터(X_train)로 정규화 학습을 하고, 같은 조건을 검증 데이터(X_test)에 적용하여 변환하는 점에 유의함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 피처 선택\n",
    "# X_train=train.loc[:,'fixed acidity':]\n",
    "# X_test=test.loc[:,'fixed acidity':]\n",
    "\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaler.fit(X_train)\n",
    "# X_train_scaled=scaler.fit_transform(X_train)\n",
    "# X_test_scaled=scaler.fit_transform(X_test)\n",
    "\n",
    "# print(X_train_scaled.shape,y_train.shape)\n",
    "# print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 설계 : 드랍아웃 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결 레이어(Dense) 4개 층으로 구성되는 신경망 모델을 구성함  \n",
    "  \n",
    "모델의 과대적합을 방지하기 위하여 드랍아웃(Dropout) 레이어를 추가함  \n",
    "  \n",
    "드랍아웃은 입력 레이어왕 은닉 레이어 간의 연결 중 일부를 랜덤으로 제거한 상태에서 학습하는 기법임  \n",
    "  \n",
    "결과적으로 유닛 사이에 연결된 가중치 수를 줄이는 효과를 얻기 때문에 과대적합을 방지 가능.  \n",
    "  \n",
    "  \n",
    "미니 배치 단위로 학습할 때마다 연결 네트워크에서 제거되는 가중치가 달라짐,  \n",
    "때문에 매번 다른 네트워크 구조를 갖는 모델을 얻게 됨  \n",
    "  \n",
    "즉, 앙상블 효과가 있어 모델 성능이 개선됨  \n",
    "  \n",
    "  \n",
    "Dense 레이어 뒤에 Dropout 레이어를 추가하고, dropout rate를 설정함  \n",
    "  \n",
    "0.2로 설정하면 20% 확률로 랜덤하게 연결을 제거하게 됨  \n",
    "  \n",
    "은닉 레이어의 활성화 함수로 tanh를 사용해 봄  \n",
    "  \n",
    "다중 분류 모델이므로 마지막 출력 레이어의 활성화 함수는 softmax를 적용함  \n",
    "  \n",
    "옵티마이저는 RMSProp, 손실 함수는 categorical_crossentropy를 지정함  \n",
    "  \n",
    "metrics 옵션에 여러 개의 보조 평가 지표를 입력할 수 있음  \n",
    "  \n",
    "여기서는 acc(정확도)와 mae(평균절대값오차)를 지정함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망 모델\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "# def build_model(train_data,train_target):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='tanh',input_dim=train_data.shape[1]))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(64,activation='tanh'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(32,activation='tanh'))\n",
    "#     model.add(Dense(train_target.shape[1],activation='softmax'))\n",
    "\n",
    "#     model.compile(optimizer='RMSProp',loss='categorical_crossentropy',metrics=['acc','mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(X_train_scaled,y_train)\n",
    "# model.summary()\n",
    "\n",
    "# # tanh 함수는 -1~+1 사이의 출력 범위를 가짐\n",
    "# # 입력값이 0 근처일 때는 학습율이 좋지만,\n",
    "# # 입력값이 커지거나 작아지는 경우 기울기(가중치)가 0에 가까워지므로\n",
    "# # 학습이 이루어지지 않는 문제가 생김.\n",
    "\n",
    "# # 따라서 ReLU 함수에 비해 사용빈도가 낮음 편임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 콜백 함수 : Early Stopping 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "콜백(callback) 함수를 사용하면 모델 학습 과정을 세밀하게 컨트롤할 수 있음.  \n",
    "  \n",
    "가장 많이 사용되는 방법 중에 Early Stopping이 있음.  \n",
    "  \n",
    "딥러닝 모델 학습에서 에포크 수를 늘려 학습을 계속 반복하면 훈련 데이터에 대한 오차(손실 함수)  \n",
    "를 계속 낮출 수 있음.  \n",
    "  \n",
    "하지만 과대적합을 일으켜 테스트 데이터를 포함한 새로운 데이터에 대한 예측력이 나빠지는 문제가 발생함.  \n",
    "  \n",
    "이때 Early Stopping을 사용하면 과대적합이 발생하기 직전에 학습을 멈출 수 있음.  \n",
    "  \n",
    "홀드아웃으로 검증 데이터를 분할하고, 검증 데이터에 대한 모델 성능이 일정 에포크 동안 좋아지지 않으면  \n",
    "모델 학습을 중단함.  \n",
    "  \n",
    "이때 허용되는 에포크 수를 patience 옵션에 설정함.  \n",
    "  \n",
    "다음의 예제는 200에포크로 설정되어 있지만, 학습 중 10에포크 동안 연속하여  \n",
    "검증 데이터에 대한 손실 함수(val_loss)가 줄어들지 않으면 학습을 멈춤.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early Stopping 기법\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# X_tr,X_val,y_tr,y_val=train_test_split(X_train_scaled,y_train,test_size=0.15,shuffle=True,random_state=SEED)\n",
    "\n",
    "# early_stopping=EarlyStopping(monitor='val_loss',patience=10)\n",
    "# history=model.fit(X_tr,y_tr,batch_size=64,epochs=200,validation_data=(X_val,y_val),callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "Early Stopping으로 학습을 멈추면 모델은 학습이 중지된 상태의 가중치로 고정됨  \n",
    "  \n",
    "검증 데이터에 대한 모델 성능을 evaluate 함수로 평가하면 앞의 실행 결과에서 54에포크가 종료된 상태에서의  \n",
    "  \n",
    "평가 지표 값(val_loss,val_acc,val_mae)과 동일하다는 것을 알 수 있음  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 예측값 정리 및 파일 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "테스트 데이터를 predict 함수에 입력하면 목표 변수의 각 클래스에 대한 확률값을 반환함  \n",
    "  \n",
    "다중 분류 문제로 마지막 레이어의 활성화 함수를 softmax로 사용했기 때문.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test 데이터에 대한 예측값 정리\n",
    "# y_pred_proba=model.predict(X_test)\n",
    "# y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "앞에서 출력한 첫 번째 원소를 보면 7개 클래스에 대한 예측 확률값이 순서대로 표시되어 있음  \n",
    "  \n",
    "4번째 원소(클래스 3)의 확률값이 가장 높으며,  \n",
    "넘파이 argmax 함수를 사용하면 가장 값이 큰 원소의 인덱스 값을 얻을 수 있음.  \n",
    "  \n",
    "따라서 7개 확률값 중에서 가장 큰 원소가 있는 인덱스 3을 출력함.  \n",
    "  \n",
    "  \n",
    "하지만 모델이 예측한 값을 그대로 제출하면 안 됨  \n",
    "  \n",
    "데이터 전처리를 할 때 목표 변수의 값에서 3을 차감했기 때문  \n",
    "  \n",
    "모델 예측값에 3을 더하면 목표 레이블 값을 복원할 수 있음  \n",
    "  \n",
    "따라서 첫 번째 테스트 샘플에 대한 예측값은 6이 됨.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_label=np.argmax(y_pred_proba,axis=-1)+3\n",
    "# y_pred_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 양식에 맞게 정리\n",
    "# submission['quality']=y_pred_label.astype(int)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일 저장\n",
    "# submission.to_csv('output/data/wine/wine_dnn_002.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# print('Number of rows and columns:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['lightning','condition','datetime','HI','DI'], axis=1, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['test']=str(df['year'])+'-'+str(df['month'])+'-'+str(df['day'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['year','month','day'],axis=1,inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Onehot Encoding\n",
    "# df['hour']=df['hour'].astype('category')\n",
    "# df=pd.get_dummies(df,columns=['hour'],prefix='H',drop_first=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_27=df[df['region']==27]\n",
    "# df_27=df_27.reset_index(drop=True)\n",
    "# df_27.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10=df[df['region']==10]\n",
    "# df_10=df_10.reset_index(drop=True)\n",
    "# df_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_01=df_10[pd.DatetimeIndex(df_10['date']).year<=2019]\n",
    "# df_10_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "# X_train_scaled=X_train.loc[:,'temp':]\n",
    "# X_test_scaled=X_test.loc[:,'temp':]\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train_scaled.values)\n",
    "# X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "# X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in test_data.take(1):\n",
    "#     inputs,targets=batch\n",
    "\n",
    "# print(\"Input:\",inputs.numpy().shape)\n",
    "# print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8m=df[(df['month']==8)]\n",
    "# df_8m_10r=df_8m[df_8m['region']==10]\n",
    "\n",
    "# df_7m=df[(df['month']==7)]\n",
    "# df_7m_10r=df_7m[df_7m['region']==10]\n",
    "\n",
    "# df_6m=df[(df['month']==6)]\n",
    "# df_6m_10r=df_6m[df_6m['region']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_8m=df_8m_10r['datetime'].to_list() \n",
    "# xs_7m=df_7m_10r['datetime'].to_list()\n",
    "# xs_6m=df_6m_10r['datetime'].to_list()\n",
    "\n",
    "# ys_8m=df_8m_10r['temp'].to_list()\n",
    "# ys_7m=df_7m_10r['temp'].to_list()\n",
    "# ys_6m=df_6m_10r['temp'].to_list()\n",
    "\n",
    "# plt.figure(figsize=(100, 8))\n",
    "\n",
    "# plt.plot(xs_8m, ys_8m, 'o-', ms=3, lw=1, label='8th month')\n",
    "# plt.plot(xs_7m, ys_7m, 'o-', ms=3, lw=1, label='7th month')\n",
    "# plt.plot(xs_6m, ys_6m, 'o-', ms=3, lw=1, label='6th month')\n",
    "# plt.ylim(0,40)\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Temp')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 라이브러리 및 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf=pd.read_csv('output/daegu_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (14831616, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831611</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>335.0</td>\n",
       "      <td>141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831612</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>339.0</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831613</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831614</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>141</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831615</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>141</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14189918 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  month  temp  rainfall  humidity  wind_speed  \\\n",
       "4519     2010-12-06     12  11.6       0.0      32.0         4.1   \n",
       "4520     2010-12-06     12  10.6       0.0      35.0         3.6   \n",
       "4521     2010-12-06     12   9.2       0.0      27.0         3.8   \n",
       "4522     2010-12-06     12   7.9       0.0      34.0         4.1   \n",
       "4523     2010-12-06     12   5.7       0.0      44.0         3.6   \n",
       "...             ...    ...   ...       ...       ...         ...   \n",
       "14831611 2022-04-30      4  10.7       0.0      71.0         2.1   \n",
       "14831612 2022-04-30      4  11.0       0.0      65.0         2.2   \n",
       "14831613 2022-04-30      4  11.9       0.0      61.0         2.2   \n",
       "14831614 2022-04-30      4  13.4       0.0      53.0         2.0   \n",
       "14831615 2022-04-30      4  15.1       0.0      41.0         2.1   \n",
       "\n",
       "          wind_direction  region  hour  \n",
       "4519               304.0       0     7  \n",
       "4520               300.0       0     8  \n",
       "4521               295.0       0     9  \n",
       "4522               281.0       0    10  \n",
       "4523               298.0       0    11  \n",
       "...                  ...     ...   ...  \n",
       "14831611           335.0     141    19  \n",
       "14831612           339.0     141    20  \n",
       "14831613           338.0     141    21  \n",
       "14831614           351.0     141    22  \n",
       "14831615             5.0     141    23  \n",
       "\n",
       "[14189918 rows x 9 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=rdf[:]\n",
    "print('Number of rows and columns:', df.shape)\n",
    "\n",
    "fact = pd.factorize(df['region'])\n",
    "df['region'] = fact[0]\n",
    "\n",
    "df.drop(['lightning','condition','datetime','HI','DI'], axis=1, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')\n",
    "\n",
    "\n",
    "# df.drop(['year','month','day'],axis=1,inplace=True)\n",
    "\n",
    "df=df[['date','month','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "# df=df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826523</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826524</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826525</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>141</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826526</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>141</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826527</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>330.0</td>\n",
       "      <td>141</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4573536 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  month  temp  rainfall  humidity  wind_speed  \\\n",
       "8760     2011-06-01      6  19.0       0.0      77.0         1.6   \n",
       "8761     2011-06-01      6  19.8       0.0      66.0         1.3   \n",
       "8762     2011-06-01      6  20.4       0.0      66.0         2.1   \n",
       "8763     2011-06-01      6  21.9       0.0      60.0         1.6   \n",
       "8764     2011-06-01      6  21.8       0.0      61.0         2.2   \n",
       "...             ...    ...   ...       ...       ...         ...   \n",
       "14826523 2021-09-30      9  16.8       0.0     100.0         0.5   \n",
       "14826524 2021-09-30      9  17.1       0.0     100.0         1.0   \n",
       "14826525 2021-09-30      9  16.9       0.0     100.0         2.0   \n",
       "14826526 2021-09-30      9  17.5       0.0     100.0         2.2   \n",
       "14826527 2021-09-30      9  19.7       0.0      90.0         2.6   \n",
       "\n",
       "          wind_direction  region  hour  \n",
       "8760                86.0       0     0  \n",
       "8761                48.0       0     1  \n",
       "8762               270.0       0     2  \n",
       "8763               101.0       0     3  \n",
       "8764               270.0       0     4  \n",
       "...                  ...     ...   ...  \n",
       "14826523           338.0     141    19  \n",
       "14826524           328.0     141    20  \n",
       "14826525           346.0     141    21  \n",
       "14826526           325.0     141    22  \n",
       "14826527           330.0     141    23  \n",
       "\n",
       "[4573536 rows x 9 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_all=df[(df['month']==12)|(df['month']==1)|(df['month']==2)|(df['month']==6)|(df['month']==7)|(df['month']==8)]\n",
    "df_all=df[(df['month']==6)|(df['month']==7)|(df['month']==8)|(df['month']==9)]\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_10r=df_all[(df_all['region']==10)]\n",
    "# df_all_10r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_10r_ind=df_all_10r.reset_index(drop=True)\n",
    "df_all_ind=df_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 6))\n",
    "# df_all_10r.plot(y=['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573531</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573532</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573533</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>141</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573534</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>141</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573535</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>330.0</td>\n",
       "      <td>141</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4573536 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "0       2011-06-01  19.0       0.0      77.0         1.6            86.0   \n",
       "1       2011-06-01  19.8       0.0      66.0         1.3            48.0   \n",
       "2       2011-06-01  20.4       0.0      66.0         2.1           270.0   \n",
       "3       2011-06-01  21.9       0.0      60.0         1.6           101.0   \n",
       "4       2011-06-01  21.8       0.0      61.0         2.2           270.0   \n",
       "...            ...   ...       ...       ...         ...             ...   \n",
       "4573531 2021-09-30  16.8       0.0     100.0         0.5           338.0   \n",
       "4573532 2021-09-30  17.1       0.0     100.0         1.0           328.0   \n",
       "4573533 2021-09-30  16.9       0.0     100.0         2.0           346.0   \n",
       "4573534 2021-09-30  17.5       0.0     100.0         2.2           325.0   \n",
       "4573535 2021-09-30  19.7       0.0      90.0         2.6           330.0   \n",
       "\n",
       "         region  hour  \n",
       "0             0     0  \n",
       "1             0     1  \n",
       "2             0     2  \n",
       "3             0     3  \n",
       "4             0     4  \n",
       "...         ...   ...  \n",
       "4573531     141    19  \n",
       "4573532     141    20  \n",
       "4573533     141    21  \n",
       "4573534     141    22  \n",
       "4573535     141    23  \n",
       "\n",
       "[4573536 rows x 8 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ind.drop(['month'],axis=1,inplace=True)\n",
    "df_all_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train과 test로 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999876, 8) (2999876, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setting\n",
    "train_split_idx=3000000\n",
    "window_size=100                       # 과거 100시간 동안 시계열 데이터를 학습 데이터로 사용\n",
    "future=24                             # 24시간 이후의 타깃 예측\n",
    "\n",
    "# Features\n",
    "X_train=df_all_ind.iloc[:train_split_idx-window_size-future,0:]\n",
    "\n",
    "# Targets\n",
    "y_train=df_all_ind.iloc[window_size+future:train_split_idx,[1]]  # 'temp' 열\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2012-08-11</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000000</th>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000001</th>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "2999999 2012-08-11  27.4       0.0      78.0         0.0             0.0   \n",
       "3000000 2012-08-12  28.5       0.0      73.0         0.8            50.0   \n",
       "3000001 2012-08-12  28.5       0.0      71.0         0.5            79.0   \n",
       "\n",
       "         region  hour  \n",
       "2999999      93    23  \n",
       "3000000      93     0  \n",
       "3000001      93     1  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ind.iloc[[train_split_idx-1,train_split_idx,train_split_idx+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573536, 8) (1573536, 1)\n"
     ]
    }
   ],
   "source": [
    "# X_test\n",
    "test_start=train_split_idx-window_size-future   # 테스트 데이터 시작 행\n",
    "test_end=df_all_ind.shape[0]-window_size-future\n",
    "X_test=df_all_ind.iloc[test_start:test_end,0:]\n",
    "\n",
    "# y_test\n",
    "# label_start= +future        # 테스트 데이터의 첫 번째 타깃 데이터 위치\n",
    "y_test=df_all_ind.iloc[train_split_idx:,[1]]    # 'temp' 열 선택\n",
    "\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력 데이터 0~1로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "X_train_scaled=X_train.loc[:,'temp':]\n",
    "X_test_scaled=X_test.loc[:,'temp':]\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train_scaled.values)\n",
    "X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 사이즈 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mini Batch 크기로 시계열 변환\n",
    "# train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=16)\n",
    "# test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=16)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# # Mini Batch 크기로 시계열 변환\n",
    "# train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=32)\n",
    "# test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=32)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mini Batch 크기로 시계열 변환\n",
    "# train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=64)\n",
    "# test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=64)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch 크기로 시계열 변환\n",
    "train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=1024)\n",
    "test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=1024)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (배치사이즈, 타임스텝, 컬럼수-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (1024, 100, 7)\n",
      "Target: (1024, 1)\n"
     ]
    }
   ],
   "source": [
    "for batch in test_data.take(1):\n",
    "    inputs,targets=batch\n",
    "\n",
    "print(\"Input:\",inputs.numpy().shape)\n",
    "print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 7), dtype=float64, numpy=\n",
       "array([[0.51829268, 0.        , 0.75555556, 0.08284024, 0.31024931,\n",
       "        1.        , 0.86956522],\n",
       "       [0.53963415, 0.        , 0.73333333, 0.07692308, 0.41274238,\n",
       "        1.        , 0.91304348],\n",
       "       [0.55487805, 0.        , 0.76666667, 0.09467456, 0.39058172,\n",
       "        1.        , 0.95652174],\n",
       "       [0.58231707, 0.        , 0.7       , 0.13017751, 0.34626039,\n",
       "        1.        , 1.        ],\n",
       "       [0.59146341, 0.        , 0.66666667, 0.18343195, 0.35734072,\n",
       "        1.        , 0.        ],\n",
       "       [0.66768293, 0.        , 0.55555556, 0.21301775, 0.31578947,\n",
       "        1.        , 0.04347826],\n",
       "       [0.71341463, 0.        , 0.48888889, 0.26627219, 0.24099723,\n",
       "        1.        , 0.08695652],\n",
       "       [0.72256098, 0.        , 0.46666667, 0.31360947, 0.33240997,\n",
       "        1.        , 0.13043478],\n",
       "       [0.72560976, 0.        , 0.45555556, 0.31952663, 0.32686981,\n",
       "        1.        , 0.17391304],\n",
       "       [0.7347561 , 0.        , 0.43333333, 0.35502959, 0.34072022,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.75      , 0.        , 0.38888889, 0.30177515, 0.33518006,\n",
       "        1.        , 0.26086957],\n",
       "       [0.71341463, 0.        , 0.37777778, 0.37278107, 0.32132964,\n",
       "        1.        , 0.30434783],\n",
       "       [0.69207317, 0.        , 0.4       , 0.30769231, 0.34072022,\n",
       "        1.        , 0.34782609],\n",
       "       [0.65853659, 0.        , 0.41111111, 0.27810651, 0.34072022,\n",
       "        1.        , 0.39130435],\n",
       "       [0.62195122, 0.        , 0.45555556, 0.28402367, 0.31024931,\n",
       "        1.        , 0.43478261],\n",
       "       [0.58841463, 0.        , 0.55555556, 0.21893491, 0.32686981,\n",
       "        1.        , 0.47826087],\n",
       "       [0.56097561, 0.        , 0.64444444, 0.22485207, 0.34072022,\n",
       "        1.        , 0.52173913],\n",
       "       [0.54878049, 0.        , 0.66666667, 0.20710059, 0.32686981,\n",
       "        1.        , 0.56521739],\n",
       "       [0.53658537, 0.        , 0.68888889, 0.12426036, 0.35457064,\n",
       "        1.        , 0.60869565],\n",
       "       [0.5304878 , 0.        , 0.7       , 0.14792899, 0.39058172,\n",
       "        1.        , 0.65217391],\n",
       "       [0.51219512, 0.        , 0.71111111, 0.07100592, 0.52631579,\n",
       "        1.        , 0.69565217],\n",
       "       [0.5       , 0.        , 0.71111111, 0.07100592, 0.48753463,\n",
       "        1.        , 0.73913043],\n",
       "       [0.50609756, 0.        , 0.75555556, 0.0295858 , 0.35457064,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.45731707, 0.        , 0.78888889, 0.        , 0.00277008,\n",
       "        1.        , 0.82608696],\n",
       "       [0.45426829, 0.        , 0.82222222, 0.0887574 , 0.47091413,\n",
       "        1.        , 0.86956522],\n",
       "       [0.45121951, 0.        , 0.68888889, 0.00591716, 0.00277008,\n",
       "        1.        , 0.91304348],\n",
       "       [0.47865854, 0.        , 0.74444444, 0.07692308, 0.45152355,\n",
       "        1.        , 0.95652174],\n",
       "       [0.55792683, 0.        , 0.66666667, 0.01183432, 0.00277008,\n",
       "        1.        , 1.        ],\n",
       "       [0.57926829, 0.        , 0.6       , 0.10650888, 0.26869806,\n",
       "        1.        , 0.        ],\n",
       "       [0.60060976, 0.        , 0.57777778, 0.14201183, 0.30470914,\n",
       "        1.        , 0.04347826],\n",
       "       [0.6554878 , 0.        , 0.48888889, 0.13609467, 0.3767313 ,\n",
       "        1.        , 0.08695652],\n",
       "       [0.69512195, 0.        , 0.42222222, 0.12426036, 0.24376731,\n",
       "        1.        , 0.13043478],\n",
       "       [0.72865854, 0.        , 0.34444444, 0.15384615, 0.31024931,\n",
       "        1.        , 0.17391304],\n",
       "       [0.73780488, 0.        , 0.31111111, 0.18343195, 0.35180055,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.75609756, 0.        , 0.28888889, 0.20710059, 0.22437673,\n",
       "        1.        , 0.26086957],\n",
       "       [0.74085366, 0.        , 0.45555556, 0.16568047, 0.3601108 ,\n",
       "        1.        , 0.30434783],\n",
       "       [0.71646341, 0.        , 0.48888889, 0.21301775, 0.26038781,\n",
       "        1.        , 0.34782609],\n",
       "       [0.67682927, 0.        , 0.47777778, 0.26035503, 0.26315789,\n",
       "        1.        , 0.39130435],\n",
       "       [0.6402439 , 0.        , 0.55555556, 0.24260355, 0.28808864,\n",
       "        1.        , 0.43478261],\n",
       "       [0.60060976, 0.        , 0.61111111, 0.21893491, 0.29085873,\n",
       "        1.        , 0.47826087],\n",
       "       [0.57621951, 0.        , 0.6       , 0.19526627, 0.29639889,\n",
       "        1.        , 0.52173913],\n",
       "       [0.58231707, 0.        , 0.62222222, 0.16568047, 0.46537396,\n",
       "        1.        , 0.56521739],\n",
       "       [0.55792683, 0.        , 0.65555556, 0.15976331, 0.46537396,\n",
       "        1.        , 0.60869565],\n",
       "       [0.5304878 , 0.        , 0.73333333, 0.13017751, 0.44044321,\n",
       "        1.        , 0.65217391],\n",
       "       [0.5152439 , 0.        , 0.77777778, 0.15384615, 0.39889197,\n",
       "        1.        , 0.69565217],\n",
       "       [0.50304878, 0.        , 0.77777778, 0.15384615, 0.43213296,\n",
       "        1.        , 0.73913043],\n",
       "       [0.48170732, 0.        , 0.81111111, 0.13017751, 0.44044321,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.47560976, 0.        , 0.82222222, 0.0887574 , 0.29639889,\n",
       "        1.        , 0.82608696],\n",
       "       [0.47256098, 0.        , 0.82222222, 0.12426036, 0.35457064,\n",
       "        1.        , 0.86956522],\n",
       "       [0.4695122 , 0.        , 0.73333333, 0.07100592, 0.31855956,\n",
       "        1.        , 0.91304348],\n",
       "       [0.48780488, 0.        , 0.75555556, 0.0591716 , 0.29916898,\n",
       "        1.        , 0.95652174],\n",
       "       [0.50914634, 0.        , 0.73333333, 0.09467456, 0.29085873,\n",
       "        1.        , 1.        ],\n",
       "       [0.57012195, 0.        , 0.67777778, 0.        , 0.00277008,\n",
       "        1.        , 0.        ],\n",
       "       [0.62804878, 0.        , 0.61111111, 0.        , 0.00277008,\n",
       "        1.        , 0.04347826],\n",
       "       [0.65853659, 0.        , 0.55555556, 0.08284024, 0.89196676,\n",
       "        1.        , 0.08695652],\n",
       "       [0.67682927, 0.        , 0.5       , 0.13017751, 0.93905817,\n",
       "        1.        , 0.13043478],\n",
       "       [0.72865854, 0.        , 0.45555556, 0.02366864, 0.00277008,\n",
       "        1.        , 0.17391304],\n",
       "       [0.77439024, 0.        , 0.35555556, 0.06508876, 0.73684211,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.7804878 , 0.        , 0.31111111, 0.19526627, 0.88642659,\n",
       "        1.        , 0.26086957],\n",
       "       [0.78963415, 0.        , 0.32222222, 0.13017751, 0.83379501,\n",
       "        1.        , 0.30434783],\n",
       "       [0.80792683, 0.        , 0.36666667, 0.14792899, 0.86149584,\n",
       "        1.        , 0.34782609],\n",
       "       [0.77743902, 0.        , 0.45555556, 0.20118343, 0.68698061,\n",
       "        1.        , 0.39130435],\n",
       "       [0.75609756, 0.        , 0.5       , 0.24260355, 0.78116343,\n",
       "        1.        , 0.43478261],\n",
       "       [0.72865854, 0.        , 0.52222222, 0.17159763, 0.90027701,\n",
       "        1.        , 0.47826087],\n",
       "       [0.7195122 , 0.        , 0.52222222, 0.10650888, 0.69806094,\n",
       "        1.        , 0.52173913],\n",
       "       [0.63719512, 0.        , 0.51111111, 0.0295858 , 0.10526316,\n",
       "        1.        , 0.56521739],\n",
       "       [0.61280488, 0.        , 0.58888889, 0.01183432, 0.00277008,\n",
       "        1.        , 0.60869565],\n",
       "       [0.60365854, 0.        , 0.65555556, 0.05325444, 0.46537396,\n",
       "        1.        , 0.65217391],\n",
       "       [0.60365854, 0.        , 0.64444444, 0.07692308, 0.47645429,\n",
       "        1.        , 0.69565217],\n",
       "       [0.57926829, 0.        , 0.66666667, 0.00591716, 0.00277008,\n",
       "        1.        , 0.73913043],\n",
       "       [0.5945122 , 0.        , 0.68888889, 0.0591716 , 0.72022161,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.55792683, 0.        , 0.71111111, 0.05325444, 0.13850416,\n",
       "        1.        , 0.82608696],\n",
       "       [0.55792683, 0.        , 0.73333333, 0.02366864, 0.00277008,\n",
       "        1.        , 0.86956522],\n",
       "       [0.56707317, 0.        , 0.73333333, 0.04733728, 0.50138504,\n",
       "        1.        , 0.91304348],\n",
       "       [0.58841463, 0.        , 0.73333333, 0.        , 0.00277008,\n",
       "        1.        , 0.95652174],\n",
       "       [0.61890244, 0.        , 0.71111111, 0.04142012, 0.15789474,\n",
       "        1.        , 1.        ],\n",
       "       [0.64329268, 0.        , 0.66666667, 0.06508876, 0.03047091,\n",
       "        1.        , 0.        ],\n",
       "       [0.67073171, 0.        , 0.6       , 0.10059172, 0.06094183,\n",
       "        1.        , 0.04347826],\n",
       "       [0.68597561, 0.        , 0.56666667, 0.14792899, 0.93628809,\n",
       "        1.        , 0.08695652],\n",
       "       [0.67378049, 0.        , 0.55555556, 0.10650888, 0.94736842,\n",
       "        1.        , 0.13043478],\n",
       "       [0.71646341, 0.        , 0.61111111, 0.17159763, 0.8365651 ,\n",
       "        1.        , 0.17391304],\n",
       "       [0.72560976, 0.        , 0.5       , 0.26035503, 0.78393352,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.68902439, 0.        , 0.57777778, 0.19526627, 0.8199446 ,\n",
       "        1.        , 0.26086957],\n",
       "       [0.625     , 0.        , 0.63333333, 0.24852071, 0.31024931,\n",
       "        1.        , 0.30434783],\n",
       "       [0.54268293, 0.01639344, 0.82222222, 0.27218935, 0.38781163,\n",
       "        1.        , 0.34782609],\n",
       "       [0.52743902, 0.01639344, 0.87777778, 0.10059172, 0.28808864,\n",
       "        1.        , 0.39130435],\n",
       "       [0.50609756, 0.01639344, 0.87777778, 0.15384615, 0.33240997,\n",
       "        1.        , 0.43478261],\n",
       "       [0.50609756, 0.        , 0.88888889, 0.23076923, 0.40443213,\n",
       "        1.        , 0.47826087],\n",
       "       [0.50304878, 0.        , 0.85555556, 0.16568047, 0.43767313,\n",
       "        1.        , 0.52173913],\n",
       "       [0.50609756, 0.        , 0.83333333, 0.1183432 , 0.38781163,\n",
       "        1.        , 0.56521739],\n",
       "       [0.51219512, 0.        , 0.82222222, 0.18934911, 0.45152355,\n",
       "        1.        , 0.60869565],\n",
       "       [0.50609756, 0.        , 0.92222222, 0.13017751, 0.43490305,\n",
       "        1.        , 0.65217391],\n",
       "       [0.50304878, 0.        , 0.9       , 0.1183432 , 0.41828255,\n",
       "        1.        , 0.69565217],\n",
       "       [0.49695122, 0.        , 0.88888889, 0.17751479, 0.4265928 ,\n",
       "        1.        , 0.73913043],\n",
       "       [0.49695122, 0.        , 0.9       , 0.15976331, 0.4099723 ,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.49085366, 0.        , 0.87777778, 0.15976331, 0.41551247,\n",
       "        1.        , 0.82608696],\n",
       "       [0.48780488, 0.        , 0.9       , 0.12426036, 0.3601108 ,\n",
       "        1.        , 0.86956522],\n",
       "       [0.48170732, 0.        , 0.85555556, 0.11242604, 0.3933518 ,\n",
       "        1.        , 0.91304348],\n",
       "       [0.49390244, 0.        , 0.85555556, 0.06508876, 0.32686981,\n",
       "        1.        , 0.95652174],\n",
       "       [0.52134146, 0.        , 0.81111111, 0.01775148, 0.00277008,\n",
       "        1.        , 1.        ]])>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([28.5])>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 32)                5120      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,665\n",
      "Trainable params: 5,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2930/2930 [==============================] - 1159s 395ms/step - loss: 2.7006 - mse: 17.6015 - val_loss: 2.3561 - val_mse: 8.5763\n",
      "Epoch 2/10\n",
      "2930/2930 [==============================] - 1176s 401ms/step - loss: 1.8551 - mse: 5.9857 - val_loss: 2.3366 - val_mse: 8.3805\n",
      "Epoch 3/10\n",
      "2930/2930 [==============================] - 2197s 750ms/step - loss: 1.8104 - mse: 5.7596 - val_loss: 2.2733 - val_mse: 8.0060\n",
      "Epoch 4/10\n",
      "2930/2930 [==============================] - 1180s 403ms/step - loss: 1.7977 - mse: 5.6833 - val_loss: 2.1771 - val_mse: 7.4599\n",
      "Epoch 5/10\n",
      "2930/2930 [==============================] - 1195s 408ms/step - loss: 1.7708 - mse: 5.5380 - val_loss: 2.0901 - val_mse: 6.8820\n",
      "Epoch 6/10\n",
      "2930/2930 [==============================] - 1179s 402ms/step - loss: 1.7070 - mse: 5.2033 - val_loss: 2.1203 - val_mse: 7.1167\n",
      "Epoch 7/10\n",
      "2930/2930 [==============================] - 1100s 375ms/step - loss: 1.6623 - mse: 4.9708 - val_loss: 1.9667 - val_mse: 6.3165\n",
      "Epoch 8/10\n",
      "2930/2930 [==============================] - 1177s 402ms/step - loss: 1.6060 - mse: 4.6727 - val_loss: 1.9678 - val_mse: 6.3444\n",
      "Epoch 9/10\n",
      "2930/2930 [==============================] - 1156s 395ms/step - loss: 1.5524 - mse: 4.3968 - val_loss: 1.8845 - val_mse: 5.9094\n",
      "Epoch 10/10\n",
      "2930/2930 [==============================] - 1137s 388ms/step - loss: 1.5088 - mse: 4.1738 - val_loss: 1.8112 - val_mse: 5.5425\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 32)                5120      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,665\n",
      "Trainable params: 5,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "307/307 [==============================] - 13s 37ms/step - loss: 7.3356 - mse: 118.0800 - val_loss: 4.9518 - val_mse: 37.8102\n",
      "Epoch 2/50\n",
      "307/307 [==============================] - 13s 42ms/step - loss: 3.4135 - mse: 17.8974 - val_loss: 4.9171 - val_mse: 37.2785\n",
      "Epoch 3/50\n",
      "307/307 [==============================] - 13s 41ms/step - loss: 3.4175 - mse: 17.9397 - val_loss: 4.9210 - val_mse: 37.2534\n",
      "Epoch 4/50\n",
      "307/307 [==============================] - 13s 41ms/step - loss: 3.3944 - mse: 17.7069 - val_loss: 4.8984 - val_mse: 36.8205\n",
      "Epoch 5/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 3.3584 - mse: 17.3606 - val_loss: 4.9347 - val_mse: 36.9598\n",
      "Epoch 6/50\n",
      "307/307 [==============================] - 13s 41ms/step - loss: 3.2445 - mse: 16.2742 - val_loss: 4.7432 - val_mse: 34.0572\n",
      "Epoch 7/50\n",
      "307/307 [==============================] - 13s 41ms/step - loss: 2.9853 - mse: 13.7900 - val_loss: 4.3985 - val_mse: 29.2849\n",
      "Epoch 8/50\n",
      "307/307 [==============================] - 13s 42ms/step - loss: 2.6313 - mse: 10.6191 - val_loss: 3.9687 - val_mse: 23.8788\n",
      "Epoch 9/50\n",
      "307/307 [==============================] - 13s 42ms/step - loss: 2.3431 - mse: 8.4027 - val_loss: 3.5544 - val_mse: 19.2887\n",
      "Epoch 10/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 2.1573 - mse: 7.1832 - val_loss: 3.3818 - val_mse: 17.4554\n",
      "Epoch 11/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 2.0565 - mse: 6.5819 - val_loss: 3.2638 - val_mse: 16.2709\n",
      "Epoch 12/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.9946 - mse: 6.2338 - val_loss: 3.2026 - val_mse: 15.6538\n",
      "Epoch 13/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.9563 - mse: 6.0201 - val_loss: 3.1422 - val_mse: 15.0717\n",
      "Epoch 14/50\n",
      "307/307 [==============================] - 12s 41ms/step - loss: 1.9259 - mse: 5.8483 - val_loss: 3.1069 - val_mse: 14.7211\n",
      "Epoch 15/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.9016 - mse: 5.7110 - val_loss: 3.0694 - val_mse: 14.3608\n",
      "Epoch 16/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.8815 - mse: 5.5982 - val_loss: 3.0268 - val_mse: 13.9655\n",
      "Epoch 17/50\n",
      "307/307 [==============================] - 12s 41ms/step - loss: 1.8574 - mse: 5.4642 - val_loss: 2.9872 - val_mse: 13.6014\n",
      "Epoch 18/50\n",
      "307/307 [==============================] - 13s 42ms/step - loss: 1.8296 - mse: 5.3156 - val_loss: 2.9330 - val_mse: 13.1270\n",
      "Epoch 19/50\n",
      "307/307 [==============================] - 13s 42ms/step - loss: 1.8086 - mse: 5.1996 - val_loss: 2.8805 - val_mse: 12.6746\n",
      "Epoch 20/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 1.7805 - mse: 5.0513 - val_loss: 2.8252 - val_mse: 12.2099\n",
      "Epoch 21/50\n",
      "307/307 [==============================] - 14s 46ms/step - loss: 1.7573 - mse: 4.9309 - val_loss: 2.7931 - val_mse: 11.9309\n",
      "Epoch 22/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 1.7341 - mse: 4.8116 - val_loss: 2.7364 - val_mse: 11.4700\n",
      "Epoch 23/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 1.7096 - mse: 4.6868 - val_loss: 2.6789 - val_mse: 11.0111\n",
      "Epoch 24/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 1.6861 - mse: 4.5693 - val_loss: 2.6196 - val_mse: 10.5484\n",
      "Epoch 25/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 1.6522 - mse: 4.4069 - val_loss: 2.5571 - val_mse: 10.0715\n",
      "Epoch 26/50\n",
      "307/307 [==============================] - 12s 41ms/step - loss: 1.6291 - mse: 4.2907 - val_loss: 2.5177 - val_mse: 9.7647\n",
      "Epoch 27/50\n",
      "307/307 [==============================] - 13s 42ms/step - loss: 1.6013 - mse: 4.1597 - val_loss: 2.4820 - val_mse: 9.4883\n",
      "Epoch 28/50\n",
      "307/307 [==============================] - 13s 41ms/step - loss: 1.5735 - mse: 4.0316 - val_loss: 2.4251 - val_mse: 9.0737\n",
      "Epoch 29/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.5431 - mse: 3.8937 - val_loss: 2.3935 - val_mse: 8.8350\n",
      "Epoch 30/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.5172 - mse: 3.7771 - val_loss: 2.3303 - val_mse: 8.3950\n",
      "Epoch 31/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.4925 - mse: 3.6690 - val_loss: 2.2823 - val_mse: 8.0618\n",
      "Epoch 32/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.4660 - mse: 3.5549 - val_loss: 2.2285 - val_mse: 7.7003\n",
      "Epoch 33/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.4405 - mse: 3.4429 - val_loss: 2.1691 - val_mse: 7.3146\n",
      "Epoch 34/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.4128 - mse: 3.3251 - val_loss: 2.1332 - val_mse: 7.0773\n",
      "Epoch 35/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.3870 - mse: 3.2201 - val_loss: 2.0755 - val_mse: 6.7205\n",
      "Epoch 36/50\n",
      "307/307 [==============================] - 12s 39ms/step - loss: 1.3638 - mse: 3.1210 - val_loss: 2.0507 - val_mse: 6.5557\n",
      "Epoch 37/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.3451 - mse: 3.0390 - val_loss: 2.0115 - val_mse: 6.3149\n",
      "Epoch 38/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.3294 - mse: 2.9726 - val_loss: 1.9794 - val_mse: 6.1162\n",
      "Epoch 39/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.3140 - mse: 2.9075 - val_loss: 1.9440 - val_mse: 5.9031\n",
      "Epoch 40/50\n",
      "307/307 [==============================] - 12s 40ms/step - loss: 1.2923 - mse: 2.8193 - val_loss: 1.9132 - val_mse: 5.7268\n",
      "Epoch 41/50\n",
      "307/307 [==============================] - 12s 41ms/step - loss: 1.2711 - mse: 2.7363 - val_loss: 1.8510 - val_mse: 5.3895\n",
      "Epoch 42/50\n",
      "307/307 [==============================] - 13s 41ms/step - loss: 1.2170 - mse: 2.5245 - val_loss: 1.7432 - val_mse: 4.7658\n",
      "Epoch 43/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 1.1617 - mse: 2.2928 - val_loss: 1.7170 - val_mse: 4.5953\n",
      "Epoch 44/50\n",
      "307/307 [==============================] - 13s 42ms/step - loss: 1.1313 - mse: 2.1758 - val_loss: 1.6688 - val_mse: 4.3464\n",
      "Epoch 45/50\n",
      "307/307 [==============================] - 13s 43ms/step - loss: 1.1135 - mse: 2.1086 - val_loss: 1.6263 - val_mse: 4.1269\n",
      "Epoch 46/50\n",
      "225/307 [====================>.........] - ETA: 2s - loss: 1.0996 - mse: 2.0567"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\prototype_LNH.ipynb Cell 122'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/TEAMPROJ/Final_temp/Team_Project/prototype_LNH.ipynb#ch0000148?line=0'>1</a>\u001b[0m \u001b[39m# 모델 훈련\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/TEAMPROJ/Final_temp/Team_Project/prototype_LNH.ipynb#ch0000148?line=1'>2</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(train_data,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49mtest_data,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/TEAMPROJ/Final_temp/Team_Project/prototype_LNH.ipynb#ch0000148?line=3'>4</a>\u001b[0m \u001b[39m# 손실 함수 그래프\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/TEAMPROJ/Final_temp/Team_Project/prototype_LNH.ipynb#ch0000148?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_loss_curve\u001b[39m(history,total_epoch\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1401'>1402</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1402'>1403</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1403'>1404</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1404'>1405</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1405'>1406</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1406'>1407</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1407'>1408</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1408'>1409</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1409'>1410</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/keras/engine/training.py?line=1410'>1411</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2449'>2450</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2450'>2451</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2451'>2452</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2452'>2453</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=2453'>2454</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1859'>1860</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1860'>1861</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1861'>1862</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1862'>1863</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1863'>1864</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1864'>1865</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=1865'>1866</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=494'>495</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=495'>496</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=508'>509</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/function.py?line=509'>510</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/TEAMPROJ/Final_temp/Team_Project/.venv/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=50,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=8,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=50,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=64,return_sequences=False))\n",
    "model.add(Dense(units=32,activation='linear'))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=8,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=50,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16ae22c5cf5bfc3495ed4b74ec927ee5dacfe7503530ef7b23599a743f937e94"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
