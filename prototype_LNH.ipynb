{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. STUDY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__) # .__version__ 속성으로 버전을 확인함\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 간단한 딥러닝 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1) (10,)\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습에 사용할 입력 데이터를 준비함.\n",
    "# y=x+1 관계를 갖는 숫자를 x,y 변수에 각각 10개씩 입력함.\n",
    "# 이 때, x변수의 숫자 배열을 (10행 1열) 형태의 2차원 배열로 변환함.\n",
    "x=[-3,31,-11,4,0,22,-2,-5,-25,-14]\n",
    "y=[-2,32,-10,5,1,23,-1,-4,-24,-13]\n",
    "\n",
    "X_train=np.array(x).reshape(-1,1)\n",
    "y_train=np.array(y)\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "케라스 Sequential API는 레이어 여러 개를 연결하여 신경망 모델을 구성하는 도구이다.  \n",
    "  \n",
    "간단한 아키텍처를 가지면서도 대부분의 딥러닝 모델을 만들 수 있다는 장점이 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential() # Sequential 모델 인스턴스를 생성함\n",
    "\n",
    "\n",
    "# add 메소드를 사용하여 완전 연결 레이어(Dense)를 모델에 추가함.\n",
    "\n",
    "# 입력 데이터의 차원(input_dim)은 모델 학습에 사용하는 설명 변수(피처)의 개수를 지정하는데,\n",
    "# 여기서는 1개의 피처를 사용하므로 1로 설정함.\n",
    "\n",
    "# 완전 연결 레이어의 출력값은 목표 레이블(Y)을 예측함\n",
    "# 한 개의 연속성 수치(ex.주택 가격)를 예측하는 회귀 문제이므로 유닛(unit) 개수는 1임\n",
    "# 활성화(activation) 함수로 'linear' 옵션을 지정하여 선형 함수의 출력을 그대로 사용함.\n",
    "model.add(Dense(units=1,activation='linear',input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary 메소드를 이용하여 모델 아키텍처(구조)를 확인함\n",
    "# 딥러닝 모델이 학습할 모수(파라미터:Param #)는 2개인데,\n",
    "# 일차함수의 기울기(회귀계수)와 절편(상수항)임.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 훈련하는데 필요한 기본 설정을 compile 함수에 지정하는데,\n",
    "# 옵티마이저(optimizer)와 손실 함수(loss)를 설정함.\n",
    "\n",
    "# adam 옵티마이저를 선택하고 회귀 분석의 손실 함수인 평균제곱오차(mse)를 지정함.\n",
    "\n",
    "# metrics 옵션에 보조 평가 지표를 추가할 수 있는데,\n",
    "# 여기서는 평균절대오차(mae)를 추가하여 손실 함수를 모니터링할 때 함께 추적하기로 함.\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x249238b3190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit 메소드에 훈련 데이터를 입력하여 모델을 학습시키는데,\n",
    "# 컴파일 단계에서 설정한 adam 옵티마이저와 mse 손실 함수를 가지고 최적의 가중치와 편향을 찾음.\n",
    "\n",
    "# 에포크(epoch)는 전체 입력 데이터를 모두 몇 번 학습할 것인지 반복 횟수를 정함.\n",
    "\n",
    "# verbose 옵션을 False(0)로 지정하면 훈련 과정을 화면에 보여주지 않는데,\n",
    "# 훈련 과정을 표시하려면 1 또는 2를 입력함.\n",
    "model.fit(X_train,y_train,epochs=3000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.89683825]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.9653623], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습을 마친 딥러닝 모델의 가중치를 확인하려면 weights 속성을 보면 됨\n",
    "# 기울기에 해당하는 가중치(kernel:0)와 절편에 해당하는 편향(bias:0) 모두 1에 가까운 값을 가지는데,\n",
    "# 이는 모델 학습을 통해 일차함수 관계식을 매우 근사하게 찾아낸 것으로 볼 수 있다.\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10.830584],\n",
       "       [11.727422],\n",
       "       [12.62426 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터(X)를 predict 메소드에 입력하면 목표 레이블(Y)에 대한 예측값을 얻을 수 있음.\n",
    "model.predict([[11],[12],[13]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 딥러닝을 활용한 회귀 분석 : 보스턴 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시드 고정: 12\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시드 고정\n",
    "SEED=12\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "print('시드 고정:',SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\TEAMPROJ\\Final_temp\\Team_Project\\.venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# sklearn 데이터셋에서 보스턴 주택 데이터셋 로딩\n",
    "from sklearn import datasets\n",
    "housing=datasets.load_boston()\n",
    "X_data=housing.data\n",
    "y_data=housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "print(X_data.shape,y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "입력 데이터의 서로 다른 피처 값의 범위를 비슷한 크기로 맞춰 주면 딥러닝 모델의 성능을 확보하는데 유리한데,  \n",
    "  \n",
    "이것을 피처 스케일링이라고 부름.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.18      , 0.06781525, 0.        , 0.31481481,\n",
       "       0.57750527, 0.64160659, 0.26920314, 0.        , 0.20801527,\n",
       "       0.28723404, 1.        , 0.08967991])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMaxScaler를 사용하여 입력 데이터(X_data)의 모든 피처 값을 0~1 범위로 정규화 처리함.\n",
    "# 피처 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "X_data_scaled=scaler.fit_transform(X_data)\n",
    "\n",
    "X_data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (404,)\n",
      "(102, 13) (102,)\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습에 사용하기 위하여 훈련 데이터(80%)와 검증 데이터(20%)를 분할함.\n",
    "# 학습 - 테스트 데이터셋 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_data,y_data,test_size=0.2,shuffle=True,random_state=SEED)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MLP 모델 아키텍처 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결(Dense) 레이어만 사용하여 5개 레이어를 갖는 다층 신경망(MLP)을 만든다.  \n",
    "  \n",
    "레이어를 추가할 때는 add 함수를 사용한다.  \n",
    "  \n",
    "은닉 레이어 4개는 각각 128개, 64개, 32개, 16개의 유닛을 갖는다.  \n",
    "  \n",
    "입력 데이터의 피처가 13개이므로 첫 번째 Dense 레이어의 input_dim에 13을 지정한다.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 심층 신경망\n",
    "def build_model(num_input=1):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(128,activation='relu',input_dim=num_input))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(1,activation='relu'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=build_model(num_input=13)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 미니 배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델을 훈련시킬 때 샘플 데이터를 한 개씩 입력해서 가중치를 갱신하려면 학습 시간이 오래 걸리는 문제가 있음.  \n",
    "  \n",
    "***미니 배치 학습***은 전체 데이터를 여러 개의 작은 배치 단위로 나누고 배치에 들어 있는 샘플 데이터를 묶어서 모델에 입력함.  \n",
    "  \n",
    "배치 단위로 경사하강법을 적용하고 손실 함수를 최소화하는 방향으로 가중치를 업데이트함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 0s - loss: 90.2208 - mae: 7.0756 - 407ms/epoch - 31ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 64.1642 - mae: 5.7309 - 12ms/epoch - 902us/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 64.0255 - mae: 5.6375 - 16ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 59.8935 - mae: 5.7237 - 17ms/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 56.3740 - mae: 5.4424 - 17ms/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 64.8597 - mae: 5.7255 - 18ms/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 55.9069 - mae: 5.6685 - 14ms/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 59.0239 - mae: 5.4474 - 16ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 53.3005 - mae: 5.2688 - 16ms/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 46.8453 - mae: 4.8642 - 15ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 49.0438 - mae: 5.0323 - 17ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 46.4895 - mae: 4.8189 - 15ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 58.3394 - mae: 5.6123 - 50ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 42.3440 - mae: 4.6123 - 21ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 44.8931 - mae: 4.6854 - 19ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 38.6946 - mae: 4.3805 - 18ms/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 39.6368 - mae: 4.5910 - 19ms/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 39.9005 - mae: 4.5373 - 17ms/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 35.7314 - mae: 4.2159 - 17ms/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 34.0336 - mae: 4.1258 - 15ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 38.6308 - mae: 4.6071 - 18ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 39.0641 - mae: 4.5982 - 15ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 37.6668 - mae: 4.3431 - 13ms/epoch - 997us/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 36.2712 - mae: 4.3668 - 15ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 30.8364 - mae: 4.0230 - 15ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 30.2662 - mae: 4.0130 - 15ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 29.2786 - mae: 3.8398 - 15ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 30.9011 - mae: 4.0383 - 16ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 32.7829 - mae: 4.2887 - 16ms/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 30.9590 - mae: 4.0465 - 17ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 27.5047 - mae: 3.7498 - 16ms/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 32.3170 - mae: 4.2155 - 16ms/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 40.6265 - mae: 4.9071 - 17ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 48.0018 - mae: 5.3645 - 17ms/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 34.2848 - mae: 4.1828 - 16ms/epoch - 1ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 32.9476 - mae: 4.2563 - 17ms/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 29.7233 - mae: 3.9528 - 16ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 28.6280 - mae: 3.8556 - 16ms/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 32.6144 - mae: 4.3094 - 15ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 26.6867 - mae: 3.7710 - 17ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 25.1271 - mae: 3.5971 - 17ms/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 28.2037 - mae: 3.8884 - 17ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 24.9302 - mae: 3.5833 - 16ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 23.4687 - mae: 3.6126 - 17ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 23.2022 - mae: 3.6273 - 16ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 28.5310 - mae: 3.9872 - 15ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 23.0256 - mae: 3.5776 - 17ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 22.9616 - mae: 3.5420 - 16ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 22.9510 - mae: 3.5974 - 17ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 22.5900 - mae: 3.5523 - 16ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 20.3832 - mae: 3.3466 - 17ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 25.0086 - mae: 3.8071 - 16ms/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 26.3167 - mae: 3.8970 - 16ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 30.0963 - mae: 3.9958 - 15ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 26.0252 - mae: 3.8822 - 15ms/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 21.9733 - mae: 3.4568 - 16ms/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 26.3157 - mae: 3.7660 - 15ms/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 23.3234 - mae: 3.5044 - 16ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 19.9016 - mae: 3.3024 - 16ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 23.6907 - mae: 3.5220 - 15ms/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 24.0144 - mae: 3.6644 - 22ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 22.3271 - mae: 3.5503 - 23ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 21.9729 - mae: 3.5274 - 23ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 20.4293 - mae: 3.4645 - 21ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 28.1231 - mae: 4.1337 - 16ms/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 24.5286 - mae: 3.5937 - 17ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 21.9476 - mae: 3.4428 - 18ms/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 19.9167 - mae: 3.3647 - 17ms/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 18.2665 - mae: 3.1735 - 17ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 18.5978 - mae: 3.2358 - 15ms/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 17.9875 - mae: 3.1271 - 15ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 18.6258 - mae: 3.2165 - 15ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 21.1500 - mae: 3.3101 - 17ms/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 22.9933 - mae: 3.6896 - 15ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 17.3658 - mae: 3.0438 - 16ms/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 24.5991 - mae: 3.7928 - 16ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 21.2481 - mae: 3.5334 - 16ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 18.5271 - mae: 3.1515 - 16ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 18.9925 - mae: 3.3458 - 17ms/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 20.1966 - mae: 3.3323 - 16ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 19.9702 - mae: 3.4382 - 16ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 18.0235 - mae: 3.1009 - 15ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 18.5946 - mae: 3.1884 - 17ms/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 22.0415 - mae: 3.4906 - 14ms/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 28.6967 - mae: 4.2275 - 15ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 21.4545 - mae: 3.4486 - 16ms/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 15.7254 - mae: 2.9105 - 18ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 19.2303 - mae: 3.2143 - 23ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 19.8284 - mae: 3.2826 - 21ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 18.6379 - mae: 3.2019 - 21ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 16.4366 - mae: 2.9550 - 17ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 16.8477 - mae: 2.9656 - 17ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 17.4118 - mae: 3.1587 - 16ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 16.9975 - mae: 3.0291 - 15ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 17.3133 - mae: 3.0197 - 16ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 22.5440 - mae: 3.5882 - 21ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 18.3141 - mae: 3.1434 - 23ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 18.8636 - mae: 3.3185 - 22ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 18.1752 - mae: 3.1667 - 20ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 17.2522 - mae: 3.2310 - 20ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24925a27e50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=32,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "evaluate 함수에 테스트 데이터를 입력하여 모델의 일반화 성능을 평가함  \n",
    "  \n",
    "loss는 11.93이고 mae는 2.57임  \n",
    "  \n",
    "검증 손실이 훈련 손실보다 크기 때문에 과대적합으로 판단됨  \n",
    "  \n",
    "배치 크기에 따라 모델 성능이 달라질 수 있기 때문에 모델을 설계할 때 중요하게 고려해야 함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 21.7316 - mae: 3.3472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21.731616973876953, 3.347184658050537]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "학습 데이터 일부(여기서는 25%)를 검증 데이터를 사용하여 교차 검증을 해봄  \n",
    "  \n",
    "fit 메소드의 validation_split 옵션에 테스트 데이터셋 비율을 입력하면 됨  \n",
    "  \n",
    "마지막 200번째 에포크 학습이 끝났을 때 훈련 손실이 검증 손실보다 작은 값이므로 과대적합 상태로 판단됨.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 - 1s - loss: 1237.2273 - mae: 25.6319 - val_loss: 181.4406 - val_mae: 11.0436 - 541ms/epoch - 54ms/step\n",
      "Epoch 2/200\n",
      "10/10 - 0s - loss: 172.0373 - mae: 10.3364 - val_loss: 102.9056 - val_mae: 7.0507 - 30ms/epoch - 3ms/step\n",
      "Epoch 3/200\n",
      "10/10 - 0s - loss: 88.3426 - mae: 6.7461 - val_loss: 60.3246 - val_mae: 6.2380 - 35ms/epoch - 3ms/step\n",
      "Epoch 4/200\n",
      "10/10 - 0s - loss: 76.0710 - mae: 6.6196 - val_loss: 59.9225 - val_mae: 5.6343 - 31ms/epoch - 3ms/step\n",
      "Epoch 5/200\n",
      "10/10 - 0s - loss: 73.5757 - mae: 6.1326 - val_loss: 59.5305 - val_mae: 5.9455 - 33ms/epoch - 3ms/step\n",
      "Epoch 6/200\n",
      "10/10 - 0s - loss: 72.6879 - mae: 6.0497 - val_loss: 58.8538 - val_mae: 5.3517 - 33ms/epoch - 3ms/step\n",
      "Epoch 7/200\n",
      "10/10 - 0s - loss: 70.4425 - mae: 5.7623 - val_loss: 55.3603 - val_mae: 5.8217 - 33ms/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "10/10 - 0s - loss: 71.0295 - mae: 6.3172 - val_loss: 54.2397 - val_mae: 5.2034 - 32ms/epoch - 3ms/step\n",
      "Epoch 9/200\n",
      "10/10 - 0s - loss: 70.3441 - mae: 5.6543 - val_loss: 53.1692 - val_mae: 5.4573 - 32ms/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "10/10 - 0s - loss: 69.5205 - mae: 6.0206 - val_loss: 52.7474 - val_mae: 5.1982 - 36ms/epoch - 4ms/step\n",
      "Epoch 11/200\n",
      "10/10 - 0s - loss: 67.7216 - mae: 5.8155 - val_loss: 52.3374 - val_mae: 5.4589 - 33ms/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "10/10 - 0s - loss: 66.8608 - mae: 5.6907 - val_loss: 51.6711 - val_mae: 5.2955 - 32ms/epoch - 3ms/step\n",
      "Epoch 13/200\n",
      "10/10 - 0s - loss: 67.0047 - mae: 5.9009 - val_loss: 50.8270 - val_mae: 5.1277 - 32ms/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "10/10 - 0s - loss: 66.5613 - mae: 5.6182 - val_loss: 51.0500 - val_mae: 5.0271 - 33ms/epoch - 3ms/step\n",
      "Epoch 15/200\n",
      "10/10 - 0s - loss: 65.8708 - mae: 5.5860 - val_loss: 50.7169 - val_mae: 5.4162 - 33ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "10/10 - 0s - loss: 65.2119 - mae: 5.7485 - val_loss: 50.7439 - val_mae: 4.9945 - 33ms/epoch - 3ms/step\n",
      "Epoch 17/200\n",
      "10/10 - 0s - loss: 66.5427 - mae: 5.4482 - val_loss: 52.7933 - val_mae: 5.6983 - 50ms/epoch - 5ms/step\n",
      "Epoch 18/200\n",
      "10/10 - 0s - loss: 66.5312 - mae: 5.7751 - val_loss: 51.4628 - val_mae: 4.8125 - 35ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "10/10 - 0s - loss: 67.4992 - mae: 5.8753 - val_loss: 49.6249 - val_mae: 5.3225 - 35ms/epoch - 4ms/step\n",
      "Epoch 20/200\n",
      "10/10 - 0s - loss: 64.2430 - mae: 5.4704 - val_loss: 49.6550 - val_mae: 5.1243 - 34ms/epoch - 3ms/step\n",
      "Epoch 21/200\n",
      "10/10 - 0s - loss: 63.3247 - mae: 5.6651 - val_loss: 48.6843 - val_mae: 5.1772 - 34ms/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "10/10 - 0s - loss: 62.5624 - mae: 5.4196 - val_loss: 48.2928 - val_mae: 5.0761 - 31ms/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "10/10 - 0s - loss: 62.4926 - mae: 5.6003 - val_loss: 47.7859 - val_mae: 5.0492 - 32ms/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "10/10 - 0s - loss: 62.1325 - mae: 5.2775 - val_loss: 46.8217 - val_mae: 5.0270 - 31ms/epoch - 3ms/step\n",
      "Epoch 25/200\n",
      "10/10 - 0s - loss: 61.9593 - mae: 5.6945 - val_loss: 47.0138 - val_mae: 4.9173 - 34ms/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "10/10 - 0s - loss: 60.8538 - mae: 5.3302 - val_loss: 46.6757 - val_mae: 4.9940 - 25ms/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "10/10 - 0s - loss: 60.4112 - mae: 5.2576 - val_loss: 46.8376 - val_mae: 5.2100 - 39ms/epoch - 4ms/step\n",
      "Epoch 28/200\n",
      "10/10 - 0s - loss: 61.0310 - mae: 5.4549 - val_loss: 46.2748 - val_mae: 4.9571 - 30ms/epoch - 3ms/step\n",
      "Epoch 29/200\n",
      "10/10 - 0s - loss: 59.0595 - mae: 5.4197 - val_loss: 45.4292 - val_mae: 4.9025 - 33ms/epoch - 3ms/step\n",
      "Epoch 30/200\n",
      "10/10 - 0s - loss: 59.9705 - mae: 5.2066 - val_loss: 46.6246 - val_mae: 5.2563 - 35ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "10/10 - 0s - loss: 59.1093 - mae: 5.2200 - val_loss: 44.0430 - val_mae: 4.6814 - 32ms/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "10/10 - 0s - loss: 58.5340 - mae: 5.4660 - val_loss: 45.1381 - val_mae: 4.5204 - 33ms/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "10/10 - 0s - loss: 58.0550 - mae: 5.1958 - val_loss: 43.5068 - val_mae: 4.8842 - 34ms/epoch - 3ms/step\n",
      "Epoch 34/200\n",
      "10/10 - 0s - loss: 55.9078 - mae: 5.1608 - val_loss: 43.3035 - val_mae: 4.4793 - 32ms/epoch - 3ms/step\n",
      "Epoch 35/200\n",
      "10/10 - 0s - loss: 57.4182 - mae: 5.3584 - val_loss: 43.0117 - val_mae: 4.4338 - 31ms/epoch - 3ms/step\n",
      "Epoch 36/200\n",
      "10/10 - 0s - loss: 57.5467 - mae: 5.2006 - val_loss: 48.8357 - val_mae: 5.5704 - 33ms/epoch - 3ms/step\n",
      "Epoch 37/200\n",
      "10/10 - 0s - loss: 59.5686 - mae: 5.1204 - val_loss: 43.2339 - val_mae: 4.9971 - 32ms/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "10/10 - 0s - loss: 62.8033 - mae: 5.8841 - val_loss: 48.6846 - val_mae: 4.4304 - 34ms/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "10/10 - 0s - loss: 55.6293 - mae: 4.9593 - val_loss: 48.6953 - val_mae: 5.6038 - 33ms/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "10/10 - 0s - loss: 54.5994 - mae: 4.9849 - val_loss: 41.7224 - val_mae: 4.4067 - 33ms/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "10/10 - 0s - loss: 52.8258 - mae: 5.1286 - val_loss: 41.3048 - val_mae: 4.3148 - 33ms/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "10/10 - 0s - loss: 51.0324 - mae: 4.9908 - val_loss: 39.9549 - val_mae: 4.5156 - 31ms/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "10/10 - 0s - loss: 50.7732 - mae: 4.7639 - val_loss: 40.5774 - val_mae: 4.8257 - 35ms/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "10/10 - 0s - loss: 49.3633 - mae: 4.8648 - val_loss: 38.1349 - val_mae: 4.1479 - 32ms/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "10/10 - 0s - loss: 47.6248 - mae: 4.6679 - val_loss: 39.2782 - val_mae: 4.5408 - 34ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "10/10 - 0s - loss: 46.8402 - mae: 4.6408 - val_loss: 43.3815 - val_mae: 5.1215 - 33ms/epoch - 3ms/step\n",
      "Epoch 47/200\n",
      "10/10 - 0s - loss: 50.4551 - mae: 4.8360 - val_loss: 46.6304 - val_mae: 5.4676 - 33ms/epoch - 3ms/step\n",
      "Epoch 48/200\n",
      "10/10 - 0s - loss: 47.4097 - mae: 4.9844 - val_loss: 38.5527 - val_mae: 4.0466 - 32ms/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "10/10 - 0s - loss: 51.5682 - mae: 5.1877 - val_loss: 43.2922 - val_mae: 4.3320 - 31ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "10/10 - 0s - loss: 47.2707 - mae: 4.8609 - val_loss: 37.7140 - val_mae: 4.0119 - 33ms/epoch - 3ms/step\n",
      "Epoch 51/200\n",
      "10/10 - 0s - loss: 45.3942 - mae: 4.5900 - val_loss: 44.7438 - val_mae: 5.3246 - 59ms/epoch - 6ms/step\n",
      "Epoch 52/200\n",
      "10/10 - 0s - loss: 44.9223 - mae: 4.6054 - val_loss: 41.1751 - val_mae: 4.9613 - 42ms/epoch - 4ms/step\n",
      "Epoch 53/200\n",
      "10/10 - 0s - loss: 47.0414 - mae: 5.1833 - val_loss: 41.4249 - val_mae: 4.1787 - 35ms/epoch - 4ms/step\n",
      "Epoch 54/200\n",
      "10/10 - 0s - loss: 41.6748 - mae: 4.5598 - val_loss: 34.7150 - val_mae: 4.0626 - 37ms/epoch - 4ms/step\n",
      "Epoch 55/200\n",
      "10/10 - 0s - loss: 41.4927 - mae: 4.4845 - val_loss: 34.4586 - val_mae: 4.0136 - 36ms/epoch - 4ms/step\n",
      "Epoch 56/200\n",
      "10/10 - 0s - loss: 39.2049 - mae: 4.2871 - val_loss: 35.1200 - val_mae: 3.9991 - 34ms/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "10/10 - 0s - loss: 40.4937 - mae: 4.4986 - val_loss: 35.8089 - val_mae: 4.0324 - 32ms/epoch - 3ms/step\n",
      "Epoch 58/200\n",
      "10/10 - 0s - loss: 42.1345 - mae: 4.6126 - val_loss: 32.5174 - val_mae: 3.9131 - 32ms/epoch - 3ms/step\n",
      "Epoch 59/200\n",
      "10/10 - 0s - loss: 36.5613 - mae: 4.1770 - val_loss: 35.2518 - val_mae: 4.4178 - 34ms/epoch - 3ms/step\n",
      "Epoch 60/200\n",
      "10/10 - 0s - loss: 36.2931 - mae: 4.1918 - val_loss: 39.3133 - val_mae: 4.8668 - 33ms/epoch - 3ms/step\n",
      "Epoch 61/200\n",
      "10/10 - 0s - loss: 36.8567 - mae: 4.3297 - val_loss: 33.5138 - val_mae: 4.2634 - 31ms/epoch - 3ms/step\n",
      "Epoch 62/200\n",
      "10/10 - 0s - loss: 36.8029 - mae: 4.3691 - val_loss: 32.9360 - val_mae: 4.1821 - 33ms/epoch - 3ms/step\n",
      "Epoch 63/200\n",
      "10/10 - 0s - loss: 35.4485 - mae: 4.2966 - val_loss: 32.5671 - val_mae: 3.8191 - 33ms/epoch - 3ms/step\n",
      "Epoch 64/200\n",
      "10/10 - 0s - loss: 34.7327 - mae: 4.1975 - val_loss: 34.0100 - val_mae: 3.8596 - 32ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "10/10 - 0s - loss: 34.7267 - mae: 4.1365 - val_loss: 31.6836 - val_mae: 3.9179 - 36ms/epoch - 4ms/step\n",
      "Epoch 66/200\n",
      "10/10 - 0s - loss: 32.5958 - mae: 4.0530 - val_loss: 33.4136 - val_mae: 4.3958 - 33ms/epoch - 3ms/step\n",
      "Epoch 67/200\n",
      "10/10 - 0s - loss: 32.0783 - mae: 4.0518 - val_loss: 53.2573 - val_mae: 6.2595 - 35ms/epoch - 3ms/step\n",
      "Epoch 68/200\n",
      "10/10 - 0s - loss: 45.7209 - mae: 5.1307 - val_loss: 36.6505 - val_mae: 4.8264 - 31ms/epoch - 3ms/step\n",
      "Epoch 69/200\n",
      "10/10 - 0s - loss: 34.2006 - mae: 4.2237 - val_loss: 33.1872 - val_mae: 4.3505 - 82ms/epoch - 8ms/step\n",
      "Epoch 70/200\n",
      "10/10 - 0s - loss: 32.1469 - mae: 4.0337 - val_loss: 33.8114 - val_mae: 4.5348 - 41ms/epoch - 4ms/step\n",
      "Epoch 71/200\n",
      "10/10 - 0s - loss: 32.9983 - mae: 4.1231 - val_loss: 32.1409 - val_mae: 4.2267 - 34ms/epoch - 3ms/step\n",
      "Epoch 72/200\n",
      "10/10 - 0s - loss: 31.4997 - mae: 4.0550 - val_loss: 30.6147 - val_mae: 4.0720 - 33ms/epoch - 3ms/step\n",
      "Epoch 73/200\n",
      "10/10 - 0s - loss: 30.0526 - mae: 3.9338 - val_loss: 30.8225 - val_mae: 3.9037 - 34ms/epoch - 3ms/step\n",
      "Epoch 74/200\n",
      "10/10 - 0s - loss: 29.7345 - mae: 3.9186 - val_loss: 30.6087 - val_mae: 3.7721 - 33ms/epoch - 3ms/step\n",
      "Epoch 75/200\n",
      "10/10 - 0s - loss: 29.9583 - mae: 4.0301 - val_loss: 32.7502 - val_mae: 3.7296 - 31ms/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "10/10 - 0s - loss: 31.4140 - mae: 4.0531 - val_loss: 31.9343 - val_mae: 4.4000 - 31ms/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "10/10 - 0s - loss: 31.6273 - mae: 4.1383 - val_loss: 31.9536 - val_mae: 4.2599 - 32ms/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "10/10 - 0s - loss: 27.5883 - mae: 3.8506 - val_loss: 30.7004 - val_mae: 4.2154 - 34ms/epoch - 3ms/step\n",
      "Epoch 79/200\n",
      "10/10 - 0s - loss: 27.3793 - mae: 3.8128 - val_loss: 28.2737 - val_mae: 3.7968 - 33ms/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "10/10 - 0s - loss: 27.7276 - mae: 3.8002 - val_loss: 29.7613 - val_mae: 4.0331 - 32ms/epoch - 3ms/step\n",
      "Epoch 81/200\n",
      "10/10 - 0s - loss: 29.4591 - mae: 4.0557 - val_loss: 33.4401 - val_mae: 4.6714 - 33ms/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "10/10 - 0s - loss: 26.0116 - mae: 3.7976 - val_loss: 28.4887 - val_mae: 3.9411 - 31ms/epoch - 3ms/step\n",
      "Epoch 83/200\n",
      "10/10 - 0s - loss: 25.1458 - mae: 3.6532 - val_loss: 32.9005 - val_mae: 4.5434 - 33ms/epoch - 3ms/step\n",
      "Epoch 84/200\n",
      "10/10 - 0s - loss: 25.5006 - mae: 3.7379 - val_loss: 28.1003 - val_mae: 3.5236 - 30ms/epoch - 3ms/step\n",
      "Epoch 85/200\n",
      "10/10 - 0s - loss: 25.8206 - mae: 3.7569 - val_loss: 27.5633 - val_mae: 3.7985 - 34ms/epoch - 3ms/step\n",
      "Epoch 86/200\n",
      "10/10 - 0s - loss: 25.1363 - mae: 3.7356 - val_loss: 30.5882 - val_mae: 3.6124 - 31ms/epoch - 3ms/step\n",
      "Epoch 87/200\n",
      "10/10 - 0s - loss: 29.2021 - mae: 4.0055 - val_loss: 36.4856 - val_mae: 4.9246 - 33ms/epoch - 3ms/step\n",
      "Epoch 88/200\n",
      "10/10 - 0s - loss: 29.6210 - mae: 4.1111 - val_loss: 27.8682 - val_mae: 3.9992 - 33ms/epoch - 3ms/step\n",
      "Epoch 89/200\n",
      "10/10 - 0s - loss: 23.5035 - mae: 3.6050 - val_loss: 27.8029 - val_mae: 3.9514 - 32ms/epoch - 3ms/step\n",
      "Epoch 90/200\n",
      "10/10 - 0s - loss: 23.7676 - mae: 3.5229 - val_loss: 28.7945 - val_mae: 3.8963 - 32ms/epoch - 3ms/step\n",
      "Epoch 91/200\n",
      "10/10 - 0s - loss: 25.0449 - mae: 3.7699 - val_loss: 32.5043 - val_mae: 4.6929 - 32ms/epoch - 3ms/step\n",
      "Epoch 92/200\n",
      "10/10 - 0s - loss: 25.9755 - mae: 3.8684 - val_loss: 28.0005 - val_mae: 3.5666 - 31ms/epoch - 3ms/step\n",
      "Epoch 93/200\n",
      "10/10 - 0s - loss: 23.7018 - mae: 3.7356 - val_loss: 27.6452 - val_mae: 3.4643 - 33ms/epoch - 3ms/step\n",
      "Epoch 94/200\n",
      "10/10 - 0s - loss: 23.1179 - mae: 3.5591 - val_loss: 26.8427 - val_mae: 3.5742 - 33ms/epoch - 3ms/step\n",
      "Epoch 95/200\n",
      "10/10 - 0s - loss: 21.4264 - mae: 3.5119 - val_loss: 26.3927 - val_mae: 3.5713 - 32ms/epoch - 3ms/step\n",
      "Epoch 96/200\n",
      "10/10 - 0s - loss: 22.0608 - mae: 3.3800 - val_loss: 31.9674 - val_mae: 4.3620 - 30ms/epoch - 3ms/step\n",
      "Epoch 97/200\n",
      "10/10 - 0s - loss: 20.5878 - mae: 3.4820 - val_loss: 24.6442 - val_mae: 3.5051 - 31ms/epoch - 3ms/step\n",
      "Epoch 98/200\n",
      "10/10 - 0s - loss: 22.6619 - mae: 3.6414 - val_loss: 26.4084 - val_mae: 3.8321 - 32ms/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "10/10 - 0s - loss: 20.2431 - mae: 3.3640 - val_loss: 26.5574 - val_mae: 3.3082 - 33ms/epoch - 3ms/step\n",
      "Epoch 100/200\n",
      "10/10 - 0s - loss: 23.0589 - mae: 3.4823 - val_loss: 29.0565 - val_mae: 4.0355 - 33ms/epoch - 3ms/step\n",
      "Epoch 101/200\n",
      "10/10 - 0s - loss: 20.1978 - mae: 3.3683 - val_loss: 23.7307 - val_mae: 3.2307 - 31ms/epoch - 3ms/step\n",
      "Epoch 102/200\n",
      "10/10 - 0s - loss: 18.7320 - mae: 3.2846 - val_loss: 23.9605 - val_mae: 3.2990 - 31ms/epoch - 3ms/step\n",
      "Epoch 103/200\n",
      "10/10 - 0s - loss: 20.9013 - mae: 3.3021 - val_loss: 26.1309 - val_mae: 3.8820 - 32ms/epoch - 3ms/step\n",
      "Epoch 104/200\n",
      "10/10 - 0s - loss: 28.3168 - mae: 4.0930 - val_loss: 33.1376 - val_mae: 4.5633 - 46ms/epoch - 5ms/step\n",
      "Epoch 105/200\n",
      "10/10 - 0s - loss: 22.3136 - mae: 3.5161 - val_loss: 26.3214 - val_mae: 3.5050 - 35ms/epoch - 3ms/step\n",
      "Epoch 106/200\n",
      "10/10 - 0s - loss: 20.5097 - mae: 3.4115 - val_loss: 27.5579 - val_mae: 3.3589 - 38ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "10/10 - 0s - loss: 19.9181 - mae: 3.3837 - val_loss: 26.9483 - val_mae: 3.8936 - 34ms/epoch - 3ms/step\n",
      "Epoch 108/200\n",
      "10/10 - 0s - loss: 18.2453 - mae: 3.1983 - val_loss: 26.7363 - val_mae: 3.8510 - 35ms/epoch - 3ms/step\n",
      "Epoch 109/200\n",
      "10/10 - 0s - loss: 20.6634 - mae: 3.3683 - val_loss: 24.7601 - val_mae: 3.4894 - 32ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "10/10 - 0s - loss: 17.1332 - mae: 3.0817 - val_loss: 23.2643 - val_mae: 3.2293 - 35ms/epoch - 3ms/step\n",
      "Epoch 111/200\n",
      "10/10 - 0s - loss: 17.8101 - mae: 3.1786 - val_loss: 25.2900 - val_mae: 3.6915 - 32ms/epoch - 3ms/step\n",
      "Epoch 112/200\n",
      "10/10 - 0s - loss: 17.1731 - mae: 3.1364 - val_loss: 23.2480 - val_mae: 3.3056 - 32ms/epoch - 3ms/step\n",
      "Epoch 113/200\n",
      "10/10 - 0s - loss: 15.8296 - mae: 2.9462 - val_loss: 23.1887 - val_mae: 3.3853 - 33ms/epoch - 3ms/step\n",
      "Epoch 114/200\n",
      "10/10 - 0s - loss: 16.7294 - mae: 3.0109 - val_loss: 24.9549 - val_mae: 3.4613 - 34ms/epoch - 3ms/step\n",
      "Epoch 115/200\n",
      "10/10 - 0s - loss: 18.9706 - mae: 3.2569 - val_loss: 26.0722 - val_mae: 3.6815 - 34ms/epoch - 3ms/step\n",
      "Epoch 116/200\n",
      "10/10 - 0s - loss: 16.9399 - mae: 3.0308 - val_loss: 25.6375 - val_mae: 3.4752 - 33ms/epoch - 3ms/step\n",
      "Epoch 117/200\n",
      "10/10 - 0s - loss: 16.9366 - mae: 2.9987 - val_loss: 25.2146 - val_mae: 3.5806 - 35ms/epoch - 4ms/step\n",
      "Epoch 118/200\n",
      "10/10 - 0s - loss: 15.5868 - mae: 3.0707 - val_loss: 29.5143 - val_mae: 3.7939 - 32ms/epoch - 3ms/step\n",
      "Epoch 119/200\n",
      "10/10 - 0s - loss: 17.7520 - mae: 3.1432 - val_loss: 24.6892 - val_mae: 3.4260 - 35ms/epoch - 3ms/step\n",
      "Epoch 120/200\n",
      "10/10 - 0s - loss: 18.2146 - mae: 3.1451 - val_loss: 26.0209 - val_mae: 3.5745 - 32ms/epoch - 3ms/step\n",
      "Epoch 121/200\n",
      "10/10 - 0s - loss: 18.1673 - mae: 3.1773 - val_loss: 24.0864 - val_mae: 3.7392 - 33ms/epoch - 3ms/step\n",
      "Epoch 122/200\n",
      "10/10 - 0s - loss: 19.2703 - mae: 3.2570 - val_loss: 26.4390 - val_mae: 3.4776 - 32ms/epoch - 3ms/step\n",
      "Epoch 123/200\n",
      "10/10 - 0s - loss: 16.9059 - mae: 3.0477 - val_loss: 23.1271 - val_mae: 3.2707 - 31ms/epoch - 3ms/step\n",
      "Epoch 124/200\n",
      "10/10 - 0s - loss: 16.1311 - mae: 2.9610 - val_loss: 32.1871 - val_mae: 4.3728 - 32ms/epoch - 3ms/step\n",
      "Epoch 125/200\n",
      "10/10 - 0s - loss: 20.1965 - mae: 3.4483 - val_loss: 24.1141 - val_mae: 3.5403 - 35ms/epoch - 3ms/step\n",
      "Epoch 126/200\n",
      "10/10 - 0s - loss: 15.5264 - mae: 2.9986 - val_loss: 24.9232 - val_mae: 3.6784 - 30ms/epoch - 3ms/step\n",
      "Epoch 127/200\n",
      "10/10 - 0s - loss: 17.6100 - mae: 3.1256 - val_loss: 29.9483 - val_mae: 4.2331 - 34ms/epoch - 3ms/step\n",
      "Epoch 128/200\n",
      "10/10 - 0s - loss: 17.8327 - mae: 3.2122 - val_loss: 25.0420 - val_mae: 3.4872 - 33ms/epoch - 3ms/step\n",
      "Epoch 129/200\n",
      "10/10 - 0s - loss: 22.7872 - mae: 3.5184 - val_loss: 26.8298 - val_mae: 3.7059 - 32ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "10/10 - 0s - loss: 18.3224 - mae: 3.2205 - val_loss: 26.2854 - val_mae: 3.8293 - 32ms/epoch - 3ms/step\n",
      "Epoch 131/200\n",
      "10/10 - 0s - loss: 15.2073 - mae: 2.9285 - val_loss: 23.5982 - val_mae: 3.4727 - 34ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "10/10 - 0s - loss: 14.2550 - mae: 2.8650 - val_loss: 24.2537 - val_mae: 3.5998 - 33ms/epoch - 3ms/step\n",
      "Epoch 133/200\n",
      "10/10 - 0s - loss: 15.4873 - mae: 2.9675 - val_loss: 23.3094 - val_mae: 3.6310 - 33ms/epoch - 3ms/step\n",
      "Epoch 134/200\n",
      "10/10 - 0s - loss: 18.2091 - mae: 3.1651 - val_loss: 24.5453 - val_mae: 3.4488 - 33ms/epoch - 3ms/step\n",
      "Epoch 135/200\n",
      "10/10 - 0s - loss: 15.8094 - mae: 2.9063 - val_loss: 25.1175 - val_mae: 3.5695 - 33ms/epoch - 3ms/step\n",
      "Epoch 136/200\n",
      "10/10 - 0s - loss: 14.2832 - mae: 2.8194 - val_loss: 23.3285 - val_mae: 3.5171 - 30ms/epoch - 3ms/step\n",
      "Epoch 137/200\n",
      "10/10 - 0s - loss: 13.5885 - mae: 2.7736 - val_loss: 22.6088 - val_mae: 3.4103 - 33ms/epoch - 3ms/step\n",
      "Epoch 138/200\n",
      "10/10 - 0s - loss: 14.4981 - mae: 2.8073 - val_loss: 26.4178 - val_mae: 3.7650 - 33ms/epoch - 3ms/step\n",
      "Epoch 139/200\n",
      "10/10 - 0s - loss: 13.1591 - mae: 2.7452 - val_loss: 33.4704 - val_mae: 4.5288 - 33ms/epoch - 3ms/step\n",
      "Epoch 140/200\n",
      "10/10 - 0s - loss: 18.3406 - mae: 3.2513 - val_loss: 28.7944 - val_mae: 4.1506 - 32ms/epoch - 3ms/step\n",
      "Epoch 141/200\n",
      "10/10 - 0s - loss: 17.2015 - mae: 3.2236 - val_loss: 34.0189 - val_mae: 4.4108 - 46ms/epoch - 5ms/step\n",
      "Epoch 142/200\n",
      "10/10 - 0s - loss: 15.8756 - mae: 3.0653 - val_loss: 25.2829 - val_mae: 3.8970 - 37ms/epoch - 4ms/step\n",
      "Epoch 143/200\n",
      "10/10 - 0s - loss: 18.1773 - mae: 3.1970 - val_loss: 41.4592 - val_mae: 5.2638 - 37ms/epoch - 4ms/step\n",
      "Epoch 144/200\n",
      "10/10 - 0s - loss: 20.9055 - mae: 3.3558 - val_loss: 30.7057 - val_mae: 3.9414 - 34ms/epoch - 3ms/step\n",
      "Epoch 145/200\n",
      "10/10 - 0s - loss: 13.8678 - mae: 2.8416 - val_loss: 25.5881 - val_mae: 3.6667 - 35ms/epoch - 3ms/step\n",
      "Epoch 146/200\n",
      "10/10 - 0s - loss: 14.9205 - mae: 2.9098 - val_loss: 24.7743 - val_mae: 3.7248 - 36ms/epoch - 4ms/step\n",
      "Epoch 147/200\n",
      "10/10 - 0s - loss: 14.3655 - mae: 2.8516 - val_loss: 24.9750 - val_mae: 3.5328 - 34ms/epoch - 3ms/step\n",
      "Epoch 148/200\n",
      "10/10 - 0s - loss: 17.8885 - mae: 3.1517 - val_loss: 28.0828 - val_mae: 3.4807 - 34ms/epoch - 3ms/step\n",
      "Epoch 149/200\n",
      "10/10 - 0s - loss: 15.7681 - mae: 3.0261 - val_loss: 24.2125 - val_mae: 3.6819 - 32ms/epoch - 3ms/step\n",
      "Epoch 150/200\n",
      "10/10 - 0s - loss: 13.8490 - mae: 2.8157 - val_loss: 24.7868 - val_mae: 3.5251 - 36ms/epoch - 4ms/step\n",
      "Epoch 151/200\n",
      "10/10 - 0s - loss: 16.5058 - mae: 3.0178 - val_loss: 23.4400 - val_mae: 3.5004 - 37ms/epoch - 4ms/step\n",
      "Epoch 152/200\n",
      "10/10 - 0s - loss: 15.6281 - mae: 2.9577 - val_loss: 27.7821 - val_mae: 4.0621 - 38ms/epoch - 4ms/step\n",
      "Epoch 153/200\n",
      "10/10 - 0s - loss: 14.9090 - mae: 2.9522 - val_loss: 25.8699 - val_mae: 3.6035 - 38ms/epoch - 4ms/step\n",
      "Epoch 154/200\n",
      "10/10 - 0s - loss: 14.8887 - mae: 2.8255 - val_loss: 26.7348 - val_mae: 3.7137 - 81ms/epoch - 8ms/step\n",
      "Epoch 155/200\n",
      "10/10 - 0s - loss: 16.0144 - mae: 2.9027 - val_loss: 29.6835 - val_mae: 4.0474 - 41ms/epoch - 4ms/step\n",
      "Epoch 156/200\n",
      "10/10 - 0s - loss: 23.4670 - mae: 3.6064 - val_loss: 26.6806 - val_mae: 3.7248 - 40ms/epoch - 4ms/step\n",
      "Epoch 157/200\n",
      "10/10 - 0s - loss: 15.2534 - mae: 2.9305 - val_loss: 24.8514 - val_mae: 3.4275 - 38ms/epoch - 4ms/step\n",
      "Epoch 158/200\n",
      "10/10 - 0s - loss: 13.8693 - mae: 2.7941 - val_loss: 25.9869 - val_mae: 3.5224 - 37ms/epoch - 4ms/step\n",
      "Epoch 159/200\n",
      "10/10 - 0s - loss: 12.5118 - mae: 2.5932 - val_loss: 24.6251 - val_mae: 3.3993 - 38ms/epoch - 4ms/step\n",
      "Epoch 160/200\n",
      "10/10 - 0s - loss: 15.4152 - mae: 2.9380 - val_loss: 29.4676 - val_mae: 3.7988 - 34ms/epoch - 3ms/step\n",
      "Epoch 161/200\n",
      "10/10 - 0s - loss: 14.3556 - mae: 2.8079 - val_loss: 24.6329 - val_mae: 3.3086 - 38ms/epoch - 4ms/step\n",
      "Epoch 162/200\n",
      "10/10 - 0s - loss: 13.7384 - mae: 2.7684 - val_loss: 28.5297 - val_mae: 3.7555 - 33ms/epoch - 3ms/step\n",
      "Epoch 163/200\n",
      "10/10 - 0s - loss: 14.4443 - mae: 2.9481 - val_loss: 22.8839 - val_mae: 3.2782 - 35ms/epoch - 3ms/step\n",
      "Epoch 164/200\n",
      "10/10 - 0s - loss: 15.0847 - mae: 2.8876 - val_loss: 22.9341 - val_mae: 3.3382 - 33ms/epoch - 3ms/step\n",
      "Epoch 165/200\n",
      "10/10 - 0s - loss: 13.4833 - mae: 2.7758 - val_loss: 23.3490 - val_mae: 3.4837 - 35ms/epoch - 4ms/step\n",
      "Epoch 166/200\n",
      "10/10 - 0s - loss: 11.9147 - mae: 2.5764 - val_loss: 23.2200 - val_mae: 3.2744 - 32ms/epoch - 3ms/step\n",
      "Epoch 167/200\n",
      "10/10 - 0s - loss: 12.7814 - mae: 2.7180 - val_loss: 25.2744 - val_mae: 3.5856 - 33ms/epoch - 3ms/step\n",
      "Epoch 168/200\n",
      "10/10 - 0s - loss: 12.0458 - mae: 2.6855 - val_loss: 23.9453 - val_mae: 3.3181 - 31ms/epoch - 3ms/step\n",
      "Epoch 169/200\n",
      "10/10 - 0s - loss: 12.5737 - mae: 2.6590 - val_loss: 26.5373 - val_mae: 3.6093 - 32ms/epoch - 3ms/step\n",
      "Epoch 170/200\n",
      "10/10 - 0s - loss: 11.9823 - mae: 2.5239 - val_loss: 25.0474 - val_mae: 3.7658 - 31ms/epoch - 3ms/step\n",
      "Epoch 171/200\n",
      "10/10 - 0s - loss: 11.9596 - mae: 2.5945 - val_loss: 25.2883 - val_mae: 3.4984 - 33ms/epoch - 3ms/step\n",
      "Epoch 172/200\n",
      "10/10 - 0s - loss: 13.1160 - mae: 2.7356 - val_loss: 23.2501 - val_mae: 3.3383 - 35ms/epoch - 3ms/step\n",
      "Epoch 173/200\n",
      "10/10 - 0s - loss: 11.6350 - mae: 2.5619 - val_loss: 23.1546 - val_mae: 3.5682 - 36ms/epoch - 4ms/step\n",
      "Epoch 174/200\n",
      "10/10 - 0s - loss: 12.6359 - mae: 2.6382 - val_loss: 24.2569 - val_mae: 3.3931 - 32ms/epoch - 3ms/step\n",
      "Epoch 175/200\n",
      "10/10 - 0s - loss: 11.6843 - mae: 2.5907 - val_loss: 22.9860 - val_mae: 3.3583 - 35ms/epoch - 3ms/step\n",
      "Epoch 176/200\n",
      "10/10 - 0s - loss: 11.5764 - mae: 2.5037 - val_loss: 27.2086 - val_mae: 3.7981 - 32ms/epoch - 3ms/step\n",
      "Epoch 177/200\n",
      "10/10 - 0s - loss: 12.6211 - mae: 2.5986 - val_loss: 20.3947 - val_mae: 3.1977 - 34ms/epoch - 3ms/step\n",
      "Epoch 178/200\n",
      "10/10 - 0s - loss: 12.4553 - mae: 2.5720 - val_loss: 25.4813 - val_mae: 3.5829 - 33ms/epoch - 3ms/step\n",
      "Epoch 179/200\n",
      "10/10 - 0s - loss: 16.2087 - mae: 2.9819 - val_loss: 29.7985 - val_mae: 3.7968 - 34ms/epoch - 3ms/step\n",
      "Epoch 180/200\n",
      "10/10 - 0s - loss: 15.6314 - mae: 3.0454 - val_loss: 26.2229 - val_mae: 3.6252 - 30ms/epoch - 3ms/step\n",
      "Epoch 181/200\n",
      "10/10 - 0s - loss: 14.1425 - mae: 2.7761 - val_loss: 26.1956 - val_mae: 3.6474 - 32ms/epoch - 3ms/step\n",
      "Epoch 182/200\n",
      "10/10 - 0s - loss: 13.9206 - mae: 2.6972 - val_loss: 25.4018 - val_mae: 3.5405 - 32ms/epoch - 3ms/step\n",
      "Epoch 183/200\n",
      "10/10 - 0s - loss: 11.9304 - mae: 2.5565 - val_loss: 22.2320 - val_mae: 3.3205 - 35ms/epoch - 3ms/step\n",
      "Epoch 184/200\n",
      "10/10 - 0s - loss: 11.9087 - mae: 2.5676 - val_loss: 25.2782 - val_mae: 3.6887 - 31ms/epoch - 3ms/step\n",
      "Epoch 185/200\n",
      "10/10 - 0s - loss: 11.6117 - mae: 2.4976 - val_loss: 23.1214 - val_mae: 3.3378 - 33ms/epoch - 3ms/step\n",
      "Epoch 186/200\n",
      "10/10 - 0s - loss: 12.1500 - mae: 2.5572 - val_loss: 23.0601 - val_mae: 3.4936 - 32ms/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "10/10 - 0s - loss: 13.6758 - mae: 2.6734 - val_loss: 30.8957 - val_mae: 4.0899 - 42ms/epoch - 4ms/step\n",
      "Epoch 188/200\n",
      "10/10 - 0s - loss: 12.6900 - mae: 2.6638 - val_loss: 23.8167 - val_mae: 3.5760 - 40ms/epoch - 4ms/step\n",
      "Epoch 189/200\n",
      "10/10 - 0s - loss: 12.5038 - mae: 2.5867 - val_loss: 27.5712 - val_mae: 3.7918 - 35ms/epoch - 3ms/step\n",
      "Epoch 190/200\n",
      "10/10 - 0s - loss: 11.9999 - mae: 2.6495 - val_loss: 25.3619 - val_mae: 3.8269 - 36ms/epoch - 4ms/step\n",
      "Epoch 191/200\n",
      "10/10 - 0s - loss: 14.2395 - mae: 2.7952 - val_loss: 26.7670 - val_mae: 3.8536 - 34ms/epoch - 3ms/step\n",
      "Epoch 192/200\n",
      "10/10 - 0s - loss: 13.7837 - mae: 2.7681 - val_loss: 24.4011 - val_mae: 3.6267 - 35ms/epoch - 3ms/step\n",
      "Epoch 193/200\n",
      "10/10 - 0s - loss: 13.0861 - mae: 2.6514 - val_loss: 24.2277 - val_mae: 3.4517 - 31ms/epoch - 3ms/step\n",
      "Epoch 194/200\n",
      "10/10 - 0s - loss: 11.9353 - mae: 2.5496 - val_loss: 24.3940 - val_mae: 3.6316 - 33ms/epoch - 3ms/step\n",
      "Epoch 195/200\n",
      "10/10 - 0s - loss: 11.8739 - mae: 2.5529 - val_loss: 24.6680 - val_mae: 3.2953 - 33ms/epoch - 3ms/step\n",
      "Epoch 196/200\n",
      "10/10 - 0s - loss: 12.2685 - mae: 2.5745 - val_loss: 27.5583 - val_mae: 3.6652 - 32ms/epoch - 3ms/step\n",
      "Epoch 197/200\n",
      "10/10 - 0s - loss: 11.9653 - mae: 2.5590 - val_loss: 25.7841 - val_mae: 3.7823 - 35ms/epoch - 3ms/step\n",
      "Epoch 198/200\n",
      "10/10 - 0s - loss: 12.7945 - mae: 2.6747 - val_loss: 25.3871 - val_mae: 3.7724 - 32ms/epoch - 3ms/step\n",
      "Epoch 199/200\n",
      "10/10 - 0s - loss: 13.2905 - mae: 2.6067 - val_loss: 26.8289 - val_mae: 3.6589 - 34ms/epoch - 3ms/step\n",
      "Epoch 200/200\n",
      "10/10 - 0s - loss: 11.9782 - mae: 2.6492 - val_loss: 23.7994 - val_mae: 3.2002 - 37ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model=build_model(num_input=13)\n",
    "history=model.fit(X_train,y_train,batch_size=32,epochs=200,validation_split=0.25,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "훈련 손실(loss)과 검증 손실(val_loss)을 그래프로 나타냄  \n",
    "  \n",
    "가로축에는 에포크(epoch)를 놓고 세로축에 손실 함수 값을 표시함  \n",
    "  \n",
    "모델 10에포크까지 매우 빠른 속도로 학습이 되고, 이후 점차 완만하게 학습 속도가 낮아지며  \n",
    "그래프가 평평해지는 추이를 보임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_curve(total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "            history.history['loss'][start-1:total_epoch],\n",
    "            label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "            history.history['val_loss'][start-1:total_epoch],\n",
    "            label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mse')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(total_epoch=200,start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "20에포크 이후의 손실 함수를 그림  \n",
    "  \n",
    "앞의 그래프에서는 훈련 손실과 검증 손실 간에 차이가 드러나지 않았지만,\n",
    "다음의 그래프를 보면 40에포크 이후 과대적합이 커지는 것을 볼 수 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curve(total_epoch=200,start=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 딥러닝을 활용한 분류 예측 : 와인 품질 등급 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시드 고정: 12\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시드 고정\n",
    "SEED=12\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "print(\"시드 고정:\",SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5497, 14) (1000, 13) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('./output/data/wine/train.csv')\n",
    "test=pd.read_csv('./output/data/wine/test.csv')\n",
    "submission=pd.read_csv('./output/data/wine/sample_submission.csv')\n",
    "\n",
    "print(train.shape,test.shape,submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>quality</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.042</td>\n",
       "      <td>9.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.99432</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.2</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.067</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>21.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.99176</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>29.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.99390</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.059</td>\n",
       "      <td>32.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  quality  fixed acidity  volatile acidity  citric acid  \\\n",
       "0      0        5            5.6             0.695         0.06   \n",
       "1      1        5            8.8             0.610         0.14   \n",
       "2      2        5            7.9             0.210         0.39   \n",
       "3      3        6            7.0             0.210         0.31   \n",
       "4      4        6            7.8             0.400         0.26   \n",
       "\n",
       "   residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
       "0             6.8      0.042                  9.0                  84.0   \n",
       "1             2.4      0.067                 10.0                  42.0   \n",
       "2             2.0      0.057                 21.0                 138.0   \n",
       "3             6.0      0.046                 29.0                 108.0   \n",
       "4             9.5      0.059                 32.0                 178.0   \n",
       "\n",
       "   density    pH  sulphates  alcohol   type  \n",
       "0  0.99432  3.44       0.44     10.2  white  \n",
       "1  0.99690  3.19       0.59      9.5    red  \n",
       "2  0.99176  3.05       0.52     10.9  white  \n",
       "3  0.99390  3.26       0.50     10.8  white  \n",
       "4  0.99550  3.04       0.43     10.9  white  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 데이터의 내용을 살펴봄, 목표 변수는 와인 품질을 나타내는 quality 열임.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  quality\n",
       "0      0        0\n",
       "1      1        0\n",
       "2      2        0\n",
       "3      3        0\n",
       "4      4        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제출 파일의 양식을 보면 와인 품질을 나타내는 quality 열에 예측값을 입력해야 함.\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white    4159\n",
       "red      1338\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type 열의 데이터를 살펴봄, 화이트 와인(white)이 4159개, 레드와인(red)이 1338개\n",
    "train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "type 열의 범주형 데이터는 문자열 값을 가짐  \n",
    "  \n",
    "모델 학습에 입력하려면 숫자형 데이터로 변환해야 함  \n",
    "  \n",
    "화이트 와인을 나타내는 'white' 문자열을 숫자 1로 바꾸고,  \n",
    "레드 와인을 나타내는 'red' 문자열을 숫자 0으로 변환함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4159\n",
       "0    1338\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['type']=np.where(train['type']=='white',1,0).astype(int)\n",
    "test['type']=np.where(test['type']=='white',1,0).astype(int)\n",
    "train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2416\n",
       "5    1788\n",
       "7     924\n",
       "4     186\n",
       "8     152\n",
       "3      26\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이번에는 목표 변수인 quality 열의 데이터 개수를 확인함, 6등급 와인의 개수가 가장 많음.\n",
    "\n",
    "train['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "목표 변수는 연속형 숫자 데이터가 아니라, 와인 등급을 나타내는 범주형 데이터임  \n",
    "  \n",
    "케라스 to_categorical 함수를 이용하여 목표 변수를 원핫 인코딩 변환함.  \n",
    "  \n",
    "원핫 인코딩을 하기 전에 숫자 3을 차감하여 와인 등급을 0~6 범위로 바꿈  \n",
    "  \n",
    "와인 등급은 3~9까지 모두 7개 클래스로 구분되는데, 3~9 범위 값으로 원핫 인코딩을 하면  \n",
    "숫자 0부터 최대값인 9까지 10개 클래스로 인식하기 때문임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train=to_categorical(train.loc[:,'quality']-3)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델 학습에 사용할 피처를 선택하고, MinMax 스케일링으로 모든 피처 변수의 데이터를 0~1 범위로  \n",
    "정규화 변환함.  \n",
    "  \n",
    "이때 훈련 데이터(X_train)로 정규화 학습을 하고, 같은 조건을 검증 데이터(X_test)에 적용하여 변환하는 점에 유의함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5497, 12) (5497, 7)\n",
      "(1000, 12)\n"
     ]
    }
   ],
   "source": [
    "# 피처 선택\n",
    "X_train=train.loc[:,'fixed acidity':]\n",
    "X_test=test.loc[:,'fixed acidity':]\n",
    "\n",
    "# 피처 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)\n",
    "\n",
    "print(X_train_scaled.shape,y_train.shape)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 설계 : 드랍아웃 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결 레이어(Dense) 4개 층으로 구성되는 신경망 모델을 구성함  \n",
    "  \n",
    "모델의 과대적합을 방지하기 위하여 드랍아웃(Dropout) 레이어를 추가함  \n",
    "  \n",
    "드랍아웃은 입력 레이어왕 은닉 레이어 간의 연결 중 일부를 랜덤으로 제거한 상태에서 학습하는 기법임  \n",
    "  \n",
    "결과적으로 유닛 사이에 연결된 가중치 수를 줄이는 효과를 얻기 때문에 과대적합을 방지 가능.  \n",
    "  \n",
    "  \n",
    "미니 배치 단위로 학습할 때마다 연결 네트워크에서 제거되는 가중치가 달라짐,  \n",
    "때문에 매번 다른 네트워크 구조를 갖는 모델을 얻게 됨  \n",
    "  \n",
    "즉, 앙상블 효과가 있어 모델 성능이 개선됨  \n",
    "  \n",
    "  \n",
    "Dense 레이어 뒤에 Dropout 레이어를 추가하고, dropout rate를 설정함  \n",
    "  \n",
    "0.2로 설정하면 20% 확률로 랜덤하게 연결을 제거하게 됨  \n",
    "  \n",
    "은닉 레이어의 활성화 함수로 tanh를 사용해 봄  \n",
    "  \n",
    "다중 분류 모델이므로 마지막 출력 레이어의 활성화 함수는 softmax를 적용함  \n",
    "  \n",
    "옵티마이저는 RMSProp, 손실 함수는 categorical_crossentropy를 지정함  \n",
    "  \n",
    "metrics 옵션에 여러 개의 보조 평가 지표를 입력할 수 있음  \n",
    "  \n",
    "여기서는 acc(정확도)와 mae(평균절대값오차)를 지정함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1664      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,231\n",
      "Trainable params: 12,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 심층 신경망 모델\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "def build_model(train_data,train_target):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(128,activation='tanh',input_dim=train_data.shape[1]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64,activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32,activation='tanh'))\n",
    "    model.add(Dense(train_target.shape[1],activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='RMSProp',loss='categorical_crossentropy',metrics=['acc','mae'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=build_model(X_train_scaled,y_train)\n",
    "model.summary()\n",
    "\n",
    "# tanh 함수는 -1~+1 사이의 출력 범위를 가짐\n",
    "# 입력값이 0 근처일 때는 학습율이 좋지만,\n",
    "# 입력값이 커지거나 작아지는 경우 기울기(가중치)가 0에 가까워지므로\n",
    "# 학습이 이루어지지 않는 문제가 생김.\n",
    "\n",
    "# 따라서 ReLU 함수에 비해 사용빈도가 낮음 편임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 콜백 함수 : Early Stopping 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "콜백(callback) 함수를 사용하면 모델 학습 과정을 세밀하게 컨트롤할 수 있음.  \n",
    "  \n",
    "가장 많이 사용되는 방법 중에 Early Stopping이 있음.  \n",
    "  \n",
    "딥러닝 모델 학습에서 에포크 수를 늘려 학습을 계속 반복하면 훈련 데이터에 대한 오차(손실 함수)  \n",
    "를 계속 낮출 수 있음.  \n",
    "  \n",
    "하지만 과대적합을 일으켜 테스트 데이터를 포함한 새로운 데이터에 대한 예측력이 나빠지는 문제가 발생함.  \n",
    "  \n",
    "이때 Early Stopping을 사용하면 과대적합이 발생하기 직전에 학습을 멈출 수 있음.  \n",
    "  \n",
    "홀드아웃으로 검증 데이터를 분할하고, 검증 데이터에 대한 모델 성능이 일정 에포크 동안 좋아지지 않으면  \n",
    "모델 학습을 중단함.  \n",
    "  \n",
    "이때 허용되는 에포크 수를 patience 옵션에 설정함.  \n",
    "  \n",
    "다음의 예제는 200에포크로 설정되어 있지만, 학습 중 10에포크 동안 연속하여  \n",
    "검증 데이터에 대한 손실 함수(val_loss)가 줄어들지 않으면 학습을 멈춤.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "73/73 - 1s - loss: 1.3005 - acc: 0.4574 - mae: 0.1930 - val_loss: 1.1688 - val_acc: 0.5055 - val_mae: 0.1808 - 894ms/epoch - 12ms/step\n",
      "Epoch 2/200\n",
      "73/73 - 0s - loss: 1.1752 - acc: 0.5015 - mae: 0.1779 - val_loss: 1.1034 - val_acc: 0.5430 - val_mae: 0.1732 - 136ms/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "73/73 - 0s - loss: 1.1449 - acc: 0.5169 - mae: 0.1742 - val_loss: 1.0814 - val_acc: 0.5442 - val_mae: 0.1681 - 141ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "73/73 - 0s - loss: 1.1285 - acc: 0.5210 - mae: 0.1719 - val_loss: 1.1267 - val_acc: 0.5042 - val_mae: 0.1698 - 144ms/epoch - 2ms/step\n",
      "Epoch 5/200\n",
      "73/73 - 0s - loss: 1.1177 - acc: 0.5330 - mae: 0.1709 - val_loss: 1.0708 - val_acc: 0.5564 - val_mae: 0.1680 - 145ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "73/73 - 0s - loss: 1.1098 - acc: 0.5240 - mae: 0.1712 - val_loss: 1.0613 - val_acc: 0.5539 - val_mae: 0.1667 - 130ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "73/73 - 0s - loss: 1.1028 - acc: 0.5291 - mae: 0.1704 - val_loss: 1.0571 - val_acc: 0.5503 - val_mae: 0.1658 - 178ms/epoch - 2ms/step\n",
      "Epoch 8/200\n",
      "73/73 - 0s - loss: 1.0996 - acc: 0.5216 - mae: 0.1700 - val_loss: 1.0612 - val_acc: 0.5576 - val_mae: 0.1655 - 148ms/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "73/73 - 0s - loss: 1.1007 - acc: 0.5334 - mae: 0.1693 - val_loss: 1.0609 - val_acc: 0.5588 - val_mae: 0.1666 - 138ms/epoch - 2ms/step\n",
      "Epoch 10/200\n",
      "73/73 - 0s - loss: 1.0927 - acc: 0.5293 - mae: 0.1692 - val_loss: 1.0612 - val_acc: 0.5370 - val_mae: 0.1684 - 143ms/epoch - 2ms/step\n",
      "Epoch 11/200\n",
      "73/73 - 0s - loss: 1.0888 - acc: 0.5357 - mae: 0.1687 - val_loss: 1.0508 - val_acc: 0.5333 - val_mae: 0.1643 - 147ms/epoch - 2ms/step\n",
      "Epoch 12/200\n",
      "73/73 - 0s - loss: 1.0894 - acc: 0.5265 - mae: 0.1689 - val_loss: 1.0499 - val_acc: 0.5552 - val_mae: 0.1659 - 141ms/epoch - 2ms/step\n",
      "Epoch 13/200\n",
      "73/73 - 0s - loss: 1.0859 - acc: 0.5302 - mae: 0.1682 - val_loss: 1.0512 - val_acc: 0.5479 - val_mae: 0.1672 - 143ms/epoch - 2ms/step\n",
      "Epoch 14/200\n",
      "73/73 - 0s - loss: 1.0813 - acc: 0.5400 - mae: 0.1682 - val_loss: 1.0457 - val_acc: 0.5527 - val_mae: 0.1639 - 138ms/epoch - 2ms/step\n",
      "Epoch 15/200\n",
      "73/73 - 0s - loss: 1.0827 - acc: 0.5353 - mae: 0.1680 - val_loss: 1.0499 - val_acc: 0.5515 - val_mae: 0.1654 - 128ms/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "73/73 - 0s - loss: 1.0821 - acc: 0.5372 - mae: 0.1677 - val_loss: 1.0494 - val_acc: 0.5467 - val_mae: 0.1643 - 173ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "73/73 - 0s - loss: 1.0812 - acc: 0.5349 - mae: 0.1679 - val_loss: 1.0466 - val_acc: 0.5588 - val_mae: 0.1670 - 148ms/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "73/73 - 0s - loss: 1.0789 - acc: 0.5360 - mae: 0.1683 - val_loss: 1.0464 - val_acc: 0.5552 - val_mae: 0.1667 - 134ms/epoch - 2ms/step\n",
      "Epoch 19/200\n",
      "73/73 - 0s - loss: 1.0792 - acc: 0.5396 - mae: 0.1678 - val_loss: 1.0375 - val_acc: 0.5600 - val_mae: 0.1642 - 132ms/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "73/73 - 0s - loss: 1.0743 - acc: 0.5432 - mae: 0.1674 - val_loss: 1.0355 - val_acc: 0.5600 - val_mae: 0.1641 - 134ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "73/73 - 0s - loss: 1.0720 - acc: 0.5405 - mae: 0.1668 - val_loss: 1.0395 - val_acc: 0.5539 - val_mae: 0.1654 - 131ms/epoch - 2ms/step\n",
      "Epoch 22/200\n",
      "73/73 - 0s - loss: 1.0735 - acc: 0.5390 - mae: 0.1673 - val_loss: 1.0492 - val_acc: 0.5309 - val_mae: 0.1650 - 142ms/epoch - 2ms/step\n",
      "Epoch 23/200\n",
      "73/73 - 0s - loss: 1.0739 - acc: 0.5424 - mae: 0.1672 - val_loss: 1.0418 - val_acc: 0.5673 - val_mae: 0.1639 - 148ms/epoch - 2ms/step\n",
      "Epoch 24/200\n",
      "73/73 - 0s - loss: 1.0688 - acc: 0.5445 - mae: 0.1662 - val_loss: 1.0342 - val_acc: 0.5527 - val_mae: 0.1652 - 177ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "73/73 - 0s - loss: 1.0670 - acc: 0.5437 - mae: 0.1666 - val_loss: 1.0323 - val_acc: 0.5624 - val_mae: 0.1620 - 147ms/epoch - 2ms/step\n",
      "Epoch 26/200\n",
      "73/73 - 0s - loss: 1.0643 - acc: 0.5447 - mae: 0.1660 - val_loss: 1.0496 - val_acc: 0.5418 - val_mae: 0.1650 - 135ms/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "73/73 - 0s - loss: 1.0618 - acc: 0.5441 - mae: 0.1659 - val_loss: 1.0435 - val_acc: 0.5455 - val_mae: 0.1635 - 124ms/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "73/73 - 0s - loss: 1.0621 - acc: 0.5497 - mae: 0.1657 - val_loss: 1.0335 - val_acc: 0.5479 - val_mae: 0.1634 - 131ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "73/73 - 0s - loss: 1.0614 - acc: 0.5486 - mae: 0.1656 - val_loss: 1.0344 - val_acc: 0.5576 - val_mae: 0.1640 - 125ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "73/73 - 0s - loss: 1.0569 - acc: 0.5439 - mae: 0.1657 - val_loss: 1.0313 - val_acc: 0.5503 - val_mae: 0.1604 - 133ms/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "73/73 - 0s - loss: 1.0578 - acc: 0.5464 - mae: 0.1649 - val_loss: 1.0361 - val_acc: 0.5770 - val_mae: 0.1635 - 135ms/epoch - 2ms/step\n",
      "Epoch 32/200\n",
      "73/73 - 0s - loss: 1.0492 - acc: 0.5554 - mae: 0.1643 - val_loss: 1.0363 - val_acc: 0.5479 - val_mae: 0.1639 - 139ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "73/73 - 0s - loss: 1.0566 - acc: 0.5454 - mae: 0.1653 - val_loss: 1.0344 - val_acc: 0.5576 - val_mae: 0.1633 - 131ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "73/73 - 0s - loss: 1.0551 - acc: 0.5477 - mae: 0.1649 - val_loss: 1.0279 - val_acc: 0.5600 - val_mae: 0.1619 - 133ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "73/73 - 0s - loss: 1.0490 - acc: 0.5546 - mae: 0.1640 - val_loss: 1.0307 - val_acc: 0.5648 - val_mae: 0.1623 - 125ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "73/73 - 0s - loss: 1.0525 - acc: 0.5520 - mae: 0.1645 - val_loss: 1.0345 - val_acc: 0.5661 - val_mae: 0.1634 - 118ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "73/73 - 0s - loss: 1.0467 - acc: 0.5486 - mae: 0.1635 - val_loss: 1.0300 - val_acc: 0.5467 - val_mae: 0.1625 - 125ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "73/73 - 0s - loss: 1.0476 - acc: 0.5533 - mae: 0.1641 - val_loss: 1.0282 - val_acc: 0.5491 - val_mae: 0.1609 - 131ms/epoch - 2ms/step\n",
      "Epoch 39/200\n",
      "73/73 - 0s - loss: 1.0476 - acc: 0.5518 - mae: 0.1635 - val_loss: 1.0271 - val_acc: 0.5539 - val_mae: 0.1615 - 127ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "73/73 - 0s - loss: 1.0460 - acc: 0.5516 - mae: 0.1640 - val_loss: 1.0331 - val_acc: 0.5806 - val_mae: 0.1626 - 146ms/epoch - 2ms/step\n",
      "Epoch 41/200\n",
      "73/73 - 0s - loss: 1.0491 - acc: 0.5509 - mae: 0.1640 - val_loss: 1.0291 - val_acc: 0.5794 - val_mae: 0.1610 - 137ms/epoch - 2ms/step\n",
      "Epoch 42/200\n",
      "73/73 - 0s - loss: 1.0430 - acc: 0.5531 - mae: 0.1632 - val_loss: 1.0354 - val_acc: 0.5830 - val_mae: 0.1646 - 128ms/epoch - 2ms/step\n",
      "Epoch 43/200\n",
      "73/73 - 0s - loss: 1.0465 - acc: 0.5512 - mae: 0.1640 - val_loss: 1.0362 - val_acc: 0.5479 - val_mae: 0.1625 - 140ms/epoch - 2ms/step\n",
      "Epoch 44/200\n",
      "73/73 - 0s - loss: 1.0454 - acc: 0.5518 - mae: 0.1643 - val_loss: 1.0244 - val_acc: 0.5648 - val_mae: 0.1610 - 125ms/epoch - 2ms/step\n",
      "Epoch 45/200\n",
      "73/73 - 0s - loss: 1.0444 - acc: 0.5486 - mae: 0.1637 - val_loss: 1.0311 - val_acc: 0.5648 - val_mae: 0.1616 - 127ms/epoch - 2ms/step\n",
      "Epoch 46/200\n",
      "73/73 - 0s - loss: 1.0445 - acc: 0.5524 - mae: 0.1641 - val_loss: 1.0260 - val_acc: 0.5539 - val_mae: 0.1600 - 127ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "73/73 - 0s - loss: 1.0426 - acc: 0.5503 - mae: 0.1634 - val_loss: 1.0409 - val_acc: 0.5709 - val_mae: 0.1620 - 122ms/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "73/73 - 0s - loss: 1.0411 - acc: 0.5533 - mae: 0.1631 - val_loss: 1.0284 - val_acc: 0.5552 - val_mae: 0.1600 - 121ms/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "73/73 - 0s - loss: 1.0345 - acc: 0.5512 - mae: 0.1626 - val_loss: 1.0259 - val_acc: 0.5648 - val_mae: 0.1609 - 130ms/epoch - 2ms/step\n",
      "Epoch 50/200\n",
      "73/73 - 0s - loss: 1.0407 - acc: 0.5533 - mae: 0.1632 - val_loss: 1.0260 - val_acc: 0.5588 - val_mae: 0.1617 - 141ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "73/73 - 0s - loss: 1.0401 - acc: 0.5557 - mae: 0.1631 - val_loss: 1.0282 - val_acc: 0.5782 - val_mae: 0.1613 - 130ms/epoch - 2ms/step\n",
      "Epoch 52/200\n",
      "73/73 - 0s - loss: 1.0409 - acc: 0.5569 - mae: 0.1631 - val_loss: 1.0411 - val_acc: 0.5527 - val_mae: 0.1639 - 167ms/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "73/73 - 0s - loss: 1.0379 - acc: 0.5531 - mae: 0.1632 - val_loss: 1.0257 - val_acc: 0.5673 - val_mae: 0.1608 - 139ms/epoch - 2ms/step\n",
      "Epoch 54/200\n",
      "73/73 - 0s - loss: 1.0376 - acc: 0.5567 - mae: 0.1627 - val_loss: 1.0265 - val_acc: 0.5576 - val_mae: 0.1614 - 141ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping 기법\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "X_tr,X_val,y_tr,y_val=train_test_split(X_train_scaled,y_train,test_size=0.15,shuffle=True,random_state=SEED)\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss',patience=10)\n",
    "history=model.fit(X_tr,y_tr,batch_size=64,epochs=200,validation_data=(X_val,y_val),callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "Early Stopping으로 학습을 멈추면 모델은 학습이 중지된 상태의 가중치로 고정됨  \n",
    "  \n",
    "검증 데이터에 대한 모델 성능을 evaluate 함수로 평가하면 앞의 실행 결과에서 54에포크가 종료된 상태에서의  \n",
    "  \n",
    "평가 지표 값(val_loss,val_acc,val_mae)과 동일하다는 것을 알 수 있음  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 1.0265 - acc: 0.5576 - mae: 0.1614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0264517068862915, 0.5575757622718811, 0.16143731772899628]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 예측값 정리 및 파일 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "테스트 데이터를 predict 함수에 입력하면 목표 변수의 각 클래스에 대한 확률값을 반환함  \n",
    "  \n",
    "다중 분류 문제로 마지막 레이어의 활성화 함수를 softmax로 사용했기 때문.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14640677, 0.02422131, 0.10052594, 0.06059571, 0.12745829,\n",
       "        0.4928767 , 0.04791526],\n",
       "       [0.07843948, 0.00263108, 0.01299645, 0.02802719, 0.12971556,\n",
       "        0.5196164 , 0.22857378],\n",
       "       [0.19741929, 0.07493018, 0.26500297, 0.14723264, 0.06576087,\n",
       "        0.21707232, 0.03258172],\n",
       "       [0.17468636, 0.08192881, 0.27029356, 0.17551476, 0.07622776,\n",
       "        0.19794784, 0.02340092],\n",
       "       [0.11724082, 0.01547744, 0.06363758, 0.0654397 , 0.08472493,\n",
       "        0.56471837, 0.08876109]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터에 대한 예측값 정리\n",
    "y_pred_proba=model.predict(X_test)\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "앞에서 출력한 첫 번째 원소를 보면 7개 클래스에 대한 예측 확률값이 순서대로 표시되어 있음  \n",
    "  \n",
    "4번째 원소(클래스 3)의 확률값이 가장 높으며,  \n",
    "넘파이 argmax 함수를 사용하면 가장 값이 큰 원소의 인덱스 값을 얻을 수 있음.  \n",
    "  \n",
    "따라서 7개 확률값 중에서 가장 큰 원소가 있는 인덱스 3을 출력함.  \n",
    "  \n",
    "  \n",
    "하지만 모델이 예측한 값을 그대로 제출하면 안 됨  \n",
    "  \n",
    "데이터 전처리를 할 때 목표 변수의 값에서 3을 차감했기 때문  \n",
    "  \n",
    "모델 예측값에 3을 더하면 목표 레이블 값을 복원할 수 있음  \n",
    "  \n",
    "따라서 첫 번째 테스트 샘플에 대한 예측값은 6이 됨.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 5, 5, 8], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label=np.argmax(y_pred_proba,axis=-1)+3\n",
    "y_pred_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  quality\n",
       "0      0        8\n",
       "1      1        8\n",
       "2      2        5\n",
       "3      3        5\n",
       "4      4        8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제출 양식에 맞게 정리\n",
    "submission['quality']=y_pred_label.astype(int)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 저장\n",
    "submission.to_csv('output/data/wine/wine_dnn_002.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. LSTM Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf=pd.read_csv('output/daegu_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (14831616, 15)\n"
     ]
    }
   ],
   "source": [
    "df=rdf[:]\n",
    "print('Number of rows and columns:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>lightning</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>condition</th>\n",
       "      <th>region</th>\n",
       "      <th>HI</th>\n",
       "      <th>DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-06-01 00:00:00</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>동인동</td>\n",
       "      <td>15.589444</td>\n",
       "      <td>60.74355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-01 01:00:00</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>동인동</td>\n",
       "      <td>17.245000</td>\n",
       "      <td>62.73431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-06-01 02:00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>동인동</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>64.65038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-06-01 03:00:00</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>동인동</td>\n",
       "      <td>20.006111</td>\n",
       "      <td>65.72772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-06-01 04:00:00</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>동인동</td>\n",
       "      <td>21.415556</td>\n",
       "      <td>67.04608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831611</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-04-30 19:00:00</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>335.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>구지면</td>\n",
       "      <td>9.679444</td>\n",
       "      <td>52.33503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831612</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-04-30 20:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>339.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>구지면</td>\n",
       "      <td>9.852778</td>\n",
       "      <td>52.99350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831613</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>2022-04-30 21:00:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>구지면</td>\n",
       "      <td>10.738333</td>\n",
       "      <td>54.40241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831614</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>2022-04-30 22:00:00</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>구지면</td>\n",
       "      <td>12.179444</td>\n",
       "      <td>56.60598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831615</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>2022-04-30 23:00:00</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>구지면</td>\n",
       "      <td>13.736111</td>\n",
       "      <td>58.79709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14831616 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          year  month  day  hour             datetime  temp  rainfall  \\\n",
       "0         2010      6    1     0  2010-06-01 00:00:00  16.5       0.0   \n",
       "1         2010      6    1     1  2010-06-01 01:00:00  18.1       0.0   \n",
       "2         2010      6    1     2  2010-06-01 02:00:00  19.7       0.0   \n",
       "3         2010      6    1     3  2010-06-01 03:00:00  20.8       0.0   \n",
       "4         2010      6    1     4  2010-06-01 04:00:00  22.2       0.0   \n",
       "...        ...    ...  ...   ...                  ...   ...       ...   \n",
       "14831611  2022      4   30    19  2022-04-30 19:00:00  10.7       0.0   \n",
       "14831612  2022      4   30    20  2022-04-30 20:00:00  11.0       0.0   \n",
       "14831613  2022      4   30    21  2022-04-30 21:00:00  11.9       0.0   \n",
       "14831614  2022      4   30    22  2022-04-30 22:00:00  13.4       0.0   \n",
       "14831615  2022      4   30    23  2022-04-30 23:00:00  15.1       0.0   \n",
       "\n",
       "          lightning  humidity  wind_speed  wind_direction  condition region  \\\n",
       "0                -1      53.0         NaN             NaN          1    동인동   \n",
       "1                -1      49.0         NaN             NaN          1    동인동   \n",
       "2                -1      46.0         NaN             NaN          1    동인동   \n",
       "3                -1      41.0         NaN             NaN          1    동인동   \n",
       "4                -1      36.0         NaN             NaN          2    동인동   \n",
       "...             ...       ...         ...             ...        ...    ...   \n",
       "14831611         -1      71.0         2.1           335.0         -1    구지면   \n",
       "14831612         -1      65.0         2.2           339.0         -1    구지면   \n",
       "14831613         -1      61.0         2.2           338.0         -1    구지면   \n",
       "14831614         -1      53.0         2.0           351.0         -1    구지면   \n",
       "14831615         -1      41.0         2.1             5.0         -1    구지면   \n",
       "\n",
       "                 HI        DI  \n",
       "0         15.589444  60.74355  \n",
       "1         17.245000  62.73431  \n",
       "2         18.926667  64.65038  \n",
       "3         20.006111  65.72772  \n",
       "4         21.415556  67.04608  \n",
       "...             ...       ...  \n",
       "14831611   9.679444  52.33503  \n",
       "14831612   9.852778  52.99350  \n",
       "14831613  10.738333  54.40241  \n",
       "14831614  12.179444  56.60598  \n",
       "14831615  13.736111  58.79709  \n",
       "\n",
       "[14831616 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14831616 entries, 0 to 14831615\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   year            int64  \n",
      " 1   month           int64  \n",
      " 2   day             int64  \n",
      " 3   hour            int64  \n",
      " 4   datetime        object \n",
      " 5   temp            float64\n",
      " 6   rainfall        float64\n",
      " 7   lightning       int64  \n",
      " 8   humidity        float64\n",
      " 9   wind_speed      float64\n",
      " 10  wind_direction  float64\n",
      " 11  condition       int64  \n",
      " 12  region          object \n",
      " 13  HI              float64\n",
      " 14  DI              float64\n",
      "dtypes: float64(7), int64(6), object(2)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>lightning</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>condition</th>\n",
       "      <th>region</th>\n",
       "      <th>HI</th>\n",
       "      <th>DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-06-01 00:00:00</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.589444</td>\n",
       "      <td>60.74355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-01 01:00:00</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17.245000</td>\n",
       "      <td>62.73431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-06-01 02:00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>64.65038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-06-01 03:00:00</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.006111</td>\n",
       "      <td>65.72772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-06-01 04:00:00</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.415556</td>\n",
       "      <td>67.04608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831611</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-04-30 19:00:00</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>335.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>141</td>\n",
       "      <td>9.679444</td>\n",
       "      <td>52.33503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831612</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-04-30 20:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>339.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>141</td>\n",
       "      <td>9.852778</td>\n",
       "      <td>52.99350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831613</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>2022-04-30 21:00:00</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>141</td>\n",
       "      <td>10.738333</td>\n",
       "      <td>54.40241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831614</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>2022-04-30 22:00:00</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>141</td>\n",
       "      <td>12.179444</td>\n",
       "      <td>56.60598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831615</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>2022-04-30 23:00:00</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>141</td>\n",
       "      <td>13.736111</td>\n",
       "      <td>58.79709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14831616 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          year  month  day  hour             datetime  temp  rainfall  \\\n",
       "0         2010      6    1     0  2010-06-01 00:00:00  16.5       0.0   \n",
       "1         2010      6    1     1  2010-06-01 01:00:00  18.1       0.0   \n",
       "2         2010      6    1     2  2010-06-01 02:00:00  19.7       0.0   \n",
       "3         2010      6    1     3  2010-06-01 03:00:00  20.8       0.0   \n",
       "4         2010      6    1     4  2010-06-01 04:00:00  22.2       0.0   \n",
       "...        ...    ...  ...   ...                  ...   ...       ...   \n",
       "14831611  2022      4   30    19  2022-04-30 19:00:00  10.7       0.0   \n",
       "14831612  2022      4   30    20  2022-04-30 20:00:00  11.0       0.0   \n",
       "14831613  2022      4   30    21  2022-04-30 21:00:00  11.9       0.0   \n",
       "14831614  2022      4   30    22  2022-04-30 22:00:00  13.4       0.0   \n",
       "14831615  2022      4   30    23  2022-04-30 23:00:00  15.1       0.0   \n",
       "\n",
       "          lightning  humidity  wind_speed  wind_direction  condition  region  \\\n",
       "0                -1      53.0         NaN             NaN          1       0   \n",
       "1                -1      49.0         NaN             NaN          1       0   \n",
       "2                -1      46.0         NaN             NaN          1       0   \n",
       "3                -1      41.0         NaN             NaN          1       0   \n",
       "4                -1      36.0         NaN             NaN          2       0   \n",
       "...             ...       ...         ...             ...        ...     ...   \n",
       "14831611         -1      71.0         2.1           335.0         -1     141   \n",
       "14831612         -1      65.0         2.2           339.0         -1     141   \n",
       "14831613         -1      61.0         2.2           338.0         -1     141   \n",
       "14831614         -1      53.0         2.0           351.0         -1     141   \n",
       "14831615         -1      41.0         2.1             5.0         -1     141   \n",
       "\n",
       "                 HI        DI  \n",
       "0         15.589444  60.74355  \n",
       "1         17.245000  62.73431  \n",
       "2         18.926667  64.65038  \n",
       "3         20.006111  65.72772  \n",
       "4         21.415556  67.04608  \n",
       "...             ...       ...  \n",
       "14831611   9.679444  52.33503  \n",
       "14831612   9.852778  52.99350  \n",
       "14831613  10.738333  54.40241  \n",
       "14831614  12.179444  56.60598  \n",
       "14831615  13.736111  58.79709  \n",
       "\n",
       "[14831616 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact = pd.factorize(df['region'])\n",
    "df['region'] = fact[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831611</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>335.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831612</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>339.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831613</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831614</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831615</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14831616 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          year  month  day  hour  temp  rainfall  humidity  wind_speed  \\\n",
       "0         2010      6    1     0  16.5       0.0      53.0         NaN   \n",
       "1         2010      6    1     1  18.1       0.0      49.0         NaN   \n",
       "2         2010      6    1     2  19.7       0.0      46.0         NaN   \n",
       "3         2010      6    1     3  20.8       0.0      41.0         NaN   \n",
       "4         2010      6    1     4  22.2       0.0      36.0         NaN   \n",
       "...        ...    ...  ...   ...   ...       ...       ...         ...   \n",
       "14831611  2022      4   30    19  10.7       0.0      71.0         2.1   \n",
       "14831612  2022      4   30    20  11.0       0.0      65.0         2.2   \n",
       "14831613  2022      4   30    21  11.9       0.0      61.0         2.2   \n",
       "14831614  2022      4   30    22  13.4       0.0      53.0         2.0   \n",
       "14831615  2022      4   30    23  15.1       0.0      41.0         2.1   \n",
       "\n",
       "          wind_direction  region  \n",
       "0                    NaN       0  \n",
       "1                    NaN       0  \n",
       "2                    NaN       0  \n",
       "3                    NaN       0  \n",
       "4                    NaN       0  \n",
       "...                  ...     ...  \n",
       "14831611           335.0     141  \n",
       "14831612           339.0     141  \n",
       "14831613           338.0     141  \n",
       "14831614           351.0     141  \n",
       "14831615             5.0     141  \n",
       "\n",
       "[14831616 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['lightning','condition','datetime','HI','DI'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831611</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>335.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831612</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>339.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831613</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831614</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831615</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14189918 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          year  month  day  hour  temp  rainfall  humidity  wind_speed  \\\n",
       "4519      2010     12    6     7  11.6       0.0      32.0         4.1   \n",
       "4520      2010     12    6     8  10.6       0.0      35.0         3.6   \n",
       "4521      2010     12    6     9   9.2       0.0      27.0         3.8   \n",
       "4522      2010     12    6    10   7.9       0.0      34.0         4.1   \n",
       "4523      2010     12    6    11   5.7       0.0      44.0         3.6   \n",
       "...        ...    ...  ...   ...   ...       ...       ...         ...   \n",
       "14831611  2022      4   30    19  10.7       0.0      71.0         2.1   \n",
       "14831612  2022      4   30    20  11.0       0.0      65.0         2.2   \n",
       "14831613  2022      4   30    21  11.9       0.0      61.0         2.2   \n",
       "14831614  2022      4   30    22  13.4       0.0      53.0         2.0   \n",
       "14831615  2022      4   30    23  15.1       0.0      41.0         2.1   \n",
       "\n",
       "          wind_direction  region  \n",
       "4519               304.0       0  \n",
       "4520               300.0       0  \n",
       "4521               295.0       0  \n",
       "4522               281.0       0  \n",
       "4523               298.0       0  \n",
       "...                  ...     ...  \n",
       "14831611           335.0     141  \n",
       "14831612           339.0     141  \n",
       "14831613           338.0     141  \n",
       "14831614           351.0     141  \n",
       "14831615             5.0     141  \n",
       "\n",
       "[14189918 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16ae22c5cf5bfc3495ed4b74ec927ee5dacfe7503530ef7b23599a743f937e94"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
