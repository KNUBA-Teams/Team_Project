{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 더미 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.__version__) # .__version__ 속성으로 버전을 확인함\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 간단한 딥러닝 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용할 입력 데이터를 준비함.\n",
    "# # y=x+1 관계를 갖는 숫자를 x,y 변수에 각각 10개씩 입력함.\n",
    "# # 이 때, x변수의 숫자 배열을 (10행 1열) 형태의 2차원 배열로 변환함.\n",
    "# x=[-3,31,-11,4,0,22,-2,-5,-25,-14]\n",
    "# y=[-2,32,-10,5,1,23,-1,-4,-24,-13]\n",
    "\n",
    "# X_train=np.array(x).reshape(-1,1)\n",
    "# y_train=np.array(y)\n",
    "\n",
    "# print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "케라스 Sequential API는 레이어 여러 개를 연결하여 신경망 모델을 구성하는 도구이다.  \n",
    "  \n",
    "간단한 아키텍처를 가지면서도 대부분의 딥러닝 모델을 만들 수 있다는 장점이 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential() # Sequential 모델 인스턴스를 생성함\n",
    "\n",
    "\n",
    "# # add 메소드를 사용하여 완전 연결 레이어(Dense)를 모델에 추가함.\n",
    "\n",
    "# # 입력 데이터의 차원(input_dim)은 모델 학습에 사용하는 설명 변수(피처)의 개수를 지정하는데,\n",
    "# # 여기서는 1개의 피처를 사용하므로 1로 설정함.\n",
    "\n",
    "# # 완전 연결 레이어의 출력값은 목표 레이블(Y)을 예측함\n",
    "# # 한 개의 연속성 수치(ex.주택 가격)를 예측하는 회귀 문제이므로 유닛(unit) 개수는 1임\n",
    "# # 활성화(activation) 함수로 'linear' 옵션을 지정하여 선형 함수의 출력을 그대로 사용함.\n",
    "# model.add(Dense(units=1,activation='linear',input_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summary 메소드를 이용하여 모델 아키텍처(구조)를 확인함\n",
    "# # 딥러닝 모델이 학습할 모수(파라미터:Param #)는 2개인데,\n",
    "# # 일차함수의 기울기(회귀계수)와 절편(상수항)임.\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델이 훈련하는데 필요한 기본 설정을 compile 함수에 지정하는데,\n",
    "# # 옵티마이저(optimizer)와 손실 함수(loss)를 설정함.\n",
    "\n",
    "# # adam 옵티마이저를 선택하고 회귀 분석의 손실 함수인 평균제곱오차(mse)를 지정함.\n",
    "\n",
    "# # metrics 옵션에 보조 평가 지표를 추가할 수 있는데,\n",
    "# # 여기서는 평균절대오차(mae)를 추가하여 손실 함수를 모니터링할 때 함께 추적하기로 함.\n",
    "# model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit 메소드에 훈련 데이터를 입력하여 모델을 학습시키는데,\n",
    "# # 컴파일 단계에서 설정한 adam 옵티마이저와 mse 손실 함수를 가지고 최적의 가중치와 편향을 찾음.\n",
    "\n",
    "# # 에포크(epoch)는 전체 입력 데이터를 모두 몇 번 학습할 것인지 반복 횟수를 정함.\n",
    "\n",
    "# # verbose 옵션을 False(0)로 지정하면 훈련 과정을 화면에 보여주지 않는데,\n",
    "# # 훈련 과정을 표시하려면 1 또는 2를 입력함.\n",
    "# model.fit(X_train,y_train,epochs=3000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습을 마친 딥러닝 모델의 가중치를 확인하려면 weights 속성을 보면 됨\n",
    "# # 기울기에 해당하는 가중치(kernel:0)와 절편에 해당하는 편향(bias:0) 모두 1에 가까운 값을 가지는데,\n",
    "# # 이는 모델 학습을 통해 일차함수 관계식을 매우 근사하게 찾아낸 것으로 볼 수 있다.\n",
    "# model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 테스트 데이터(X)를 predict 메소드에 입력하면 목표 레이블(Y)에 대한 예측값을 얻을 수 있음.\n",
    "# model.predict([[11],[12],[13]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 딥러닝을 활용한 회귀 분석 : 보스턴 주택 가격 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print('시드 고정:',SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sklearn 데이터셋에서 보스턴 주택 데이터셋 로딩\n",
    "# from sklearn import datasets\n",
    "# housing=datasets.load_boston()\n",
    "# X_data=housing.data\n",
    "# y_data=housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_data.shape,y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "입력 데이터의 서로 다른 피처 값의 범위를 비슷한 크기로 맞춰 주면 딥러닝 모델의 성능을 확보하는데 유리한데,  \n",
    "  \n",
    "이것을 피처 스케일링이라고 부름.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MinMaxScaler를 사용하여 입력 데이터(X_data)의 모든 피처 값을 0~1 범위로 정규화 처리함.\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# X_data_scaled=scaler.fit_transform(X_data)\n",
    "\n",
    "# X_data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습에 사용하기 위하여 훈련 데이터(80%)와 검증 데이터(20%)를 분할함.\n",
    "# # 학습 - 테스트 데이터셋 분할\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X_data,y_data,test_size=0.2,shuffle=True,random_state=SEED)\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MLP 모델 아키텍처 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결(Dense) 레이어만 사용하여 5개 레이어를 갖는 다층 신경망(MLP)을 만든다.  \n",
    "  \n",
    "레이어를 추가할 때는 add 함수를 사용한다.  \n",
    "  \n",
    "은닉 레이어 4개는 각각 128개, 64개, 32개, 16개의 유닛을 갖는다.  \n",
    "  \n",
    "입력 데이터의 피처가 13개이므로 첫 번째 Dense 레이어의 input_dim에 13을 지정한다.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망\n",
    "# def build_model(num_input=1):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='relu',input_dim=num_input))\n",
    "#     model.add(Dense(64,activation='relu'))\n",
    "#     model.add(Dense(32,activation='relu'))\n",
    "#     model.add(Dense(16,activation='relu'))\n",
    "#     model.add(Dense(1,activation='relu'))\n",
    "\n",
    "#     model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(num_input=13)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 미니 배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델을 훈련시킬 때 샘플 데이터를 한 개씩 입력해서 가중치를 갱신하려면 학습 시간이 오래 걸리는 문제가 있음.  \n",
    "  \n",
    "***미니 배치 학습***은 전체 데이터를 여러 개의 작은 배치 단위로 나누고 배치에 들어 있는 샘플 데이터를 묶어서 모델에 입력함.  \n",
    "  \n",
    "배치 단위로 경사하강법을 적용하고 손실 함수를 최소화하는 방향으로 가중치를 업데이트함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 훈련\n",
    "# model.fit(X_train,y_train,epochs=100,batch_size=32,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "evaluate 함수에 테스트 데이터를 입력하여 모델의 일반화 성능을 평가함  \n",
    "  \n",
    "loss는 11.93이고 mae는 2.57임  \n",
    "  \n",
    "검증 손실이 훈련 손실보다 크기 때문에 과대적합으로 판단됨  \n",
    "  \n",
    "배치 크기에 따라 모델 성능이 달라질 수 있기 때문에 모델을 설계할 때 중요하게 고려해야 함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "학습 데이터 일부(여기서는 25%)를 검증 데이터를 사용하여 교차 검증을 해봄  \n",
    "  \n",
    "fit 메소드의 validation_split 옵션에 테스트 데이터셋 비율을 입력하면 됨  \n",
    "  \n",
    "마지막 200번째 에포크 학습이 끝났을 때 훈련 손실이 검증 손실보다 작은 값이므로 과대적합 상태로 판단됨.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=build_model(num_input=13)\n",
    "# history=model.fit(X_train,y_train,batch_size=32,epochs=200,validation_split=0.25,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "훈련 손실(loss)과 검증 손실(val_loss)을 그래프로 나타냄  \n",
    "  \n",
    "가로축에는 에포크(epoch)를 놓고 세로축에 손실 함수 값을 표시함  \n",
    "  \n",
    "모델 10에포크까지 매우 빠른 속도로 학습이 되고, 이후 점차 완만하게 학습 속도가 낮아지며  \n",
    "그래프가 평평해지는 추이를 보임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_loss_curve(total_epoch=10,start=1):\n",
    "#     plt.figure(figsize=(5,5))\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['loss'][start-1:total_epoch],\n",
    "#             label='Train')\n",
    "#     plt.plot(range(start,total_epoch+1),\n",
    "#             history.history['val_loss'][start-1:total_epoch],\n",
    "#             label='Validation')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('mse')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_loss_curve(total_epoch=200,start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "20에포크 이후의 손실 함수를 그림  \n",
    "  \n",
    "앞의 그래프에서는 훈련 손실과 검증 손실 간에 차이가 드러나지 않았지만,\n",
    "다음의 그래프를 보면 40에포크 이후 과대적합이 커지는 것을 볼 수 있다.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_curve(total_epoch=200,start=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 딥러닝을 활용한 분류 예측 : 와인 품질 등급 판별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 랜덤 시드 고정\n",
    "# SEED=12\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# print(\"시드 고정:\",SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=pd.read_csv('./output/data/wine/train.csv')\n",
    "# test=pd.read_csv('./output/data/wine/test.csv')\n",
    "# submission=pd.read_csv('./output/data/wine/sample_submission.csv')\n",
    "\n",
    "# print(train.shape,test.shape,submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train 데이터의 내용을 살펴봄, 목표 변수는 와인 품질을 나타내는 quality 열임.\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일의 양식을 보면 와인 품질을 나타내는 quality 열에 예측값을 입력해야 함.\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type 열의 데이터를 살펴봄, 화이트 와인(white)이 4159개, 레드와인(red)이 1338개\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "type 열의 범주형 데이터는 문자열 값을 가짐  \n",
    "  \n",
    "모델 학습에 입력하려면 숫자형 데이터로 변환해야 함  \n",
    "  \n",
    "화이트 와인을 나타내는 'white' 문자열을 숫자 1로 바꾸고,  \n",
    "레드 와인을 나타내는 'red' 문자열을 숫자 0으로 변환함.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['type']=np.where(train['type']=='white',1,0).astype(int)\n",
    "# test['type']=np.where(test['type']=='white',1,0).astype(int)\n",
    "# train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이번에는 목표 변수인 quality 열의 데이터 개수를 확인함, 6등급 와인의 개수가 가장 많음.\n",
    "\n",
    "# train['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "목표 변수는 연속형 숫자 데이터가 아니라, 와인 등급을 나타내는 범주형 데이터임  \n",
    "  \n",
    "케라스 to_categorical 함수를 이용하여 목표 변수를 원핫 인코딩 변환함.  \n",
    "  \n",
    "원핫 인코딩을 하기 전에 숫자 3을 차감하여 와인 등급을 0~6 범위로 바꿈  \n",
    "  \n",
    "와인 등급은 3~9까지 모두 7개 클래스로 구분되는데, 3~9 범위 값으로 원핫 인코딩을 하면  \n",
    "숫자 0부터 최대값인 9까지 10개 클래스로 인식하기 때문임.  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# y_train=to_categorical(train.loc[:,'quality']-3)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "모델 학습에 사용할 피처를 선택하고, MinMax 스케일링으로 모든 피처 변수의 데이터를 0~1 범위로  \n",
    "정규화 변환함.  \n",
    "  \n",
    "이때 훈련 데이터(X_train)로 정규화 학습을 하고, 같은 조건을 검증 데이터(X_test)에 적용하여 변환하는 점에 유의함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 피처 선택\n",
    "# X_train=train.loc[:,'fixed acidity':]\n",
    "# X_test=test.loc[:,'fixed acidity':]\n",
    "\n",
    "# # 피처 스케일링\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# scaler.fit(X_train)\n",
    "# X_train_scaled=scaler.fit_transform(X_train)\n",
    "# X_test_scaled=scaler.fit_transform(X_test)\n",
    "\n",
    "# print(X_train_scaled.shape,y_train.shape)\n",
    "# print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 모델 설계 : 드랍아웃 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "완전 연결 레이어(Dense) 4개 층으로 구성되는 신경망 모델을 구성함  \n",
    "  \n",
    "모델의 과대적합을 방지하기 위하여 드랍아웃(Dropout) 레이어를 추가함  \n",
    "  \n",
    "드랍아웃은 입력 레이어왕 은닉 레이어 간의 연결 중 일부를 랜덤으로 제거한 상태에서 학습하는 기법임  \n",
    "  \n",
    "결과적으로 유닛 사이에 연결된 가중치 수를 줄이는 효과를 얻기 때문에 과대적합을 방지 가능.  \n",
    "  \n",
    "  \n",
    "미니 배치 단위로 학습할 때마다 연결 네트워크에서 제거되는 가중치가 달라짐,  \n",
    "때문에 매번 다른 네트워크 구조를 갖는 모델을 얻게 됨  \n",
    "  \n",
    "즉, 앙상블 효과가 있어 모델 성능이 개선됨  \n",
    "  \n",
    "  \n",
    "Dense 레이어 뒤에 Dropout 레이어를 추가하고, dropout rate를 설정함  \n",
    "  \n",
    "0.2로 설정하면 20% 확률로 랜덤하게 연결을 제거하게 됨  \n",
    "  \n",
    "은닉 레이어의 활성화 함수로 tanh를 사용해 봄  \n",
    "  \n",
    "다중 분류 모델이므로 마지막 출력 레이어의 활성화 함수는 softmax를 적용함  \n",
    "  \n",
    "옵티마이저는 RMSProp, 손실 함수는 categorical_crossentropy를 지정함  \n",
    "  \n",
    "metrics 옵션에 여러 개의 보조 평가 지표를 입력할 수 있음  \n",
    "  \n",
    "여기서는 acc(정확도)와 mae(평균절대값오차)를 지정함.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 심층 신경망 모델\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "# def build_model(train_data,train_target):\n",
    "#     model=Sequential()\n",
    "#     model.add(Dense(128,activation='tanh',input_dim=train_data.shape[1]))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(64,activation='tanh'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(32,activation='tanh'))\n",
    "#     model.add(Dense(train_target.shape[1],activation='softmax'))\n",
    "\n",
    "#     model.compile(optimizer='RMSProp',loss='categorical_crossentropy',metrics=['acc','mae'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model=build_model(X_train_scaled,y_train)\n",
    "# model.summary()\n",
    "\n",
    "# # tanh 함수는 -1~+1 사이의 출력 범위를 가짐\n",
    "# # 입력값이 0 근처일 때는 학습율이 좋지만,\n",
    "# # 입력값이 커지거나 작아지는 경우 기울기(가중치)가 0에 가까워지므로\n",
    "# # 학습이 이루어지지 않는 문제가 생김.\n",
    "\n",
    "# # 따라서 ReLU 함수에 비해 사용빈도가 낮음 편임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 콜백 함수 : Early Stopping 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "콜백(callback) 함수를 사용하면 모델 학습 과정을 세밀하게 컨트롤할 수 있음.  \n",
    "  \n",
    "가장 많이 사용되는 방법 중에 Early Stopping이 있음.  \n",
    "  \n",
    "딥러닝 모델 학습에서 에포크 수를 늘려 학습을 계속 반복하면 훈련 데이터에 대한 오차(손실 함수)  \n",
    "를 계속 낮출 수 있음.  \n",
    "  \n",
    "하지만 과대적합을 일으켜 테스트 데이터를 포함한 새로운 데이터에 대한 예측력이 나빠지는 문제가 발생함.  \n",
    "  \n",
    "이때 Early Stopping을 사용하면 과대적합이 발생하기 직전에 학습을 멈출 수 있음.  \n",
    "  \n",
    "홀드아웃으로 검증 데이터를 분할하고, 검증 데이터에 대한 모델 성능이 일정 에포크 동안 좋아지지 않으면  \n",
    "모델 학습을 중단함.  \n",
    "  \n",
    "이때 허용되는 에포크 수를 patience 옵션에 설정함.  \n",
    "  \n",
    "다음의 예제는 200에포크로 설정되어 있지만, 학습 중 10에포크 동안 연속하여  \n",
    "검증 데이터에 대한 손실 함수(val_loss)가 줄어들지 않으면 학습을 멈춤.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early Stopping 기법\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# X_tr,X_val,y_tr,y_val=train_test_split(X_train_scaled,y_train,test_size=0.15,shuffle=True,random_state=SEED)\n",
    "\n",
    "# early_stopping=EarlyStopping(monitor='val_loss',patience=10)\n",
    "# history=model.fit(X_tr,y_tr,batch_size=64,epochs=200,validation_data=(X_val,y_val),callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "Early Stopping으로 학습을 멈추면 모델은 학습이 중지된 상태의 가중치로 고정됨  \n",
    "  \n",
    "검증 데이터에 대한 모델 성능을 evaluate 함수로 평가하면 앞의 실행 결과에서 54에포크가 종료된 상태에서의  \n",
    "  \n",
    "평가 지표 값(val_loss,val_acc,val_mae)과 동일하다는 것을 알 수 있음  \n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 예측값 정리 및 파일 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "테스트 데이터를 predict 함수에 입력하면 목표 변수의 각 클래스에 대한 확률값을 반환함  \n",
    "  \n",
    "다중 분류 문제로 마지막 레이어의 활성화 함수를 softmax로 사용했기 때문.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test 데이터에 대한 예측값 정리\n",
    "# y_pred_proba=model.predict(X_test)\n",
    "# y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "앞에서 출력한 첫 번째 원소를 보면 7개 클래스에 대한 예측 확률값이 순서대로 표시되어 있음  \n",
    "  \n",
    "4번째 원소(클래스 3)의 확률값이 가장 높으며,  \n",
    "넘파이 argmax 함수를 사용하면 가장 값이 큰 원소의 인덱스 값을 얻을 수 있음.  \n",
    "  \n",
    "따라서 7개 확률값 중에서 가장 큰 원소가 있는 인덱스 3을 출력함.  \n",
    "  \n",
    "  \n",
    "하지만 모델이 예측한 값을 그대로 제출하면 안 됨  \n",
    "  \n",
    "데이터 전처리를 할 때 목표 변수의 값에서 3을 차감했기 때문  \n",
    "  \n",
    "모델 예측값에 3을 더하면 목표 레이블 값을 복원할 수 있음  \n",
    "  \n",
    "따라서 첫 번째 테스트 샘플에 대한 예측값은 6이 됨.\n",
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_label=np.argmax(y_pred_proba,axis=-1)+3\n",
    "# y_pred_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 양식에 맞게 정리\n",
    "# submission['quality']=y_pred_label.astype(int)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 제출 파일 저장\n",
    "# submission.to_csv('output/data/wine/wine_dnn_002.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# print('Number of rows and columns:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['lightning','condition','datetime','HI','DI'], axis=1, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['test']=str(df['year'])+'-'+str(df['month'])+'-'+str(df['day'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['year','month','day'],axis=1,inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Onehot Encoding\n",
    "# df['hour']=df['hour'].astype('category')\n",
    "# df=pd.get_dummies(df,columns=['hour'],prefix='H',drop_first=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_27=df[df['region']==27]\n",
    "# df_27=df_27.reset_index(drop=True)\n",
    "# df_27.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10=df[df['region']==10]\n",
    "# df_10=df_10.reset_index(drop=True)\n",
    "# df_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_10_01=df_10[pd.DatetimeIndex(df_10['date']).year<=2019]\n",
    "# df_10_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "# X_train_scaled=X_train.loc[:,'temp':]\n",
    "# X_test_scaled=X_test.loc[:,'temp':]\n",
    "\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train_scaled.values)\n",
    "# X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "# X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in test_data.take(1):\n",
    "#     inputs,targets=batch\n",
    "\n",
    "# print(\"Input:\",inputs.numpy().shape)\n",
    "# print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=rdf[:]\n",
    "# fact = pd.factorize(df['region'])\n",
    "# df['region'] = fact[0]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_8m=df[(df['month']==8)]\n",
    "# df_8m_10r=df_8m[df_8m['region']==10]\n",
    "\n",
    "# df_7m=df[(df['month']==7)]\n",
    "# df_7m_10r=df_7m[df_7m['region']==10]\n",
    "\n",
    "# df_6m=df[(df['month']==6)]\n",
    "# df_6m_10r=df_6m[df_6m['region']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_8m=df_8m_10r['datetime'].to_list() \n",
    "# xs_7m=df_7m_10r['datetime'].to_list()\n",
    "# xs_6m=df_6m_10r['datetime'].to_list()\n",
    "\n",
    "# ys_8m=df_8m_10r['temp'].to_list()\n",
    "# ys_7m=df_7m_10r['temp'].to_list()\n",
    "# ys_6m=df_6m_10r['temp'].to_list()\n",
    "\n",
    "# plt.figure(figsize=(100, 8))\n",
    "\n",
    "# plt.plot(xs_8m, ys_8m, 'o-', ms=3, lw=1, label='8th month')\n",
    "# plt.plot(xs_7m, ys_7m, 'o-', ms=3, lw=1, label='7th month')\n",
    "# plt.plot(xs_6m, ys_6m, 'o-', ms=3, lw=1, label='6th month')\n",
    "# plt.ylim(0,40)\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Temp')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. 라이브러리 및 데이터 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf=pd.read_csv('output/daegu_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (14831616, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>2010-12-06</td>\n",
       "      <td>12</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831611</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>335.0</td>\n",
       "      <td>141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831612</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>339.0</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831613</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831614</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>141</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831615</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>141</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14189918 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  month  temp  rainfall  humidity  wind_speed  \\\n",
       "4519     2010-12-06     12  11.6       0.0      32.0         4.1   \n",
       "4520     2010-12-06     12  10.6       0.0      35.0         3.6   \n",
       "4521     2010-12-06     12   9.2       0.0      27.0         3.8   \n",
       "4522     2010-12-06     12   7.9       0.0      34.0         4.1   \n",
       "4523     2010-12-06     12   5.7       0.0      44.0         3.6   \n",
       "...             ...    ...   ...       ...       ...         ...   \n",
       "14831611 2022-04-30      4  10.7       0.0      71.0         2.1   \n",
       "14831612 2022-04-30      4  11.0       0.0      65.0         2.2   \n",
       "14831613 2022-04-30      4  11.9       0.0      61.0         2.2   \n",
       "14831614 2022-04-30      4  13.4       0.0      53.0         2.0   \n",
       "14831615 2022-04-30      4  15.1       0.0      41.0         2.1   \n",
       "\n",
       "          wind_direction  region  hour  \n",
       "4519               304.0       0     7  \n",
       "4520               300.0       0     8  \n",
       "4521               295.0       0     9  \n",
       "4522               281.0       0    10  \n",
       "4523               298.0       0    11  \n",
       "...                  ...     ...   ...  \n",
       "14831611           335.0     141    19  \n",
       "14831612           339.0     141    20  \n",
       "14831613           338.0     141    21  \n",
       "14831614           351.0     141    22  \n",
       "14831615             5.0     141    23  \n",
       "\n",
       "[14189918 rows x 9 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=rdf[:]\n",
    "print('Number of rows and columns:', df.shape)\n",
    "\n",
    "fact = pd.factorize(df['region'])\n",
    "df['region'] = fact[0]\n",
    "\n",
    "df.drop(['lightning','condition','datetime','HI','DI'], axis=1, inplace=True)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['date'] = pd.to_datetime((df['year']*10000 + df['month']*100 + df['day']).astype(str), format='%Y%m%d')\n",
    "\n",
    "\n",
    "# df.drop(['year','month','day'],axis=1,inplace=True)\n",
    "\n",
    "df=df[['date','month','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "# df=df[['date','temp','rainfall','humidity','wind_speed','wind_direction','region','hour']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826523</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826524</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826525</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>141</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826526</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>141</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826527</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>330.0</td>\n",
       "      <td>141</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4573536 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  month  temp  rainfall  humidity  wind_speed  \\\n",
       "8760     2011-06-01      6  19.0       0.0      77.0         1.6   \n",
       "8761     2011-06-01      6  19.8       0.0      66.0         1.3   \n",
       "8762     2011-06-01      6  20.4       0.0      66.0         2.1   \n",
       "8763     2011-06-01      6  21.9       0.0      60.0         1.6   \n",
       "8764     2011-06-01      6  21.8       0.0      61.0         2.2   \n",
       "...             ...    ...   ...       ...       ...         ...   \n",
       "14826523 2021-09-30      9  16.8       0.0     100.0         0.5   \n",
       "14826524 2021-09-30      9  17.1       0.0     100.0         1.0   \n",
       "14826525 2021-09-30      9  16.9       0.0     100.0         2.0   \n",
       "14826526 2021-09-30      9  17.5       0.0     100.0         2.2   \n",
       "14826527 2021-09-30      9  19.7       0.0      90.0         2.6   \n",
       "\n",
       "          wind_direction  region  hour  \n",
       "8760                86.0       0     0  \n",
       "8761                48.0       0     1  \n",
       "8762               270.0       0     2  \n",
       "8763               101.0       0     3  \n",
       "8764               270.0       0     4  \n",
       "...                  ...     ...   ...  \n",
       "14826523           338.0     141    19  \n",
       "14826524           328.0     141    20  \n",
       "14826525           346.0     141    21  \n",
       "14826526           325.0     141    22  \n",
       "14826527           330.0     141    23  \n",
       "\n",
       "[4573536 rows x 9 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_all=df[(df['month']==12)|(df['month']==1)|(df['month']==2)|(df['month']==6)|(df['month']==7)|(df['month']==8)]\n",
    "df_all=df[(df['month']==6)|(df['month']==7)|(df['month']==8)|(df['month']==9)]\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_10r=df_all[(df_all['region']==10)]\n",
    "# df_all_10r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_10r_ind=df_all_10r.reset_index(drop=True)\n",
    "df_all_ind=df_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 6))\n",
    "# df_all_10r.plot(y=['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573531</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>338.0</td>\n",
       "      <td>141</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573532</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573533</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>141</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573534</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>141</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573535</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>330.0</td>\n",
       "      <td>141</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4573536 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "0       2011-06-01  19.0       0.0      77.0         1.6            86.0   \n",
       "1       2011-06-01  19.8       0.0      66.0         1.3            48.0   \n",
       "2       2011-06-01  20.4       0.0      66.0         2.1           270.0   \n",
       "3       2011-06-01  21.9       0.0      60.0         1.6           101.0   \n",
       "4       2011-06-01  21.8       0.0      61.0         2.2           270.0   \n",
       "...            ...   ...       ...       ...         ...             ...   \n",
       "4573531 2021-09-30  16.8       0.0     100.0         0.5           338.0   \n",
       "4573532 2021-09-30  17.1       0.0     100.0         1.0           328.0   \n",
       "4573533 2021-09-30  16.9       0.0     100.0         2.0           346.0   \n",
       "4573534 2021-09-30  17.5       0.0     100.0         2.2           325.0   \n",
       "4573535 2021-09-30  19.7       0.0      90.0         2.6           330.0   \n",
       "\n",
       "         region  hour  \n",
       "0             0     0  \n",
       "1             0     1  \n",
       "2             0     2  \n",
       "3             0     3  \n",
       "4             0     4  \n",
       "...         ...   ...  \n",
       "4573531     141    19  \n",
       "4573532     141    20  \n",
       "4573533     141    21  \n",
       "4573534     141    22  \n",
       "4573535     141    23  \n",
       "\n",
       "[4573536 rows x 8 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ind.drop(['month'],axis=1,inplace=True)\n",
    "df_all_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train과 test로 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999876, 8) (2999876, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setting\n",
    "train_split_idx=3000000\n",
    "window_size=100                       # 과거 100시간 동안 시계열 데이터를 학습 데이터로 사용\n",
    "future=24                             # 24시간 이후의 타깃 예측\n",
    "\n",
    "# Features\n",
    "X_train=df_all_ind.iloc[:train_split_idx-window_size-future,0:]\n",
    "\n",
    "# Targets\n",
    "y_train=df_all_ind.iloc[window_size+future:train_split_idx,[1]]  # 'temp' 열\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>region</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2012-08-11</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000000</th>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000001</th>\n",
       "      <td>2012-08-12</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>79.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  temp  rainfall  humidity  wind_speed  wind_direction  \\\n",
       "2999999 2012-08-11  27.4       0.0      78.0         0.0             0.0   \n",
       "3000000 2012-08-12  28.5       0.0      73.0         0.8            50.0   \n",
       "3000001 2012-08-12  28.5       0.0      71.0         0.5            79.0   \n",
       "\n",
       "         region  hour  \n",
       "2999999      93    23  \n",
       "3000000      93     0  \n",
       "3000001      93     1  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ind.iloc[[train_split_idx-1,train_split_idx,train_split_idx+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573536, 8) (1573536, 1)\n"
     ]
    }
   ],
   "source": [
    "# X_test\n",
    "test_start=train_split_idx-window_size-future   # 테스트 데이터 시작 행\n",
    "test_end=df_all_ind.shape[0]-window_size-future\n",
    "X_test=df_all_ind.iloc[test_start:test_end,0:]\n",
    "\n",
    "# y_test\n",
    "# label_start= +future        # 테스트 데이터의 첫 번째 타깃 데이터 위치\n",
    "y_test=df_all_ind.iloc[train_split_idx:,[1]]    # 'temp' 열 선택\n",
    "\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력 데이터 0~1로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "X_train_scaled=X_train.loc[:,'temp':]\n",
    "X_test_scaled=X_test.loc[:,'temp':]\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train_scaled.values)\n",
    "X_train_scaled.loc[:,:]=scaler.transform(X_train_scaled.values)\n",
    "X_test_scaled.loc[:,:]=scaler.transform(X_test_scaled.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배치 사이즈 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mini Batch 크기로 시계열 변환\n",
    "# train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=16)\n",
    "# test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=16)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# # Mini Batch 크기로 시계열 변환\n",
    "# train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=32)\n",
    "# test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=32)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mini Batch 크기로 시계열 변환\n",
    "# train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=64)\n",
    "# test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=64)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# # Mini Batch 크기로 시계열 변환\n",
    "# train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=1024)\n",
    "# test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=1024)\n",
    "\n",
    "# print(train_data)\n",
    "# print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Mini Batch 크기로 시계열 변환\n",
    "train_data=timeseries_dataset_from_array(X_train_scaled,y_train,sequence_length=window_size,batch_size=16384)\n",
    "test_data=timeseries_dataset_from_array(X_test_scaled,y_test,sequence_length=window_size,batch_size=16384)\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (배치사이즈, 타임스텝, 컬럼수-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (16384, 100, 7)\n",
      "Target: (16384, 1)\n"
     ]
    }
   ],
   "source": [
    "for batch in test_data.take(1):\n",
    "    inputs,targets=batch\n",
    "\n",
    "print(\"Input:\",inputs.numpy().shape)\n",
    "print(\"Target:\",targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 7), dtype=float64, numpy=\n",
       "array([[0.51829268, 0.        , 0.75555556, 0.08284024, 0.31024931,\n",
       "        1.        , 0.86956522],\n",
       "       [0.53963415, 0.        , 0.73333333, 0.07692308, 0.41274238,\n",
       "        1.        , 0.91304348],\n",
       "       [0.55487805, 0.        , 0.76666667, 0.09467456, 0.39058172,\n",
       "        1.        , 0.95652174],\n",
       "       [0.58231707, 0.        , 0.7       , 0.13017751, 0.34626039,\n",
       "        1.        , 1.        ],\n",
       "       [0.59146341, 0.        , 0.66666667, 0.18343195, 0.35734072,\n",
       "        1.        , 0.        ],\n",
       "       [0.66768293, 0.        , 0.55555556, 0.21301775, 0.31578947,\n",
       "        1.        , 0.04347826],\n",
       "       [0.71341463, 0.        , 0.48888889, 0.26627219, 0.24099723,\n",
       "        1.        , 0.08695652],\n",
       "       [0.72256098, 0.        , 0.46666667, 0.31360947, 0.33240997,\n",
       "        1.        , 0.13043478],\n",
       "       [0.72560976, 0.        , 0.45555556, 0.31952663, 0.32686981,\n",
       "        1.        , 0.17391304],\n",
       "       [0.7347561 , 0.        , 0.43333333, 0.35502959, 0.34072022,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.75      , 0.        , 0.38888889, 0.30177515, 0.33518006,\n",
       "        1.        , 0.26086957],\n",
       "       [0.71341463, 0.        , 0.37777778, 0.37278107, 0.32132964,\n",
       "        1.        , 0.30434783],\n",
       "       [0.69207317, 0.        , 0.4       , 0.30769231, 0.34072022,\n",
       "        1.        , 0.34782609],\n",
       "       [0.65853659, 0.        , 0.41111111, 0.27810651, 0.34072022,\n",
       "        1.        , 0.39130435],\n",
       "       [0.62195122, 0.        , 0.45555556, 0.28402367, 0.31024931,\n",
       "        1.        , 0.43478261],\n",
       "       [0.58841463, 0.        , 0.55555556, 0.21893491, 0.32686981,\n",
       "        1.        , 0.47826087],\n",
       "       [0.56097561, 0.        , 0.64444444, 0.22485207, 0.34072022,\n",
       "        1.        , 0.52173913],\n",
       "       [0.54878049, 0.        , 0.66666667, 0.20710059, 0.32686981,\n",
       "        1.        , 0.56521739],\n",
       "       [0.53658537, 0.        , 0.68888889, 0.12426036, 0.35457064,\n",
       "        1.        , 0.60869565],\n",
       "       [0.5304878 , 0.        , 0.7       , 0.14792899, 0.39058172,\n",
       "        1.        , 0.65217391],\n",
       "       [0.51219512, 0.        , 0.71111111, 0.07100592, 0.52631579,\n",
       "        1.        , 0.69565217],\n",
       "       [0.5       , 0.        , 0.71111111, 0.07100592, 0.48753463,\n",
       "        1.        , 0.73913043],\n",
       "       [0.50609756, 0.        , 0.75555556, 0.0295858 , 0.35457064,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.45731707, 0.        , 0.78888889, 0.        , 0.00277008,\n",
       "        1.        , 0.82608696],\n",
       "       [0.45426829, 0.        , 0.82222222, 0.0887574 , 0.47091413,\n",
       "        1.        , 0.86956522],\n",
       "       [0.45121951, 0.        , 0.68888889, 0.00591716, 0.00277008,\n",
       "        1.        , 0.91304348],\n",
       "       [0.47865854, 0.        , 0.74444444, 0.07692308, 0.45152355,\n",
       "        1.        , 0.95652174],\n",
       "       [0.55792683, 0.        , 0.66666667, 0.01183432, 0.00277008,\n",
       "        1.        , 1.        ],\n",
       "       [0.57926829, 0.        , 0.6       , 0.10650888, 0.26869806,\n",
       "        1.        , 0.        ],\n",
       "       [0.60060976, 0.        , 0.57777778, 0.14201183, 0.30470914,\n",
       "        1.        , 0.04347826],\n",
       "       [0.6554878 , 0.        , 0.48888889, 0.13609467, 0.3767313 ,\n",
       "        1.        , 0.08695652],\n",
       "       [0.69512195, 0.        , 0.42222222, 0.12426036, 0.24376731,\n",
       "        1.        , 0.13043478],\n",
       "       [0.72865854, 0.        , 0.34444444, 0.15384615, 0.31024931,\n",
       "        1.        , 0.17391304],\n",
       "       [0.73780488, 0.        , 0.31111111, 0.18343195, 0.35180055,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.75609756, 0.        , 0.28888889, 0.20710059, 0.22437673,\n",
       "        1.        , 0.26086957],\n",
       "       [0.74085366, 0.        , 0.45555556, 0.16568047, 0.3601108 ,\n",
       "        1.        , 0.30434783],\n",
       "       [0.71646341, 0.        , 0.48888889, 0.21301775, 0.26038781,\n",
       "        1.        , 0.34782609],\n",
       "       [0.67682927, 0.        , 0.47777778, 0.26035503, 0.26315789,\n",
       "        1.        , 0.39130435],\n",
       "       [0.6402439 , 0.        , 0.55555556, 0.24260355, 0.28808864,\n",
       "        1.        , 0.43478261],\n",
       "       [0.60060976, 0.        , 0.61111111, 0.21893491, 0.29085873,\n",
       "        1.        , 0.47826087],\n",
       "       [0.57621951, 0.        , 0.6       , 0.19526627, 0.29639889,\n",
       "        1.        , 0.52173913],\n",
       "       [0.58231707, 0.        , 0.62222222, 0.16568047, 0.46537396,\n",
       "        1.        , 0.56521739],\n",
       "       [0.55792683, 0.        , 0.65555556, 0.15976331, 0.46537396,\n",
       "        1.        , 0.60869565],\n",
       "       [0.5304878 , 0.        , 0.73333333, 0.13017751, 0.44044321,\n",
       "        1.        , 0.65217391],\n",
       "       [0.5152439 , 0.        , 0.77777778, 0.15384615, 0.39889197,\n",
       "        1.        , 0.69565217],\n",
       "       [0.50304878, 0.        , 0.77777778, 0.15384615, 0.43213296,\n",
       "        1.        , 0.73913043],\n",
       "       [0.48170732, 0.        , 0.81111111, 0.13017751, 0.44044321,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.47560976, 0.        , 0.82222222, 0.0887574 , 0.29639889,\n",
       "        1.        , 0.82608696],\n",
       "       [0.47256098, 0.        , 0.82222222, 0.12426036, 0.35457064,\n",
       "        1.        , 0.86956522],\n",
       "       [0.4695122 , 0.        , 0.73333333, 0.07100592, 0.31855956,\n",
       "        1.        , 0.91304348],\n",
       "       [0.48780488, 0.        , 0.75555556, 0.0591716 , 0.29916898,\n",
       "        1.        , 0.95652174],\n",
       "       [0.50914634, 0.        , 0.73333333, 0.09467456, 0.29085873,\n",
       "        1.        , 1.        ],\n",
       "       [0.57012195, 0.        , 0.67777778, 0.        , 0.00277008,\n",
       "        1.        , 0.        ],\n",
       "       [0.62804878, 0.        , 0.61111111, 0.        , 0.00277008,\n",
       "        1.        , 0.04347826],\n",
       "       [0.65853659, 0.        , 0.55555556, 0.08284024, 0.89196676,\n",
       "        1.        , 0.08695652],\n",
       "       [0.67682927, 0.        , 0.5       , 0.13017751, 0.93905817,\n",
       "        1.        , 0.13043478],\n",
       "       [0.72865854, 0.        , 0.45555556, 0.02366864, 0.00277008,\n",
       "        1.        , 0.17391304],\n",
       "       [0.77439024, 0.        , 0.35555556, 0.06508876, 0.73684211,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.7804878 , 0.        , 0.31111111, 0.19526627, 0.88642659,\n",
       "        1.        , 0.26086957],\n",
       "       [0.78963415, 0.        , 0.32222222, 0.13017751, 0.83379501,\n",
       "        1.        , 0.30434783],\n",
       "       [0.80792683, 0.        , 0.36666667, 0.14792899, 0.86149584,\n",
       "        1.        , 0.34782609],\n",
       "       [0.77743902, 0.        , 0.45555556, 0.20118343, 0.68698061,\n",
       "        1.        , 0.39130435],\n",
       "       [0.75609756, 0.        , 0.5       , 0.24260355, 0.78116343,\n",
       "        1.        , 0.43478261],\n",
       "       [0.72865854, 0.        , 0.52222222, 0.17159763, 0.90027701,\n",
       "        1.        , 0.47826087],\n",
       "       [0.7195122 , 0.        , 0.52222222, 0.10650888, 0.69806094,\n",
       "        1.        , 0.52173913],\n",
       "       [0.63719512, 0.        , 0.51111111, 0.0295858 , 0.10526316,\n",
       "        1.        , 0.56521739],\n",
       "       [0.61280488, 0.        , 0.58888889, 0.01183432, 0.00277008,\n",
       "        1.        , 0.60869565],\n",
       "       [0.60365854, 0.        , 0.65555556, 0.05325444, 0.46537396,\n",
       "        1.        , 0.65217391],\n",
       "       [0.60365854, 0.        , 0.64444444, 0.07692308, 0.47645429,\n",
       "        1.        , 0.69565217],\n",
       "       [0.57926829, 0.        , 0.66666667, 0.00591716, 0.00277008,\n",
       "        1.        , 0.73913043],\n",
       "       [0.5945122 , 0.        , 0.68888889, 0.0591716 , 0.72022161,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.55792683, 0.        , 0.71111111, 0.05325444, 0.13850416,\n",
       "        1.        , 0.82608696],\n",
       "       [0.55792683, 0.        , 0.73333333, 0.02366864, 0.00277008,\n",
       "        1.        , 0.86956522],\n",
       "       [0.56707317, 0.        , 0.73333333, 0.04733728, 0.50138504,\n",
       "        1.        , 0.91304348],\n",
       "       [0.58841463, 0.        , 0.73333333, 0.        , 0.00277008,\n",
       "        1.        , 0.95652174],\n",
       "       [0.61890244, 0.        , 0.71111111, 0.04142012, 0.15789474,\n",
       "        1.        , 1.        ],\n",
       "       [0.64329268, 0.        , 0.66666667, 0.06508876, 0.03047091,\n",
       "        1.        , 0.        ],\n",
       "       [0.67073171, 0.        , 0.6       , 0.10059172, 0.06094183,\n",
       "        1.        , 0.04347826],\n",
       "       [0.68597561, 0.        , 0.56666667, 0.14792899, 0.93628809,\n",
       "        1.        , 0.08695652],\n",
       "       [0.67378049, 0.        , 0.55555556, 0.10650888, 0.94736842,\n",
       "        1.        , 0.13043478],\n",
       "       [0.71646341, 0.        , 0.61111111, 0.17159763, 0.8365651 ,\n",
       "        1.        , 0.17391304],\n",
       "       [0.72560976, 0.        , 0.5       , 0.26035503, 0.78393352,\n",
       "        1.        , 0.2173913 ],\n",
       "       [0.68902439, 0.        , 0.57777778, 0.19526627, 0.8199446 ,\n",
       "        1.        , 0.26086957],\n",
       "       [0.625     , 0.        , 0.63333333, 0.24852071, 0.31024931,\n",
       "        1.        , 0.30434783],\n",
       "       [0.54268293, 0.01639344, 0.82222222, 0.27218935, 0.38781163,\n",
       "        1.        , 0.34782609],\n",
       "       [0.52743902, 0.01639344, 0.87777778, 0.10059172, 0.28808864,\n",
       "        1.        , 0.39130435],\n",
       "       [0.50609756, 0.01639344, 0.87777778, 0.15384615, 0.33240997,\n",
       "        1.        , 0.43478261],\n",
       "       [0.50609756, 0.        , 0.88888889, 0.23076923, 0.40443213,\n",
       "        1.        , 0.47826087],\n",
       "       [0.50304878, 0.        , 0.85555556, 0.16568047, 0.43767313,\n",
       "        1.        , 0.52173913],\n",
       "       [0.50609756, 0.        , 0.83333333, 0.1183432 , 0.38781163,\n",
       "        1.        , 0.56521739],\n",
       "       [0.51219512, 0.        , 0.82222222, 0.18934911, 0.45152355,\n",
       "        1.        , 0.60869565],\n",
       "       [0.50609756, 0.        , 0.92222222, 0.13017751, 0.43490305,\n",
       "        1.        , 0.65217391],\n",
       "       [0.50304878, 0.        , 0.9       , 0.1183432 , 0.41828255,\n",
       "        1.        , 0.69565217],\n",
       "       [0.49695122, 0.        , 0.88888889, 0.17751479, 0.4265928 ,\n",
       "        1.        , 0.73913043],\n",
       "       [0.49695122, 0.        , 0.9       , 0.15976331, 0.4099723 ,\n",
       "        1.        , 0.7826087 ],\n",
       "       [0.49085366, 0.        , 0.87777778, 0.15976331, 0.41551247,\n",
       "        1.        , 0.82608696],\n",
       "       [0.48780488, 0.        , 0.9       , 0.12426036, 0.3601108 ,\n",
       "        1.        , 0.86956522],\n",
       "       [0.48170732, 0.        , 0.85555556, 0.11242604, 0.3933518 ,\n",
       "        1.        , 0.91304348],\n",
       "       [0.49390244, 0.        , 0.85555556, 0.06508876, 0.32686981,\n",
       "        1.        , 0.95652174],\n",
       "       [0.52134146, 0.        , 0.81111111, 0.01775148, 0.00277008,\n",
       "        1.        , 1.        ]])>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([28.5])>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 32)                5120      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,665\n",
      "Trainable params: 5,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2930/2930 [==============================] - 1159s 395ms/step - loss: 2.7006 - mse: 17.6015 - val_loss: 2.3561 - val_mse: 8.5763\n",
      "Epoch 2/10\n",
      "2930/2930 [==============================] - 1176s 401ms/step - loss: 1.8551 - mse: 5.9857 - val_loss: 2.3366 - val_mse: 8.3805\n",
      "Epoch 3/10\n",
      "2930/2930 [==============================] - 2197s 750ms/step - loss: 1.8104 - mse: 5.7596 - val_loss: 2.2733 - val_mse: 8.0060\n",
      "Epoch 4/10\n",
      "2930/2930 [==============================] - 1180s 403ms/step - loss: 1.7977 - mse: 5.6833 - val_loss: 2.1771 - val_mse: 7.4599\n",
      "Epoch 5/10\n",
      "2930/2930 [==============================] - 1195s 408ms/step - loss: 1.7708 - mse: 5.5380 - val_loss: 2.0901 - val_mse: 6.8820\n",
      "Epoch 6/10\n",
      "2930/2930 [==============================] - 1179s 402ms/step - loss: 1.7070 - mse: 5.2033 - val_loss: 2.1203 - val_mse: 7.1167\n",
      "Epoch 7/10\n",
      "2930/2930 [==============================] - 1100s 375ms/step - loss: 1.6623 - mse: 4.9708 - val_loss: 1.9667 - val_mse: 6.3165\n",
      "Epoch 8/10\n",
      "2930/2930 [==============================] - 1177s 402ms/step - loss: 1.6060 - mse: 4.6727 - val_loss: 1.9678 - val_mse: 6.3444\n",
      "Epoch 9/10\n",
      "2930/2930 [==============================] - 1156s 395ms/step - loss: 1.5524 - mse: 4.3968 - val_loss: 1.8845 - val_mse: 5.9094\n",
      "Epoch 10/10\n",
      "2930/2930 [==============================] - 1137s 388ms/step - loss: 1.5088 - mse: 4.1738 - val_loss: 1.8112 - val_mse: 5.5425\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 32)                5120      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,665\n",
      "Trainable params: 5,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 767s 4s/step - loss: 8.2209 - mse: 129.8818 - val_loss: 3.6361 - val_mse: 20.2549\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 770s 4s/step - loss: 3.6200 - mse: 20.1000 - val_loss: 3.6021 - val_mse: 19.8297\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 777s 4s/step - loss: 3.5127 - mse: 18.9238 - val_loss: 3.4075 - val_mse: 17.7022\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 766s 4s/step - loss: 3.1182 - mse: 14.9072 - val_loss: 2.6792 - val_mse: 11.0566\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 781s 4s/step - loss: 2.2757 - mse: 8.3358 - val_loss: 2.1125 - val_mse: 7.4652\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 776s 4s/step - loss: 2.0581 - mse: 7.0796 - val_loss: 1.9764 - val_mse: 6.6229\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 778s 4s/step - loss: 1.9504 - mse: 6.4651 - val_loss: 1.9320 - val_mse: 6.3497\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 809s 4s/step - loss: 1.9136 - mse: 6.2713 - val_loss: 1.9074 - val_mse: 6.3176\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 806s 4s/step - loss: 1.8955 - mse: 6.1839 - val_loss: 1.8944 - val_mse: 6.2713\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 820s 4s/step - loss: 1.8836 - mse: 6.1242 - val_loss: 1.8831 - val_mse: 6.2158\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=32,return_sequences=False))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=8,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=50,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5층 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Input(shape=[100,7]))\n",
    "\n",
    "model.add(LSTM(units=64,return_sequences=False))\n",
    "model.add(Dense(units=32,activation='linear'))\n",
    "model.add(Dense(units=16,activation='linear'))\n",
    "model.add(Dense(units=8,activation='linear'))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae',metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=10,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history=model.fit(train_data,epochs=50,validation_data=test_data,verbose=1)\n",
    "\n",
    "# 손실 함수 그래프\n",
    "def plot_loss_curve(history,total_epoch=10,start=1):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['loss'][start-1:total_epoch],\n",
    "        label='Train')\n",
    "    plt.plot(range(start,total_epoch+1),\n",
    "        history.history['val_loss'][start-1:total_epoch],\n",
    "        label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history=history,total_epoch=len(history.history['loss']),start=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16ae22c5cf5bfc3495ed4b74ec927ee5dacfe7503530ef7b23599a743f937e94"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
